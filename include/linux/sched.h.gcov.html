<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - btrfstest.info - include/linux/sched.h</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">include/linux</a> - sched.h<span style="font-size: 80%;"> (source / <a href="sched.h.func.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">btrfstest.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">4</td>
            <td class="headerCovTableEntry">6</td>
            <td class="headerCovTableEntryLo">66.7 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2014-11-28</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntry">0</td>
            <td class="headerCovTableEntryHi">-</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : #ifndef _LINUX_SCHED_H</a>
<span class="lineNum">       2 </span>            : #define _LINUX_SCHED_H
<span class="lineNum">       3 </span>            : 
<span class="lineNum">       4 </span>            : #include &lt;uapi/linux/sched.h&gt;
<span class="lineNum">       5 </span>            : 
<span class="lineNum">       6 </span>            : #include &lt;linux/sched/prio.h&gt;
<span class="lineNum">       7 </span>            : 
<span class="lineNum">       8 </span>            : 
<span class="lineNum">       9 </span>            : struct sched_param {
<span class="lineNum">      10 </span>            :         int sched_priority;
<span class="lineNum">      11 </span>            : };
<span class="lineNum">      12 </span>            : 
<span class="lineNum">      13 </span>            : #include &lt;asm/param.h&gt;    /* for HZ */
<span class="lineNum">      14 </span>            : 
<span class="lineNum">      15 </span>            : #include &lt;linux/capability.h&gt;
<span class="lineNum">      16 </span>            : #include &lt;linux/threads.h&gt;
<span class="lineNum">      17 </span>            : #include &lt;linux/kernel.h&gt;
<span class="lineNum">      18 </span>            : #include &lt;linux/types.h&gt;
<span class="lineNum">      19 </span>            : #include &lt;linux/timex.h&gt;
<span class="lineNum">      20 </span>            : #include &lt;linux/jiffies.h&gt;
<span class="lineNum">      21 </span>            : #include &lt;linux/plist.h&gt;
<span class="lineNum">      22 </span>            : #include &lt;linux/rbtree.h&gt;
<span class="lineNum">      23 </span>            : #include &lt;linux/thread_info.h&gt;
<span class="lineNum">      24 </span>            : #include &lt;linux/cpumask.h&gt;
<span class="lineNum">      25 </span>            : #include &lt;linux/errno.h&gt;
<span class="lineNum">      26 </span>            : #include &lt;linux/nodemask.h&gt;
<span class="lineNum">      27 </span>            : #include &lt;linux/mm_types.h&gt;
<span class="lineNum">      28 </span>            : #include &lt;linux/preempt_mask.h&gt;
<span class="lineNum">      29 </span>            : 
<span class="lineNum">      30 </span>            : #include &lt;asm/page.h&gt;
<span class="lineNum">      31 </span>            : #include &lt;asm/ptrace.h&gt;
<span class="lineNum">      32 </span>            : #include &lt;linux/cputime.h&gt;
<span class="lineNum">      33 </span>            : 
<span class="lineNum">      34 </span>            : #include &lt;linux/smp.h&gt;
<span class="lineNum">      35 </span>            : #include &lt;linux/sem.h&gt;
<span class="lineNum">      36 </span>            : #include &lt;linux/shm.h&gt;
<span class="lineNum">      37 </span>            : #include &lt;linux/signal.h&gt;
<span class="lineNum">      38 </span>            : #include &lt;linux/compiler.h&gt;
<span class="lineNum">      39 </span>            : #include &lt;linux/completion.h&gt;
<span class="lineNum">      40 </span>            : #include &lt;linux/pid.h&gt;
<span class="lineNum">      41 </span>            : #include &lt;linux/percpu.h&gt;
<span class="lineNum">      42 </span>            : #include &lt;linux/topology.h&gt;
<span class="lineNum">      43 </span>            : #include &lt;linux/proportions.h&gt;
<span class="lineNum">      44 </span>            : #include &lt;linux/seccomp.h&gt;
<span class="lineNum">      45 </span>            : #include &lt;linux/rcupdate.h&gt;
<span class="lineNum">      46 </span>            : #include &lt;linux/rculist.h&gt;
<span class="lineNum">      47 </span>            : #include &lt;linux/rtmutex.h&gt;
<span class="lineNum">      48 </span>            : 
<span class="lineNum">      49 </span>            : #include &lt;linux/time.h&gt;
<span class="lineNum">      50 </span>            : #include &lt;linux/param.h&gt;
<span class="lineNum">      51 </span>            : #include &lt;linux/resource.h&gt;
<span class="lineNum">      52 </span>            : #include &lt;linux/timer.h&gt;
<span class="lineNum">      53 </span>            : #include &lt;linux/hrtimer.h&gt;
<span class="lineNum">      54 </span>            : #include &lt;linux/task_io_accounting.h&gt;
<span class="lineNum">      55 </span>            : #include &lt;linux/latencytop.h&gt;
<span class="lineNum">      56 </span>            : #include &lt;linux/cred.h&gt;
<span class="lineNum">      57 </span>            : #include &lt;linux/llist.h&gt;
<span class="lineNum">      58 </span>            : #include &lt;linux/uidgid.h&gt;
<span class="lineNum">      59 </span>            : #include &lt;linux/gfp.h&gt;
<span class="lineNum">      60 </span>            : 
<span class="lineNum">      61 </span>            : #include &lt;asm/processor.h&gt;
<span class="lineNum">      62 </span>            : 
<span class="lineNum">      63 </span>            : #define SCHED_ATTR_SIZE_VER0    48      /* sizeof first published struct */
<span class="lineNum">      64 </span>            : 
<span class="lineNum">      65 </span>            : /*
<span class="lineNum">      66 </span>            :  * Extended scheduling parameters data structure.
<span class="lineNum">      67 </span>            :  *
<span class="lineNum">      68 </span>            :  * This is needed because the original struct sched_param can not be
<span class="lineNum">      69 </span>            :  * altered without introducing ABI issues with legacy applications
<span class="lineNum">      70 </span>            :  * (e.g., in sched_getparam()).
<span class="lineNum">      71 </span>            :  *
<span class="lineNum">      72 </span>            :  * However, the possibility of specifying more than just a priority for
<span class="lineNum">      73 </span>            :  * the tasks may be useful for a wide variety of application fields, e.g.,
<span class="lineNum">      74 </span>            :  * multimedia, streaming, automation and control, and many others.
<span class="lineNum">      75 </span>            :  *
<span class="lineNum">      76 </span>            :  * This variant (sched_attr) is meant at describing a so-called
<span class="lineNum">      77 </span>            :  * sporadic time-constrained task. In such model a task is specified by:
<span class="lineNum">      78 </span>            :  *  - the activation period or minimum instance inter-arrival time;
<span class="lineNum">      79 </span>            :  *  - the maximum (or average, depending on the actual scheduling
<span class="lineNum">      80 </span>            :  *    discipline) computation time of all instances, a.k.a. runtime;
<span class="lineNum">      81 </span>            :  *  - the deadline (relative to the actual activation time) of each
<span class="lineNum">      82 </span>            :  *    instance.
<span class="lineNum">      83 </span>            :  * Very briefly, a periodic (sporadic) task asks for the execution of
<span class="lineNum">      84 </span>            :  * some specific computation --which is typically called an instance--
<span class="lineNum">      85 </span>            :  * (at most) every period. Moreover, each instance typically lasts no more
<span class="lineNum">      86 </span>            :  * than the runtime and must be completed by time instant t equal to
<span class="lineNum">      87 </span>            :  * the instance activation time + the deadline.
<span class="lineNum">      88 </span>            :  *
<span class="lineNum">      89 </span>            :  * This is reflected by the actual fields of the sched_attr structure:
<span class="lineNum">      90 </span>            :  *
<span class="lineNum">      91 </span>            :  *  @size               size of the structure, for fwd/bwd compat.
<span class="lineNum">      92 </span>            :  *
<span class="lineNum">      93 </span>            :  *  @sched_policy       task's scheduling policy
<span class="lineNum">      94 </span>            :  *  @sched_flags        for customizing the scheduler behaviour
<span class="lineNum">      95 </span>            :  *  @sched_nice         task's nice value      (SCHED_NORMAL/BATCH)
<span class="lineNum">      96 </span>            :  *  @sched_priority     task's static priority (SCHED_FIFO/RR)
<span class="lineNum">      97 </span>            :  *  @sched_deadline     representative of the task's deadline
<span class="lineNum">      98 </span>            :  *  @sched_runtime      representative of the task's runtime
<span class="lineNum">      99 </span>            :  *  @sched_period       representative of the task's period
<span class="lineNum">     100 </span>            :  *
<span class="lineNum">     101 </span>            :  * Given this task model, there are a multiplicity of scheduling algorithms
<span class="lineNum">     102 </span>            :  * and policies, that can be used to ensure all the tasks will make their
<span class="lineNum">     103 </span>            :  * timing constraints.
<span class="lineNum">     104 </span>            :  *
<span class="lineNum">     105 </span>            :  * As of now, the SCHED_DEADLINE policy (sched_dl scheduling class) is the
<span class="lineNum">     106 </span>            :  * only user of this new interface. More information about the algorithm
<span class="lineNum">     107 </span>            :  * available in the scheduling class file or in Documentation/.
<span class="lineNum">     108 </span>            :  */
<span class="lineNum">     109 </span>            : struct sched_attr {
<span class="lineNum">     110 </span>            :         u32 size;
<span class="lineNum">     111 </span>            : 
<span class="lineNum">     112 </span>            :         u32 sched_policy;
<span class="lineNum">     113 </span>            :         u64 sched_flags;
<span class="lineNum">     114 </span>            : 
<span class="lineNum">     115 </span>            :         /* SCHED_NORMAL, SCHED_BATCH */
<span class="lineNum">     116 </span>            :         s32 sched_nice;
<span class="lineNum">     117 </span>            : 
<span class="lineNum">     118 </span>            :         /* SCHED_FIFO, SCHED_RR */
<span class="lineNum">     119 </span>            :         u32 sched_priority;
<span class="lineNum">     120 </span>            : 
<span class="lineNum">     121 </span>            :         /* SCHED_DEADLINE */
<span class="lineNum">     122 </span>            :         u64 sched_runtime;
<span class="lineNum">     123 </span>            :         u64 sched_deadline;
<span class="lineNum">     124 </span>            :         u64 sched_period;
<span class="lineNum">     125 </span>            : };
<span class="lineNum">     126 </span>            : 
<span class="lineNum">     127 </span>            : struct exec_domain;
<span class="lineNum">     128 </span>            : struct futex_pi_state;
<span class="lineNum">     129 </span>            : struct robust_list_head;
<span class="lineNum">     130 </span>            : struct bio_list;
<span class="lineNum">     131 </span>            : struct fs_struct;
<span class="lineNum">     132 </span>            : struct perf_event_context;
<span class="lineNum">     133 </span>            : struct blk_plug;
<span class="lineNum">     134 </span>            : struct filename;
<span class="lineNum">     135 </span>            : 
<span class="lineNum">     136 </span>            : #define VMACACHE_BITS 2
<span class="lineNum">     137 </span>            : #define VMACACHE_SIZE (1U &lt;&lt; VMACACHE_BITS)
<span class="lineNum">     138 </span>            : #define VMACACHE_MASK (VMACACHE_SIZE - 1)
<span class="lineNum">     139 </span>            : 
<span class="lineNum">     140 </span>            : /*
<span class="lineNum">     141 </span>            :  * These are the constant used to fake the fixed-point load-average
<span class="lineNum">     142 </span>            :  * counting. Some notes:
<span class="lineNum">     143 </span>            :  *  - 11 bit fractions expand to 22 bits by the multiplies: this gives
<span class="lineNum">     144 </span>            :  *    a load-average precision of 10 bits integer + 11 bits fractional
<span class="lineNum">     145 </span>            :  *  - if you want to count load-averages more often, you need more
<span class="lineNum">     146 </span>            :  *    precision, or rounding will get you. With 2-second counting freq,
<span class="lineNum">     147 </span>            :  *    the EXP_n values would be 1981, 2034 and 2043 if still using only
<span class="lineNum">     148 </span>            :  *    11 bit fractions.
<span class="lineNum">     149 </span>            :  */
<span class="lineNum">     150 </span>            : extern unsigned long avenrun[];         /* Load averages */
<span class="lineNum">     151 </span>            : extern void get_avenrun(unsigned long *loads, unsigned long offset, int shift);
<span class="lineNum">     152 </span>            : 
<span class="lineNum">     153 </span>            : #define FSHIFT          11              /* nr of bits of precision */
<span class="lineNum">     154 </span>            : #define FIXED_1         (1&lt;&lt;FSHIFT)       /* 1.0 as fixed-point */
<span class="lineNum">     155 </span>            : #define LOAD_FREQ       (5*HZ+1)        /* 5 sec intervals */
<span class="lineNum">     156 </span>            : #define EXP_1           1884            /* 1/exp(5sec/1min) as fixed-point */
<span class="lineNum">     157 </span>            : #define EXP_5           2014            /* 1/exp(5sec/5min) */
<span class="lineNum">     158 </span>            : #define EXP_15          2037            /* 1/exp(5sec/15min) */
<span class="lineNum">     159 </span>            : 
<span class="lineNum">     160 </span>            : #define CALC_LOAD(load,exp,n) \
<span class="lineNum">     161 </span>            :         load *= exp; \
<span class="lineNum">     162 </span>            :         load += n*(FIXED_1-exp); \
<span class="lineNum">     163 </span>            :         load &gt;&gt;= FSHIFT;
<span class="lineNum">     164 </span>            : 
<span class="lineNum">     165 </span>            : extern unsigned long total_forks;
<span class="lineNum">     166 </span>            : extern int nr_threads;
<span class="lineNum">     167 </span>            : DECLARE_PER_CPU(unsigned long, process_counts);
<span class="lineNum">     168 </span>            : extern int nr_processes(void);
<span class="lineNum">     169 </span>            : extern unsigned long nr_running(void);
<span class="lineNum">     170 </span>            : extern unsigned long nr_iowait(void);
<span class="lineNum">     171 </span>            : extern unsigned long nr_iowait_cpu(int cpu);
<span class="lineNum">     172 </span>            : extern void get_iowait_load(unsigned long *nr_waiters, unsigned long *load);
<span class="lineNum">     173 </span>            : 
<span class="lineNum">     174 </span>            : extern void calc_global_load(unsigned long ticks);
<span class="lineNum">     175 </span>            : extern void update_cpu_load_nohz(void);
<span class="lineNum">     176 </span>            : 
<span class="lineNum">     177 </span>            : extern unsigned long get_parent_ip(unsigned long addr);
<span class="lineNum">     178 </span>            : 
<span class="lineNum">     179 </span>            : extern void dump_cpu_task(int cpu);
<span class="lineNum">     180 </span>            : 
<span class="lineNum">     181 </span>            : struct seq_file;
<span class="lineNum">     182 </span>            : struct cfs_rq;
<span class="lineNum">     183 </span>            : struct task_group;
<span class="lineNum">     184 </span>            : #ifdef CONFIG_SCHED_DEBUG
<span class="lineNum">     185 </span>            : extern void proc_sched_show_task(struct task_struct *p, struct seq_file *m);
<span class="lineNum">     186 </span>            : extern void proc_sched_set_task(struct task_struct *p);
<span class="lineNum">     187 </span>            : extern void
<span class="lineNum">     188 </span>            : print_cfs_rq(struct seq_file *m, int cpu, struct cfs_rq *cfs_rq);
<span class="lineNum">     189 </span>            : #endif
<span class="lineNum">     190 </span>            : 
<span class="lineNum">     191 </span>            : /*
<span class="lineNum">     192 </span>            :  * Task state bitmask. NOTE! These bits are also
<span class="lineNum">     193 </span>            :  * encoded in fs/proc/array.c: get_task_state().
<span class="lineNum">     194 </span>            :  *
<span class="lineNum">     195 </span>            :  * We have two separate sets of flags: task-&gt;state
<span class="lineNum">     196 </span>            :  * is about runnability, while task-&gt;exit_state are
<span class="lineNum">     197 </span>            :  * about the task exiting. Confusing, but this way
<span class="lineNum">     198 </span>            :  * modifying one set can't modify the other one by
<span class="lineNum">     199 </span>            :  * mistake.
<span class="lineNum">     200 </span>            :  */
<span class="lineNum">     201 </span>            : #define TASK_RUNNING            0
<span class="lineNum">     202 </span>            : #define TASK_INTERRUPTIBLE      1
<span class="lineNum">     203 </span>            : #define TASK_UNINTERRUPTIBLE    2
<span class="lineNum">     204 </span>            : #define __TASK_STOPPED          4
<span class="lineNum">     205 </span>            : #define __TASK_TRACED           8
<span class="lineNum">     206 </span>            : /* in tsk-&gt;exit_state */
<span class="lineNum">     207 </span>            : #define EXIT_DEAD               16
<span class="lineNum">     208 </span>            : #define EXIT_ZOMBIE             32
<span class="lineNum">     209 </span>            : #define EXIT_TRACE              (EXIT_ZOMBIE | EXIT_DEAD)
<span class="lineNum">     210 </span>            : /* in tsk-&gt;state again */
<span class="lineNum">     211 </span>            : #define TASK_DEAD               64
<span class="lineNum">     212 </span>            : #define TASK_WAKEKILL           128
<span class="lineNum">     213 </span>            : #define TASK_WAKING             256
<span class="lineNum">     214 </span>            : #define TASK_PARKED             512
<span class="lineNum">     215 </span>            : #define TASK_STATE_MAX          1024
<span class="lineNum">     216 </span>            : 
<span class="lineNum">     217 </span>            : #define TASK_STATE_TO_CHAR_STR &quot;RSDTtXZxKWP&quot;
<span class="lineNum">     218 </span>            : 
<span class="lineNum">     219 </span>            : extern char ___assert_task_state[1 - 2*!!(
<span class="lineNum">     220 </span>            :                 sizeof(TASK_STATE_TO_CHAR_STR)-1 != ilog2(TASK_STATE_MAX)+1)];
<span class="lineNum">     221 </span>            : 
<span class="lineNum">     222 </span>            : /* Convenience macros for the sake of set_task_state */
<span class="lineNum">     223 </span>            : #define TASK_KILLABLE           (TASK_WAKEKILL | TASK_UNINTERRUPTIBLE)
<span class="lineNum">     224 </span>            : #define TASK_STOPPED            (TASK_WAKEKILL | __TASK_STOPPED)
<span class="lineNum">     225 </span>            : #define TASK_TRACED             (TASK_WAKEKILL | __TASK_TRACED)
<span class="lineNum">     226 </span>            : 
<span class="lineNum">     227 </span>            : /* Convenience macros for the sake of wake_up */
<span class="lineNum">     228 </span>            : #define TASK_NORMAL             (TASK_INTERRUPTIBLE | TASK_UNINTERRUPTIBLE)
<span class="lineNum">     229 </span>            : #define TASK_ALL                (TASK_NORMAL | __TASK_STOPPED | __TASK_TRACED)
<span class="lineNum">     230 </span>            : 
<span class="lineNum">     231 </span>            : /* get_task_state() */
<span class="lineNum">     232 </span>            : #define TASK_REPORT             (TASK_RUNNING | TASK_INTERRUPTIBLE | \
<span class="lineNum">     233 </span>            :                                  TASK_UNINTERRUPTIBLE | __TASK_STOPPED | \
<span class="lineNum">     234 </span>            :                                  __TASK_TRACED | EXIT_ZOMBIE | EXIT_DEAD)
<span class="lineNum">     235 </span>            : 
<span class="lineNum">     236 </span>            : #define task_is_traced(task)    ((task-&gt;state &amp; __TASK_TRACED) != 0)
<span class="lineNum">     237 </span>            : #define task_is_stopped(task)   ((task-&gt;state &amp; __TASK_STOPPED) != 0)
<span class="lineNum">     238 </span>            : #define task_is_stopped_or_traced(task) \
<span class="lineNum">     239 </span>            :                         ((task-&gt;state &amp; (__TASK_STOPPED | __TASK_TRACED)) != 0)
<span class="lineNum">     240 </span>            : #define task_contributes_to_load(task)  \
<span class="lineNum">     241 </span>            :                                 ((task-&gt;state &amp; TASK_UNINTERRUPTIBLE) != 0 &amp;&amp; \
<span class="lineNum">     242 </span>            :                                  (task-&gt;flags &amp; PF_FROZEN) == 0)
<span class="lineNum">     243 </span>            : 
<span class="lineNum">     244 </span>            : #define __set_task_state(tsk, state_value)              \
<span class="lineNum">     245 </span>            :         do { (tsk)-&gt;state = (state_value); } while (0)
<span class="lineNum">     246 </span>            : #define set_task_state(tsk, state_value)                \
<span class="lineNum">     247 </span>            :         set_mb((tsk)-&gt;state, (state_value))
<span class="lineNum">     248 </span>            : 
<span class="lineNum">     249 </span>            : /*
<span class="lineNum">     250 </span>            :  * set_current_state() includes a barrier so that the write of current-&gt;state
<span class="lineNum">     251 </span>            :  * is correctly serialised wrt the caller's subsequent test of whether to
<span class="lineNum">     252 </span>            :  * actually sleep:
<span class="lineNum">     253 </span>            :  *
<span class="lineNum">     254 </span>            :  *      set_current_state(TASK_UNINTERRUPTIBLE);
<span class="lineNum">     255 </span>            :  *      if (do_i_need_to_sleep())
<span class="lineNum">     256 </span>            :  *              schedule();
<span class="lineNum">     257 </span>            :  *
<span class="lineNum">     258 </span>            :  * If the caller does not need such serialisation then use __set_current_state()
<span class="lineNum">     259 </span>            :  */
<span class="lineNum">     260 </span>            : #define __set_current_state(state_value)                        \
<span class="lineNum">     261 </span>            :         do { current-&gt;state = (state_value); } while (0)
<span class="lineNum">     262 </span>            : #define set_current_state(state_value)          \
<span class="lineNum">     263 </span>            :         set_mb(current-&gt;state, (state_value))
<span class="lineNum">     264 </span>            : 
<span class="lineNum">     265 </span>            : /* Task command name length */
<span class="lineNum">     266 </span>            : #define TASK_COMM_LEN 16
<span class="lineNum">     267 </span>            : 
<span class="lineNum">     268 </span>            : #include &lt;linux/spinlock.h&gt;
<span class="lineNum">     269 </span>            : 
<span class="lineNum">     270 </span>            : /*
<span class="lineNum">     271 </span>            :  * This serializes &quot;schedule()&quot; and also protects
<span class="lineNum">     272 </span>            :  * the run-queue from deletions/modifications (but
<span class="lineNum">     273 </span>            :  * _adding_ to the beginning of the run-queue has
<span class="lineNum">     274 </span>            :  * a separate lock).
<span class="lineNum">     275 </span>            :  */
<span class="lineNum">     276 </span>            : extern rwlock_t tasklist_lock;
<span class="lineNum">     277 </span>            : extern spinlock_t mmlist_lock;
<span class="lineNum">     278 </span>            : 
<span class="lineNum">     279 </span>            : struct task_struct;
<span class="lineNum">     280 </span>            : 
<span class="lineNum">     281 </span>            : #ifdef CONFIG_PROVE_RCU
<span class="lineNum">     282 </span>            : extern int lockdep_tasklist_lock_is_held(void);
<span class="lineNum">     283 </span>            : #endif /* #ifdef CONFIG_PROVE_RCU */
<span class="lineNum">     284 </span>            : 
<span class="lineNum">     285 </span>            : extern void sched_init(void);
<span class="lineNum">     286 </span>            : extern void sched_init_smp(void);
<span class="lineNum">     287 </span>            : extern asmlinkage void schedule_tail(struct task_struct *prev);
<span class="lineNum">     288 </span>            : extern void init_idle(struct task_struct *idle, int cpu);
<span class="lineNum">     289 </span>            : extern void init_idle_bootup_task(struct task_struct *idle);
<span class="lineNum">     290 </span>            : 
<span class="lineNum">     291 </span>            : extern int runqueue_is_locked(int cpu);
<span class="lineNum">     292 </span>            : 
<span class="lineNum">     293 </span>            : #if defined(CONFIG_SMP) &amp;&amp; defined(CONFIG_NO_HZ_COMMON)
<span class="lineNum">     294 </span>            : extern void nohz_balance_enter_idle(int cpu);
<span class="lineNum">     295 </span>            : extern void set_cpu_sd_state_idle(void);
<span class="lineNum">     296 </span>            : extern int get_nohz_timer_target(int pinned);
<span class="lineNum">     297 </span>            : #else
<span class="lineNum">     298 </span>            : static inline void nohz_balance_enter_idle(int cpu) { }
<span class="lineNum">     299 </span>            : static inline void set_cpu_sd_state_idle(void) { }
<span class="lineNum">     300 </span>            : static inline int get_nohz_timer_target(int pinned)
<span class="lineNum">     301 </span>            : {
<span class="lineNum">     302 </span>            :         return smp_processor_id();
<span class="lineNum">     303 </span>            : }
<span class="lineNum">     304 </span>            : #endif
<span class="lineNum">     305 </span>            : 
<span class="lineNum">     306 </span>            : /*
<span class="lineNum">     307 </span>            :  * Only dump TASK_* tasks. (0 for all tasks)
<span class="lineNum">     308 </span>            :  */
<span class="lineNum">     309 </span>            : extern void show_state_filter(unsigned long state_filter);
<span class="lineNum">     310 </span>            : 
<span class="lineNum">     311 </span>            : static inline void show_state(void)
<span class="lineNum">     312 </span>            : {
<span class="lineNum">     313 </span>            :         show_state_filter(0);
<span class="lineNum">     314 </span>            : }
<span class="lineNum">     315 </span>            : 
<span class="lineNum">     316 </span>            : extern void show_regs(struct pt_regs *);
<span class="lineNum">     317 </span>            : 
<span class="lineNum">     318 </span>            : /*
<span class="lineNum">     319 </span>            :  * TASK is a pointer to the task whose backtrace we want to see (or NULL for current
<span class="lineNum">     320 </span>            :  * task), SP is the stack pointer of the first frame that should be shown in the back
<span class="lineNum">     321 </span>            :  * trace (or NULL if the entire call-chain of the task should be shown).
<span class="lineNum">     322 </span>            :  */
<span class="lineNum">     323 </span>            : extern void show_stack(struct task_struct *task, unsigned long *sp);
<span class="lineNum">     324 </span>            : 
<span class="lineNum">     325 </span>            : void io_schedule(void);
<span class="lineNum">     326 </span>            : long io_schedule_timeout(long timeout);
<span class="lineNum">     327 </span>            : 
<span class="lineNum">     328 </span>            : extern void cpu_init (void);
<span class="lineNum">     329 </span>            : extern void trap_init(void);
<span class="lineNum">     330 </span>            : extern void update_process_times(int user);
<span class="lineNum">     331 </span>            : extern void scheduler_tick(void);
<span class="lineNum">     332 </span>            : 
<span class="lineNum">     333 </span>            : extern void sched_show_task(struct task_struct *p);
<span class="lineNum">     334 </span>            : 
<span class="lineNum">     335 </span>            : #ifdef CONFIG_LOCKUP_DETECTOR
<span class="lineNum">     336 </span>            : extern void touch_softlockup_watchdog(void);
<span class="lineNum">     337 </span>            : extern void touch_softlockup_watchdog_sync(void);
<span class="lineNum">     338 </span>            : extern void touch_all_softlockup_watchdogs(void);
<span class="lineNum">     339 </span>            : extern int proc_dowatchdog_thresh(struct ctl_table *table, int write,
<span class="lineNum">     340 </span>            :                                   void __user *buffer,
<span class="lineNum">     341 </span>            :                                   size_t *lenp, loff_t *ppos);
<span class="lineNum">     342 </span>            : extern unsigned int  softlockup_panic;
<span class="lineNum">     343 </span>            : void lockup_detector_init(void);
<span class="lineNum">     344 </span>            : #else
<span class="lineNum">     345 </span>            : static inline void touch_softlockup_watchdog(void)
<span class="lineNum">     346 </span>            : {
<span class="lineNum">     347 </span>            : }
<span class="lineNum">     348 </span>            : static inline void touch_softlockup_watchdog_sync(void)
<span class="lineNum">     349 </span>            : {
<span class="lineNum">     350 </span>            : }
<span class="lineNum">     351 </span>            : static inline void touch_all_softlockup_watchdogs(void)
<span class="lineNum">     352 </span>            : {
<span class="lineNum">     353 </span>            : }
<span class="lineNum">     354 </span>            : static inline void lockup_detector_init(void)
<span class="lineNum">     355 </span>            : {
<span class="lineNum">     356 </span>            : }
<span class="lineNum">     357 </span>            : #endif
<span class="lineNum">     358 </span>            : 
<span class="lineNum">     359 </span>            : #ifdef CONFIG_DETECT_HUNG_TASK
<span class="lineNum">     360 </span>            : void reset_hung_task_detector(void);
<span class="lineNum">     361 </span>            : #else
<span class="lineNum">     362 </span>            : static inline void reset_hung_task_detector(void)
<span class="lineNum">     363 </span>            : {
<span class="lineNum">     364 </span>            : }
<span class="lineNum">     365 </span>            : #endif
<span class="lineNum">     366 </span>            : 
<span class="lineNum">     367 </span>            : /* Attach to any functions which should be ignored in wchan output. */
<span class="lineNum">     368 </span>            : #define __sched         __attribute__((__section__(&quot;.sched.text&quot;)))
<span class="lineNum">     369 </span>            : 
<span class="lineNum">     370 </span>            : /* Linker adds these: start and end of __sched functions */
<span class="lineNum">     371 </span>            : extern char __sched_text_start[], __sched_text_end[];
<span class="lineNum">     372 </span>            : 
<span class="lineNum">     373 </span>            : /* Is this address in the __sched functions? */
<span class="lineNum">     374 </span>            : extern int in_sched_functions(unsigned long addr);
<span class="lineNum">     375 </span>            : 
<span class="lineNum">     376 </span>            : #define MAX_SCHEDULE_TIMEOUT    LONG_MAX
<span class="lineNum">     377 </span>            : extern signed long schedule_timeout(signed long timeout);
<span class="lineNum">     378 </span>            : extern signed long schedule_timeout_interruptible(signed long timeout);
<span class="lineNum">     379 </span>            : extern signed long schedule_timeout_killable(signed long timeout);
<span class="lineNum">     380 </span>            : extern signed long schedule_timeout_uninterruptible(signed long timeout);
<span class="lineNum">     381 </span>            : asmlinkage void schedule(void);
<span class="lineNum">     382 </span>            : extern void schedule_preempt_disabled(void);
<span class="lineNum">     383 </span>            : 
<span class="lineNum">     384 </span>            : struct nsproxy;
<span class="lineNum">     385 </span>            : struct user_namespace;
<span class="lineNum">     386 </span>            : 
<span class="lineNum">     387 </span>            : #ifdef CONFIG_MMU
<span class="lineNum">     388 </span>            : extern void arch_pick_mmap_layout(struct mm_struct *mm);
<span class="lineNum">     389 </span>            : extern unsigned long
<span class="lineNum">     390 </span>            : arch_get_unmapped_area(struct file *, unsigned long, unsigned long,
<span class="lineNum">     391 </span>            :                        unsigned long, unsigned long);
<span class="lineNum">     392 </span>            : extern unsigned long
<span class="lineNum">     393 </span>            : arch_get_unmapped_area_topdown(struct file *filp, unsigned long addr,
<span class="lineNum">     394 </span>            :                           unsigned long len, unsigned long pgoff,
<span class="lineNum">     395 </span>            :                           unsigned long flags);
<span class="lineNum">     396 </span>            : #else
<span class="lineNum">     397 </span>            : static inline void arch_pick_mmap_layout(struct mm_struct *mm) {}
<span class="lineNum">     398 </span>            : #endif
<span class="lineNum">     399 </span>            : 
<span class="lineNum">     400 </span>            : #define SUID_DUMP_DISABLE       0       /* No setuid dumping */
<span class="lineNum">     401 </span>            : #define SUID_DUMP_USER          1       /* Dump as user of process */
<span class="lineNum">     402 </span>            : #define SUID_DUMP_ROOT          2       /* Dump as root */
<span class="lineNum">     403 </span>            : 
<span class="lineNum">     404 </span>            : /* mm flags */
<span class="lineNum">     405 </span>            : 
<span class="lineNum">     406 </span>            : /* for SUID_DUMP_* above */
<span class="lineNum">     407 </span>            : #define MMF_DUMPABLE_BITS 2
<span class="lineNum">     408 </span>            : #define MMF_DUMPABLE_MASK ((1 &lt;&lt; MMF_DUMPABLE_BITS) - 1)
<span class="lineNum">     409 </span>            : 
<span class="lineNum">     410 </span>            : extern void set_dumpable(struct mm_struct *mm, int value);
<span class="lineNum">     411 </span>            : /*
<span class="lineNum">     412 </span>            :  * This returns the actual value of the suid_dumpable flag. For things
<span class="lineNum">     413 </span>            :  * that are using this for checking for privilege transitions, it must
<span class="lineNum">     414 </span>            :  * test against SUID_DUMP_USER rather than treating it as a boolean
<span class="lineNum">     415 </span>            :  * value.
<span class="lineNum">     416 </span>            :  */
<span class="lineNum">     417 </span>            : static inline int __get_dumpable(unsigned long mm_flags)
<span class="lineNum">     418 </span>            : {
<span class="lineNum">     419 </span>            :         return mm_flags &amp; MMF_DUMPABLE_MASK;
<span class="lineNum">     420 </span>            : }
<span class="lineNum">     421 </span>            : 
<span class="lineNum">     422 </span>            : static inline int get_dumpable(struct mm_struct *mm)
<span class="lineNum">     423 </span>            : {
<span class="lineNum">     424 </span>            :         return __get_dumpable(mm-&gt;flags);
<span class="lineNum">     425 </span>            : }
<span class="lineNum">     426 </span>            : 
<span class="lineNum">     427 </span>            : /* coredump filter bits */
<span class="lineNum">     428 </span>            : #define MMF_DUMP_ANON_PRIVATE   2
<span class="lineNum">     429 </span>            : #define MMF_DUMP_ANON_SHARED    3
<span class="lineNum">     430 </span>            : #define MMF_DUMP_MAPPED_PRIVATE 4
<span class="lineNum">     431 </span>            : #define MMF_DUMP_MAPPED_SHARED  5
<span class="lineNum">     432 </span>            : #define MMF_DUMP_ELF_HEADERS    6
<span class="lineNum">     433 </span>            : #define MMF_DUMP_HUGETLB_PRIVATE 7
<span class="lineNum">     434 </span>            : #define MMF_DUMP_HUGETLB_SHARED  8
<span class="lineNum">     435 </span>            : 
<span class="lineNum">     436 </span>            : #define MMF_DUMP_FILTER_SHIFT   MMF_DUMPABLE_BITS
<span class="lineNum">     437 </span>            : #define MMF_DUMP_FILTER_BITS    7
<span class="lineNum">     438 </span>            : #define MMF_DUMP_FILTER_MASK \
<span class="lineNum">     439 </span>            :         (((1 &lt;&lt; MMF_DUMP_FILTER_BITS) - 1) &lt;&lt; MMF_DUMP_FILTER_SHIFT)
<span class="lineNum">     440 </span>            : #define MMF_DUMP_FILTER_DEFAULT \
<span class="lineNum">     441 </span>            :         ((1 &lt;&lt; MMF_DUMP_ANON_PRIVATE) |   (1 &lt;&lt; MMF_DUMP_ANON_SHARED) |\
<span class="lineNum">     442 </span>            :          (1 &lt;&lt; MMF_DUMP_HUGETLB_PRIVATE) | MMF_DUMP_MASK_DEFAULT_ELF)
<span class="lineNum">     443 </span>            : 
<span class="lineNum">     444 </span>            : #ifdef CONFIG_CORE_DUMP_DEFAULT_ELF_HEADERS
<span class="lineNum">     445 </span>            : # define MMF_DUMP_MASK_DEFAULT_ELF      (1 &lt;&lt; MMF_DUMP_ELF_HEADERS)
<span class="lineNum">     446 </span>            : #else
<span class="lineNum">     447 </span>            : # define MMF_DUMP_MASK_DEFAULT_ELF      0
<span class="lineNum">     448 </span>            : #endif
<span class="lineNum">     449 </span>            :                                         /* leave room for more dump flags */
<span class="lineNum">     450 </span>            : #define MMF_VM_MERGEABLE        16      /* KSM may merge identical pages */
<span class="lineNum">     451 </span>            : #define MMF_VM_HUGEPAGE         17      /* set when VM_HUGEPAGE is set on vma */
<span class="lineNum">     452 </span>            : #define MMF_EXE_FILE_CHANGED    18      /* see prctl_set_mm_exe_file() */
<span class="lineNum">     453 </span>            : 
<span class="lineNum">     454 </span>            : #define MMF_HAS_UPROBES         19      /* has uprobes */
<span class="lineNum">     455 </span>            : #define MMF_RECALC_UPROBES      20      /* MMF_HAS_UPROBES can be wrong */
<span class="lineNum">     456 </span>            : 
<span class="lineNum">     457 </span>            : #define MMF_INIT_MASK           (MMF_DUMPABLE_MASK | MMF_DUMP_FILTER_MASK)
<span class="lineNum">     458 </span>            : 
<span class="lineNum">     459 </span>            : struct sighand_struct {
<span class="lineNum">     460 </span>            :         atomic_t                count;
<span class="lineNum">     461 </span>            :         struct k_sigaction      action[_NSIG];
<span class="lineNum">     462 </span>            :         spinlock_t              siglock;
<span class="lineNum">     463 </span>            :         wait_queue_head_t       signalfd_wqh;
<span class="lineNum">     464 </span>            : };
<span class="lineNum">     465 </span>            : 
<span class="lineNum">     466 </span>            : struct pacct_struct {
<span class="lineNum">     467 </span>            :         int                     ac_flag;
<span class="lineNum">     468 </span>            :         long                    ac_exitcode;
<span class="lineNum">     469 </span>            :         unsigned long           ac_mem;
<span class="lineNum">     470 </span>            :         cputime_t               ac_utime, ac_stime;
<span class="lineNum">     471 </span>            :         unsigned long           ac_minflt, ac_majflt;
<span class="lineNum">     472 </span>            : };
<span class="lineNum">     473 </span>            : 
<span class="lineNum">     474 </span>            : struct cpu_itimer {
<span class="lineNum">     475 </span>            :         cputime_t expires;
<span class="lineNum">     476 </span>            :         cputime_t incr;
<span class="lineNum">     477 </span>            :         u32 error;
<span class="lineNum">     478 </span>            :         u32 incr_error;
<span class="lineNum">     479 </span>            : };
<span class="lineNum">     480 </span>            : 
<span class="lineNum">     481 </span>            : /**
<span class="lineNum">     482 </span>            :  * struct cputime - snaphsot of system and user cputime
<span class="lineNum">     483 </span>            :  * @utime: time spent in user mode
<span class="lineNum">     484 </span>            :  * @stime: time spent in system mode
<span class="lineNum">     485 </span>            :  *
<span class="lineNum">     486 </span>            :  * Gathers a generic snapshot of user and system time.
<span class="lineNum">     487 </span>            :  */
<span class="lineNum">     488 </span>            : struct cputime {
<span class="lineNum">     489 </span>            :         cputime_t utime;
<span class="lineNum">     490 </span>            :         cputime_t stime;
<span class="lineNum">     491 </span>            : };
<span class="lineNum">     492 </span>            : 
<span class="lineNum">     493 </span>            : /**
<span class="lineNum">     494 </span>            :  * struct task_cputime - collected CPU time counts
<span class="lineNum">     495 </span>            :  * @utime:              time spent in user mode, in &amp;cputime_t units
<span class="lineNum">     496 </span>            :  * @stime:              time spent in kernel mode, in &amp;cputime_t units
<span class="lineNum">     497 </span>            :  * @sum_exec_runtime:   total time spent on the CPU, in nanoseconds
<span class="lineNum">     498 </span>            :  *
<span class="lineNum">     499 </span>            :  * This is an extension of struct cputime that includes the total runtime
<span class="lineNum">     500 </span>            :  * spent by the task from the scheduler point of view.
<span class="lineNum">     501 </span>            :  *
<span class="lineNum">     502 </span>            :  * As a result, this structure groups together three kinds of CPU time
<span class="lineNum">     503 </span>            :  * that are tracked for threads and thread groups.  Most things considering
<span class="lineNum">     504 </span>            :  * CPU time want to group these counts together and treat all three
<span class="lineNum">     505 </span>            :  * of them in parallel.
<span class="lineNum">     506 </span>            :  */
<span class="lineNum">     507 </span>            : struct task_cputime {
<span class="lineNum">     508 </span>            :         cputime_t utime;
<span class="lineNum">     509 </span>            :         cputime_t stime;
<span class="lineNum">     510 </span>            :         unsigned long long sum_exec_runtime;
<span class="lineNum">     511 </span>            : };
<span class="lineNum">     512 </span>            : /* Alternate field names when used to cache expirations. */
<span class="lineNum">     513 </span>            : #define prof_exp        stime
<span class="lineNum">     514 </span>            : #define virt_exp        utime
<span class="lineNum">     515 </span>            : #define sched_exp       sum_exec_runtime
<span class="lineNum">     516 </span>            : 
<span class="lineNum">     517 </span>            : #define INIT_CPUTIME    \
<span class="lineNum">     518 </span>            :         (struct task_cputime) {                                 \
<span class="lineNum">     519 </span>            :                 .utime = 0,                                     \
<span class="lineNum">     520 </span>            :                 .stime = 0,                                     \
<span class="lineNum">     521 </span>            :                 .sum_exec_runtime = 0,                          \
<span class="lineNum">     522 </span>            :         }
<span class="lineNum">     523 </span>            : 
<span class="lineNum">     524 </span>            : #ifdef CONFIG_PREEMPT_COUNT
<span class="lineNum">     525 </span>            : #define PREEMPT_DISABLED        (1 + PREEMPT_ENABLED)
<span class="lineNum">     526 </span>            : #else
<span class="lineNum">     527 </span>            : #define PREEMPT_DISABLED        PREEMPT_ENABLED
<span class="lineNum">     528 </span>            : #endif
<span class="lineNum">     529 </span>            : 
<span class="lineNum">     530 </span>            : /*
<span class="lineNum">     531 </span>            :  * Disable preemption until the scheduler is running.
<span class="lineNum">     532 </span>            :  * Reset by start_kernel()-&gt;sched_init()-&gt;init_idle().
<span class="lineNum">     533 </span>            :  *
<span class="lineNum">     534 </span>            :  * We include PREEMPT_ACTIVE to avoid cond_resched() from working
<span class="lineNum">     535 </span>            :  * before the scheduler is active -- see should_resched().
<span class="lineNum">     536 </span>            :  */
<span class="lineNum">     537 </span>            : #define INIT_PREEMPT_COUNT      (PREEMPT_DISABLED + PREEMPT_ACTIVE)
<span class="lineNum">     538 </span>            : 
<span class="lineNum">     539 </span>            : /**
<span class="lineNum">     540 </span>            :  * struct thread_group_cputimer - thread group interval timer counts
<span class="lineNum">     541 </span>            :  * @cputime:            thread group interval timers.
<span class="lineNum">     542 </span>            :  * @running:            non-zero when there are timers running and
<span class="lineNum">     543 </span>            :  *                      @cputime receives updates.
<span class="lineNum">     544 </span>            :  * @lock:               lock for fields in this struct.
<span class="lineNum">     545 </span>            :  *
<span class="lineNum">     546 </span>            :  * This structure contains the version of task_cputime, above, that is
<span class="lineNum">     547 </span>            :  * used for thread group CPU timer calculations.
<span class="lineNum">     548 </span>            :  */
<span class="lineNum">     549 </span>            : struct thread_group_cputimer {
<span class="lineNum">     550 </span>            :         struct task_cputime cputime;
<span class="lineNum">     551 </span>            :         int running;
<span class="lineNum">     552 </span>            :         raw_spinlock_t lock;
<span class="lineNum">     553 </span>            : };
<span class="lineNum">     554 </span>            : 
<span class="lineNum">     555 </span>            : #include &lt;linux/rwsem.h&gt;
<span class="lineNum">     556 </span>            : struct autogroup;
<span class="lineNum">     557 </span>            : 
<span class="lineNum">     558 </span>            : /*
<span class="lineNum">     559 </span>            :  * NOTE! &quot;signal_struct&quot; does not have its own
<span class="lineNum">     560 </span>            :  * locking, because a shared signal_struct always
<span class="lineNum">     561 </span>            :  * implies a shared sighand_struct, so locking
<span class="lineNum">     562 </span>            :  * sighand_struct is always a proper superset of
<span class="lineNum">     563 </span>            :  * the locking of signal_struct.
<span class="lineNum">     564 </span>            :  */
<span class="lineNum">     565 </span>            : struct signal_struct {
<span class="lineNum">     566 </span>            :         atomic_t                sigcnt;
<span class="lineNum">     567 </span>            :         atomic_t                live;
<span class="lineNum">     568 </span>            :         int                     nr_threads;
<span class="lineNum">     569 </span>            :         struct list_head        thread_head;
<span class="lineNum">     570 </span>            : 
<span class="lineNum">     571 </span>            :         wait_queue_head_t       wait_chldexit;  /* for wait4() */
<span class="lineNum">     572 </span>            : 
<span class="lineNum">     573 </span>            :         /* current thread group signal load-balancing target: */
<span class="lineNum">     574 </span>            :         struct task_struct      *curr_target;
<span class="lineNum">     575 </span>            : 
<span class="lineNum">     576 </span>            :         /* shared signal handling: */
<span class="lineNum">     577 </span>            :         struct sigpending       shared_pending;
<span class="lineNum">     578 </span>            : 
<span class="lineNum">     579 </span>            :         /* thread group exit support */
<span class="lineNum">     580 </span>            :         int                     group_exit_code;
<span class="lineNum">     581 </span>            :         /* overloaded:
<span class="lineNum">     582 </span>            :          * - notify group_exit_task when -&gt;count is equal to notify_count
<span class="lineNum">     583 </span>            :          * - everyone except group_exit_task is stopped during signal delivery
<span class="lineNum">     584 </span>            :          *   of fatal signals, group_exit_task processes the signal.
<span class="lineNum">     585 </span>            :          */
<span class="lineNum">     586 </span>            :         int                     notify_count;
<span class="lineNum">     587 </span>            :         struct task_struct      *group_exit_task;
<span class="lineNum">     588 </span>            : 
<span class="lineNum">     589 </span>            :         /* thread group stop support, overloads group_exit_code too */
<span class="lineNum">     590 </span>            :         int                     group_stop_count;
<span class="lineNum">     591 </span>            :         unsigned int            flags; /* see SIGNAL_* flags below */
<span class="lineNum">     592 </span>            : 
<span class="lineNum">     593 </span>            :         /*
<span class="lineNum">     594 </span>            :          * PR_SET_CHILD_SUBREAPER marks a process, like a service
<span class="lineNum">     595 </span>            :          * manager, to re-parent orphan (double-forking) child processes
<span class="lineNum">     596 </span>            :          * to this process instead of 'init'. The service manager is
<span class="lineNum">     597 </span>            :          * able to receive SIGCHLD signals and is able to investigate
<span class="lineNum">     598 </span>            :          * the process until it calls wait(). All children of this
<span class="lineNum">     599 </span>            :          * process will inherit a flag if they should look for a
<span class="lineNum">     600 </span>            :          * child_subreaper process at exit.
<span class="lineNum">     601 </span>            :          */
<span class="lineNum">     602 </span>            :         unsigned int            is_child_subreaper:1;
<span class="lineNum">     603 </span>            :         unsigned int            has_child_subreaper:1;
<span class="lineNum">     604 </span>            : 
<span class="lineNum">     605 </span>            :         /* POSIX.1b Interval Timers */
<span class="lineNum">     606 </span>            :         int                     posix_timer_id;
<span class="lineNum">     607 </span>            :         struct list_head        posix_timers;
<span class="lineNum">     608 </span>            : 
<span class="lineNum">     609 </span>            :         /* ITIMER_REAL timer for the process */
<span class="lineNum">     610 </span>            :         struct hrtimer real_timer;
<span class="lineNum">     611 </span>            :         struct pid *leader_pid;
<span class="lineNum">     612 </span>            :         ktime_t it_real_incr;
<span class="lineNum">     613 </span>            : 
<span class="lineNum">     614 </span>            :         /*
<span class="lineNum">     615 </span>            :          * ITIMER_PROF and ITIMER_VIRTUAL timers for the process, we use
<span class="lineNum">     616 </span>            :          * CPUCLOCK_PROF and CPUCLOCK_VIRT for indexing array as these
<span class="lineNum">     617 </span>            :          * values are defined to 0 and 1 respectively
<span class="lineNum">     618 </span>            :          */
<span class="lineNum">     619 </span>            :         struct cpu_itimer it[2];
<span class="lineNum">     620 </span>            : 
<span class="lineNum">     621 </span>            :         /*
<span class="lineNum">     622 </span>            :          * Thread group totals for process CPU timers.
<span class="lineNum">     623 </span>            :          * See thread_group_cputimer(), et al, for details.
<span class="lineNum">     624 </span>            :          */
<span class="lineNum">     625 </span>            :         struct thread_group_cputimer cputimer;
<span class="lineNum">     626 </span>            : 
<span class="lineNum">     627 </span>            :         /* Earliest-expiration cache. */
<span class="lineNum">     628 </span>            :         struct task_cputime cputime_expires;
<span class="lineNum">     629 </span>            : 
<span class="lineNum">     630 </span>            :         struct list_head cpu_timers[3];
<span class="lineNum">     631 </span>            : 
<span class="lineNum">     632 </span>            :         struct pid *tty_old_pgrp;
<span class="lineNum">     633 </span>            : 
<span class="lineNum">     634 </span>            :         /* boolean value for session group leader */
<span class="lineNum">     635 </span>            :         int leader;
<span class="lineNum">     636 </span>            : 
<span class="lineNum">     637 </span>            :         struct tty_struct *tty; /* NULL if no tty */
<span class="lineNum">     638 </span>            : 
<span class="lineNum">     639 </span>            : #ifdef CONFIG_SCHED_AUTOGROUP
<span class="lineNum">     640 </span>            :         struct autogroup *autogroup;
<span class="lineNum">     641 </span>            : #endif
<span class="lineNum">     642 </span>            :         /*
<span class="lineNum">     643 </span>            :          * Cumulative resource counters for dead threads in the group,
<span class="lineNum">     644 </span>            :          * and for reaped dead child processes forked by this group.
<span class="lineNum">     645 </span>            :          * Live threads maintain their own counters and add to these
<span class="lineNum">     646 </span>            :          * in __exit_signal, except for the group leader.
<span class="lineNum">     647 </span>            :          */
<span class="lineNum">     648 </span>            :         cputime_t utime, stime, cutime, cstime;
<span class="lineNum">     649 </span>            :         cputime_t gtime;
<span class="lineNum">     650 </span>            :         cputime_t cgtime;
<span class="lineNum">     651 </span>            : #ifndef CONFIG_VIRT_CPU_ACCOUNTING_NATIVE
<span class="lineNum">     652 </span>            :         struct cputime prev_cputime;
<span class="lineNum">     653 </span>            : #endif
<span class="lineNum">     654 </span>            :         unsigned long nvcsw, nivcsw, cnvcsw, cnivcsw;
<span class="lineNum">     655 </span>            :         unsigned long min_flt, maj_flt, cmin_flt, cmaj_flt;
<span class="lineNum">     656 </span>            :         unsigned long inblock, oublock, cinblock, coublock;
<span class="lineNum">     657 </span>            :         unsigned long maxrss, cmaxrss;
<span class="lineNum">     658 </span>            :         struct task_io_accounting ioac;
<span class="lineNum">     659 </span>            : 
<span class="lineNum">     660 </span>            :         /*
<span class="lineNum">     661 </span>            :          * Cumulative ns of schedule CPU time fo dead threads in the
<span class="lineNum">     662 </span>            :          * group, not including a zombie group leader, (This only differs
<span class="lineNum">     663 </span>            :          * from jiffies_to_ns(utime + stime) if sched_clock uses something
<span class="lineNum">     664 </span>            :          * other than jiffies.)
<span class="lineNum">     665 </span>            :          */
<span class="lineNum">     666 </span>            :         unsigned long long sum_sched_runtime;
<span class="lineNum">     667 </span>            : 
<span class="lineNum">     668 </span>            :         /*
<span class="lineNum">     669 </span>            :          * We don't bother to synchronize most readers of this at all,
<span class="lineNum">     670 </span>            :          * because there is no reader checking a limit that actually needs
<span class="lineNum">     671 </span>            :          * to get both rlim_cur and rlim_max atomically, and either one
<span class="lineNum">     672 </span>            :          * alone is a single word that can safely be read normally.
<span class="lineNum">     673 </span>            :          * getrlimit/setrlimit use task_lock(current-&gt;group_leader) to
<span class="lineNum">     674 </span>            :          * protect this instead of the siglock, because they really
<span class="lineNum">     675 </span>            :          * have no need to disable irqs.
<span class="lineNum">     676 </span>            :          */
<span class="lineNum">     677 </span>            :         struct rlimit rlim[RLIM_NLIMITS];
<span class="lineNum">     678 </span>            : 
<span class="lineNum">     679 </span>            : #ifdef CONFIG_BSD_PROCESS_ACCT
<span class="lineNum">     680 </span>            :         struct pacct_struct pacct;      /* per-process accounting information */
<span class="lineNum">     681 </span>            : #endif
<span class="lineNum">     682 </span>            : #ifdef CONFIG_TASKSTATS
<span class="lineNum">     683 </span>            :         struct taskstats *stats;
<span class="lineNum">     684 </span>            : #endif
<span class="lineNum">     685 </span>            : #ifdef CONFIG_AUDIT
<span class="lineNum">     686 </span>            :         unsigned audit_tty;
<span class="lineNum">     687 </span>            :         unsigned audit_tty_log_passwd;
<span class="lineNum">     688 </span>            :         struct tty_audit_buf *tty_audit_buf;
<span class="lineNum">     689 </span>            : #endif
<span class="lineNum">     690 </span>            : #ifdef CONFIG_CGROUPS
<span class="lineNum">     691 </span>            :         /*
<span class="lineNum">     692 </span>            :          * group_rwsem prevents new tasks from entering the threadgroup and
<span class="lineNum">     693 </span>            :          * member tasks from exiting,a more specifically, setting of
<span class="lineNum">     694 </span>            :          * PF_EXITING.  fork and exit paths are protected with this rwsem
<span class="lineNum">     695 </span>            :          * using threadgroup_change_begin/end().  Users which require
<span class="lineNum">     696 </span>            :          * threadgroup to remain stable should use threadgroup_[un]lock()
<span class="lineNum">     697 </span>            :          * which also takes care of exec path.  Currently, cgroup is the
<span class="lineNum">     698 </span>            :          * only user.
<span class="lineNum">     699 </span>            :          */
<span class="lineNum">     700 </span>            :         struct rw_semaphore group_rwsem;
<span class="lineNum">     701 </span>            : #endif
<span class="lineNum">     702 </span>            : 
<span class="lineNum">     703 </span>            :         oom_flags_t oom_flags;
<span class="lineNum">     704 </span>            :         short oom_score_adj;            /* OOM kill score adjustment */
<span class="lineNum">     705 </span>            :         short oom_score_adj_min;        /* OOM kill score adjustment min value.
<span class="lineNum">     706 </span>            :                                          * Only settable by CAP_SYS_RESOURCE. */
<span class="lineNum">     707 </span>            : 
<span class="lineNum">     708 </span>            :         struct mutex cred_guard_mutex;  /* guard against foreign influences on
<span class="lineNum">     709 </span>            :                                          * credential calculations
<span class="lineNum">     710 </span>            :                                          * (notably. ptrace) */
<span class="lineNum">     711 </span>            : };
<span class="lineNum">     712 </span>            : 
<span class="lineNum">     713 </span>            : /*
<span class="lineNum">     714 </span>            :  * Bits in flags field of signal_struct.
<span class="lineNum">     715 </span>            :  */
<span class="lineNum">     716 </span>            : #define SIGNAL_STOP_STOPPED     0x00000001 /* job control stop in effect */
<span class="lineNum">     717 </span>            : #define SIGNAL_STOP_CONTINUED   0x00000002 /* SIGCONT since WCONTINUED reap */
<span class="lineNum">     718 </span>            : #define SIGNAL_GROUP_EXIT       0x00000004 /* group exit in progress */
<span class="lineNum">     719 </span>            : #define SIGNAL_GROUP_COREDUMP   0x00000008 /* coredump in progress */
<span class="lineNum">     720 </span>            : /*
<span class="lineNum">     721 </span>            :  * Pending notifications to parent.
<span class="lineNum">     722 </span>            :  */
<span class="lineNum">     723 </span>            : #define SIGNAL_CLD_STOPPED      0x00000010
<span class="lineNum">     724 </span>            : #define SIGNAL_CLD_CONTINUED    0x00000020
<span class="lineNum">     725 </span>            : #define SIGNAL_CLD_MASK         (SIGNAL_CLD_STOPPED|SIGNAL_CLD_CONTINUED)
<span class="lineNum">     726 </span>            : 
<span class="lineNum">     727 </span>            : #define SIGNAL_UNKILLABLE       0x00000040 /* for init: ignore fatal signals */
<span class="lineNum">     728 </span>            : 
<span class="lineNum">     729 </span>            : /* If true, all threads except -&gt;group_exit_task have pending SIGKILL */
<span class="lineNum">     730 </span>            : static inline int signal_group_exit(const struct signal_struct *sig)
<span class="lineNum">     731 </span>            : {
<span class="lineNum">     732 </span>            :         return  (sig-&gt;flags &amp; SIGNAL_GROUP_EXIT) ||
<span class="lineNum">     733 </span>            :                 (sig-&gt;group_exit_task != NULL);
<span class="lineNum">     734 </span>            : }
<span class="lineNum">     735 </span>            : 
<span class="lineNum">     736 </span>            : /*
<span class="lineNum">     737 </span>            :  * Some day this will be a full-fledged user tracking system..
<span class="lineNum">     738 </span>            :  */
<span class="lineNum">     739 </span>            : struct user_struct {
<span class="lineNum">     740 </span>            :         atomic_t __count;       /* reference count */
<span class="lineNum">     741 </span>            :         atomic_t processes;     /* How many processes does this user have? */
<span class="lineNum">     742 </span>            :         atomic_t sigpending;    /* How many pending signals does this user have? */
<span class="lineNum">     743 </span>            : #ifdef CONFIG_INOTIFY_USER
<span class="lineNum">     744 </span>            :         atomic_t inotify_watches; /* How many inotify watches does this user have? */
<span class="lineNum">     745 </span>            :         atomic_t inotify_devs;  /* How many inotify devs does this user have opened? */
<span class="lineNum">     746 </span>            : #endif
<span class="lineNum">     747 </span>            : #ifdef CONFIG_FANOTIFY
<span class="lineNum">     748 </span>            :         atomic_t fanotify_listeners;
<span class="lineNum">     749 </span>            : #endif
<span class="lineNum">     750 </span>            : #ifdef CONFIG_EPOLL
<span class="lineNum">     751 </span>            :         atomic_long_t epoll_watches; /* The number of file descriptors currently watched */
<span class="lineNum">     752 </span>            : #endif
<span class="lineNum">     753 </span>            : #ifdef CONFIG_POSIX_MQUEUE
<span class="lineNum">     754 </span>            :         /* protected by mq_lock */
<span class="lineNum">     755 </span>            :         unsigned long mq_bytes; /* How many bytes can be allocated to mqueue? */
<span class="lineNum">     756 </span>            : #endif
<span class="lineNum">     757 </span>            :         unsigned long locked_shm; /* How many pages of mlocked shm ? */
<span class="lineNum">     758 </span>            : 
<span class="lineNum">     759 </span>            : #ifdef CONFIG_KEYS
<span class="lineNum">     760 </span>            :         struct key *uid_keyring;        /* UID specific keyring */
<span class="lineNum">     761 </span>            :         struct key *session_keyring;    /* UID's default session keyring */
<span class="lineNum">     762 </span>            : #endif
<span class="lineNum">     763 </span>            : 
<span class="lineNum">     764 </span>            :         /* Hash table maintenance information */
<span class="lineNum">     765 </span>            :         struct hlist_node uidhash_node;
<span class="lineNum">     766 </span>            :         kuid_t uid;
<span class="lineNum">     767 </span>            : 
<span class="lineNum">     768 </span>            : #ifdef CONFIG_PERF_EVENTS
<span class="lineNum">     769 </span>            :         atomic_long_t locked_vm;
<span class="lineNum">     770 </span>            : #endif
<span class="lineNum">     771 </span>            : };
<span class="lineNum">     772 </span>            : 
<span class="lineNum">     773 </span>            : extern int uids_sysfs_init(void);
<span class="lineNum">     774 </span>            : 
<span class="lineNum">     775 </span>            : extern struct user_struct *find_user(kuid_t);
<span class="lineNum">     776 </span>            : 
<span class="lineNum">     777 </span>            : extern struct user_struct root_user;
<span class="lineNum">     778 </span>            : #define INIT_USER (&amp;root_user)
<span class="lineNum">     779 </span>            : 
<span class="lineNum">     780 </span>            : 
<span class="lineNum">     781 </span>            : struct backing_dev_info;
<span class="lineNum">     782 </span>            : struct reclaim_state;
<span class="lineNum">     783 </span>            : 
<span class="lineNum">     784 </span>            : #if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
<span class="lineNum">     785 </span>            : struct sched_info {
<span class="lineNum">     786 </span>            :         /* cumulative counters */
<span class="lineNum">     787 </span>            :         unsigned long pcount;         /* # of times run on this cpu */
<span class="lineNum">     788 </span>            :         unsigned long long run_delay; /* time spent waiting on a runqueue */
<span class="lineNum">     789 </span>            : 
<span class="lineNum">     790 </span>            :         /* timestamps */
<span class="lineNum">     791 </span>            :         unsigned long long last_arrival,/* when we last ran on a cpu */
<span class="lineNum">     792 </span>            :                            last_queued; /* when we were last queued to run */
<span class="lineNum">     793 </span>            : };
<span class="lineNum">     794 </span>            : #endif /* defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT) */
<span class="lineNum">     795 </span>            : 
<span class="lineNum">     796 </span>            : #ifdef CONFIG_TASK_DELAY_ACCT
<span class="lineNum">     797 </span>            : struct task_delay_info {
<span class="lineNum">     798 </span>            :         spinlock_t      lock;
<span class="lineNum">     799 </span>            :         unsigned int    flags;  /* Private per-task flags */
<span class="lineNum">     800 </span>            : 
<span class="lineNum">     801 </span>            :         /* For each stat XXX, add following, aligned appropriately
<span class="lineNum">     802 </span>            :          *
<span class="lineNum">     803 </span>            :          * struct timespec XXX_start, XXX_end;
<span class="lineNum">     804 </span>            :          * u64 XXX_delay;
<span class="lineNum">     805 </span>            :          * u32 XXX_count;
<span class="lineNum">     806 </span>            :          *
<span class="lineNum">     807 </span>            :          * Atomicity of updates to XXX_delay, XXX_count protected by
<span class="lineNum">     808 </span>            :          * single lock above (split into XXX_lock if contention is an issue).
<span class="lineNum">     809 </span>            :          */
<span class="lineNum">     810 </span>            : 
<span class="lineNum">     811 </span>            :         /*
<span class="lineNum">     812 </span>            :          * XXX_count is incremented on every XXX operation, the delay
<span class="lineNum">     813 </span>            :          * associated with the operation is added to XXX_delay.
<span class="lineNum">     814 </span>            :          * XXX_delay contains the accumulated delay time in nanoseconds.
<span class="lineNum">     815 </span>            :          */
<span class="lineNum">     816 </span>            :         u64 blkio_start;        /* Shared by blkio, swapin */
<span class="lineNum">     817 </span>            :         u64 blkio_delay;        /* wait for sync block io completion */
<span class="lineNum">     818 </span>            :         u64 swapin_delay;       /* wait for swapin block io completion */
<span class="lineNum">     819 </span>            :         u32 blkio_count;        /* total count of the number of sync block */
<span class="lineNum">     820 </span>            :                                 /* io operations performed */
<span class="lineNum">     821 </span>            :         u32 swapin_count;       /* total count of the number of swapin block */
<span class="lineNum">     822 </span>            :                                 /* io operations performed */
<span class="lineNum">     823 </span>            : 
<span class="lineNum">     824 </span>            :         u64 freepages_start;
<span class="lineNum">     825 </span>            :         u64 freepages_delay;    /* wait for memory reclaim */
<span class="lineNum">     826 </span>            :         u32 freepages_count;    /* total count of memory reclaim */
<span class="lineNum">     827 </span>            : };
<span class="lineNum">     828 </span>            : #endif  /* CONFIG_TASK_DELAY_ACCT */
<span class="lineNum">     829 </span>            : 
<span class="lineNum">     830 </span>            : static inline int sched_info_on(void)
<span class="lineNum">     831 </span>            : {
<span class="lineNum">     832 </span>            : #ifdef CONFIG_SCHEDSTATS
<span class="lineNum">     833 </span>            :         return 1;
<span class="lineNum">     834 </span>            : #elif defined(CONFIG_TASK_DELAY_ACCT)
<span class="lineNum">     835 </span>            :         extern int delayacct_on;
<span class="lineNum">     836 </span>            :         return delayacct_on;
<span class="lineNum">     837 </span>            : #else
<span class="lineNum">     838 </span>            :         return 0;
<span class="lineNum">     839 </span>            : #endif
<span class="lineNum">     840 </span>            : }
<span class="lineNum">     841 </span>            : 
<span class="lineNum">     842 </span>            : enum cpu_idle_type {
<span class="lineNum">     843 </span>            :         CPU_IDLE,
<span class="lineNum">     844 </span>            :         CPU_NOT_IDLE,
<span class="lineNum">     845 </span>            :         CPU_NEWLY_IDLE,
<span class="lineNum">     846 </span>            :         CPU_MAX_IDLE_TYPES
<span class="lineNum">     847 </span>            : };
<span class="lineNum">     848 </span>            : 
<span class="lineNum">     849 </span>            : /*
<span class="lineNum">     850 </span>            :  * Increase resolution of cpu_capacity calculations
<span class="lineNum">     851 </span>            :  */
<span class="lineNum">     852 </span>            : #define SCHED_CAPACITY_SHIFT    10
<span class="lineNum">     853 </span>            : #define SCHED_CAPACITY_SCALE    (1L &lt;&lt; SCHED_CAPACITY_SHIFT)
<span class="lineNum">     854 </span>            : 
<span class="lineNum">     855 </span>            : /*
<span class="lineNum">     856 </span>            :  * sched-domains (multiprocessor balancing) declarations:
<span class="lineNum">     857 </span>            :  */
<span class="lineNum">     858 </span>            : #ifdef CONFIG_SMP
<span class="lineNum">     859 </span>            : #define SD_LOAD_BALANCE         0x0001  /* Do load balancing on this domain. */
<span class="lineNum">     860 </span>            : #define SD_BALANCE_NEWIDLE      0x0002  /* Balance when about to become idle */
<span class="lineNum">     861 </span>            : #define SD_BALANCE_EXEC         0x0004  /* Balance on exec */
<span class="lineNum">     862 </span>            : #define SD_BALANCE_FORK         0x0008  /* Balance on fork, clone */
<span class="lineNum">     863 </span>            : #define SD_BALANCE_WAKE         0x0010  /* Balance on wakeup */
<span class="lineNum">     864 </span>            : #define SD_WAKE_AFFINE          0x0020  /* Wake task to waking CPU */
<span class="lineNum">     865 </span>            : #define SD_SHARE_CPUCAPACITY    0x0080  /* Domain members share cpu power */
<span class="lineNum">     866 </span>            : #define SD_SHARE_POWERDOMAIN    0x0100  /* Domain members share power domain */
<span class="lineNum">     867 </span>            : #define SD_SHARE_PKG_RESOURCES  0x0200  /* Domain members share cpu pkg resources */
<span class="lineNum">     868 </span>            : #define SD_SERIALIZE            0x0400  /* Only a single load balancing instance */
<span class="lineNum">     869 </span>            : #define SD_ASYM_PACKING         0x0800  /* Place busy groups earlier in the domain */
<span class="lineNum">     870 </span>            : #define SD_PREFER_SIBLING       0x1000  /* Prefer to place tasks in a sibling domain */
<span class="lineNum">     871 </span>            : #define SD_OVERLAP              0x2000  /* sched_domains of this level overlap */
<span class="lineNum">     872 </span>            : #define SD_NUMA                 0x4000  /* cross-node balancing */
<span class="lineNum">     873 </span>            : 
<span class="lineNum">     874 </span>            : #ifdef CONFIG_SCHED_SMT
<span class="lineNum">     875 </span>            : static inline int cpu_smt_flags(void)
<span class="lineNum">     876 </span>            : {
<span class="lineNum">     877 </span>            :         return SD_SHARE_CPUCAPACITY | SD_SHARE_PKG_RESOURCES;
<span class="lineNum">     878 </span>            : }
<span class="lineNum">     879 </span>            : #endif
<span class="lineNum">     880 </span>            : 
<span class="lineNum">     881 </span>            : #ifdef CONFIG_SCHED_MC
<span class="lineNum">     882 </span>            : static inline int cpu_core_flags(void)
<span class="lineNum">     883 </span>            : {
<span class="lineNum">     884 </span>            :         return SD_SHARE_PKG_RESOURCES;
<span class="lineNum">     885 </span>            : }
<span class="lineNum">     886 </span>            : #endif
<span class="lineNum">     887 </span>            : 
<span class="lineNum">     888 </span>            : #ifdef CONFIG_NUMA
<span class="lineNum">     889 </span>            : static inline int cpu_numa_flags(void)
<span class="lineNum">     890 </span>            : {
<span class="lineNum">     891 </span>            :         return SD_NUMA;
<span class="lineNum">     892 </span>            : }
<span class="lineNum">     893 </span>            : #endif
<span class="lineNum">     894 </span>            : 
<span class="lineNum">     895 </span>            : struct sched_domain_attr {
<span class="lineNum">     896 </span>            :         int relax_domain_level;
<span class="lineNum">     897 </span>            : };
<span class="lineNum">     898 </span>            : 
<span class="lineNum">     899 </span>            : #define SD_ATTR_INIT    (struct sched_domain_attr) {    \
<span class="lineNum">     900 </span>            :         .relax_domain_level = -1,                       \
<span class="lineNum">     901 </span>            : }
<span class="lineNum">     902 </span>            : 
<span class="lineNum">     903 </span>            : extern int sched_domain_level_max;
<span class="lineNum">     904 </span>            : 
<span class="lineNum">     905 </span>            : struct sched_group;
<span class="lineNum">     906 </span>            : 
<span class="lineNum">     907 </span>            : struct sched_domain {
<span class="lineNum">     908 </span>            :         /* These fields must be setup */
<span class="lineNum">     909 </span>            :         struct sched_domain *parent;    /* top domain must be null terminated */
<span class="lineNum">     910 </span>            :         struct sched_domain *child;     /* bottom domain must be null terminated */
<span class="lineNum">     911 </span>            :         struct sched_group *groups;     /* the balancing groups of the domain */
<span class="lineNum">     912 </span>            :         unsigned long min_interval;     /* Minimum balance interval ms */
<span class="lineNum">     913 </span>            :         unsigned long max_interval;     /* Maximum balance interval ms */
<span class="lineNum">     914 </span>            :         unsigned int busy_factor;       /* less balancing by factor if busy */
<span class="lineNum">     915 </span>            :         unsigned int imbalance_pct;     /* No balance until over watermark */
<span class="lineNum">     916 </span>            :         unsigned int cache_nice_tries;  /* Leave cache hot tasks for # tries */
<span class="lineNum">     917 </span>            :         unsigned int busy_idx;
<span class="lineNum">     918 </span>            :         unsigned int idle_idx;
<span class="lineNum">     919 </span>            :         unsigned int newidle_idx;
<span class="lineNum">     920 </span>            :         unsigned int wake_idx;
<span class="lineNum">     921 </span>            :         unsigned int forkexec_idx;
<span class="lineNum">     922 </span>            :         unsigned int smt_gain;
<span class="lineNum">     923 </span>            : 
<span class="lineNum">     924 </span>            :         int nohz_idle;                  /* NOHZ IDLE status */
<span class="lineNum">     925 </span>            :         int flags;                      /* See SD_* */
<span class="lineNum">     926 </span>            :         int level;
<span class="lineNum">     927 </span>            : 
<span class="lineNum">     928 </span>            :         /* Runtime fields. */
<span class="lineNum">     929 </span>            :         unsigned long last_balance;     /* init to jiffies. units in jiffies */
<span class="lineNum">     930 </span>            :         unsigned int balance_interval;  /* initialise to 1. units in ms. */
<span class="lineNum">     931 </span>            :         unsigned int nr_balance_failed; /* initialise to 0 */
<span class="lineNum">     932 </span>            : 
<span class="lineNum">     933 </span>            :         /* idle_balance() stats */
<span class="lineNum">     934 </span>            :         u64 max_newidle_lb_cost;
<span class="lineNum">     935 </span>            :         unsigned long next_decay_max_lb_cost;
<span class="lineNum">     936 </span>            : 
<span class="lineNum">     937 </span>            : #ifdef CONFIG_SCHEDSTATS
<span class="lineNum">     938 </span>            :         /* load_balance() stats */
<span class="lineNum">     939 </span>            :         unsigned int lb_count[CPU_MAX_IDLE_TYPES];
<span class="lineNum">     940 </span>            :         unsigned int lb_failed[CPU_MAX_IDLE_TYPES];
<span class="lineNum">     941 </span>            :         unsigned int lb_balanced[CPU_MAX_IDLE_TYPES];
<span class="lineNum">     942 </span>            :         unsigned int lb_imbalance[CPU_MAX_IDLE_TYPES];
<span class="lineNum">     943 </span>            :         unsigned int lb_gained[CPU_MAX_IDLE_TYPES];
<span class="lineNum">     944 </span>            :         unsigned int lb_hot_gained[CPU_MAX_IDLE_TYPES];
<span class="lineNum">     945 </span>            :         unsigned int lb_nobusyg[CPU_MAX_IDLE_TYPES];
<span class="lineNum">     946 </span>            :         unsigned int lb_nobusyq[CPU_MAX_IDLE_TYPES];
<span class="lineNum">     947 </span>            : 
<span class="lineNum">     948 </span>            :         /* Active load balancing */
<span class="lineNum">     949 </span>            :         unsigned int alb_count;
<span class="lineNum">     950 </span>            :         unsigned int alb_failed;
<span class="lineNum">     951 </span>            :         unsigned int alb_pushed;
<span class="lineNum">     952 </span>            : 
<span class="lineNum">     953 </span>            :         /* SD_BALANCE_EXEC stats */
<span class="lineNum">     954 </span>            :         unsigned int sbe_count;
<span class="lineNum">     955 </span>            :         unsigned int sbe_balanced;
<span class="lineNum">     956 </span>            :         unsigned int sbe_pushed;
<span class="lineNum">     957 </span>            : 
<span class="lineNum">     958 </span>            :         /* SD_BALANCE_FORK stats */
<span class="lineNum">     959 </span>            :         unsigned int sbf_count;
<span class="lineNum">     960 </span>            :         unsigned int sbf_balanced;
<span class="lineNum">     961 </span>            :         unsigned int sbf_pushed;
<span class="lineNum">     962 </span>            : 
<span class="lineNum">     963 </span>            :         /* try_to_wake_up() stats */
<span class="lineNum">     964 </span>            :         unsigned int ttwu_wake_remote;
<span class="lineNum">     965 </span>            :         unsigned int ttwu_move_affine;
<span class="lineNum">     966 </span>            :         unsigned int ttwu_move_balance;
<span class="lineNum">     967 </span>            : #endif
<span class="lineNum">     968 </span>            : #ifdef CONFIG_SCHED_DEBUG
<span class="lineNum">     969 </span>            :         char *name;
<span class="lineNum">     970 </span>            : #endif
<span class="lineNum">     971 </span>            :         union {
<span class="lineNum">     972 </span>            :                 void *private;          /* used during construction */
<span class="lineNum">     973 </span>            :                 struct rcu_head rcu;    /* used during destruction */
<span class="lineNum">     974 </span>            :         };
<span class="lineNum">     975 </span>            : 
<span class="lineNum">     976 </span>            :         unsigned int span_weight;
<span class="lineNum">     977 </span>            :         /*
<span class="lineNum">     978 </span>            :          * Span of all CPUs in this domain.
<span class="lineNum">     979 </span>            :          *
<span class="lineNum">     980 </span>            :          * NOTE: this field is variable length. (Allocated dynamically
<span class="lineNum">     981 </span>            :          * by attaching extra space to the end of the structure,
<span class="lineNum">     982 </span>            :          * depending on how many CPUs the kernel has booted up with)
<span class="lineNum">     983 </span>            :          */
<span class="lineNum">     984 </span>            :         unsigned long span[0];
<span class="lineNum">     985 </span>            : };
<span class="lineNum">     986 </span>            : 
<span class="lineNum">     987 </span>            : static inline struct cpumask *sched_domain_span(struct sched_domain *sd)
<span class="lineNum">     988 </span>            : {
<span class="lineNum">     989 </span>            :         return to_cpumask(sd-&gt;span);
<span class="lineNum">     990 </span>            : }
<span class="lineNum">     991 </span>            : 
<span class="lineNum">     992 </span>            : extern void partition_sched_domains(int ndoms_new, cpumask_var_t doms_new[],
<span class="lineNum">     993 </span>            :                                     struct sched_domain_attr *dattr_new);
<span class="lineNum">     994 </span>            : 
<span class="lineNum">     995 </span>            : /* Allocate an array of sched domains, for partition_sched_domains(). */
<span class="lineNum">     996 </span>            : cpumask_var_t *alloc_sched_domains(unsigned int ndoms);
<span class="lineNum">     997 </span>            : void free_sched_domains(cpumask_var_t doms[], unsigned int ndoms);
<span class="lineNum">     998 </span>            : 
<span class="lineNum">     999 </span>            : bool cpus_share_cache(int this_cpu, int that_cpu);
<span class="lineNum">    1000 </span>            : 
<span class="lineNum">    1001 </span>            : typedef const struct cpumask *(*sched_domain_mask_f)(int cpu);
<span class="lineNum">    1002 </span>            : typedef int (*sched_domain_flags_f)(void);
<span class="lineNum">    1003 </span>            : 
<span class="lineNum">    1004 </span>            : #define SDTL_OVERLAP    0x01
<span class="lineNum">    1005 </span>            : 
<span class="lineNum">    1006 </span>            : struct sd_data {
<span class="lineNum">    1007 </span>            :         struct sched_domain **__percpu sd;
<span class="lineNum">    1008 </span>            :         struct sched_group **__percpu sg;
<span class="lineNum">    1009 </span>            :         struct sched_group_capacity **__percpu sgc;
<span class="lineNum">    1010 </span>            : };
<span class="lineNum">    1011 </span>            : 
<span class="lineNum">    1012 </span>            : struct sched_domain_topology_level {
<span class="lineNum">    1013 </span>            :         sched_domain_mask_f mask;
<span class="lineNum">    1014 </span>            :         sched_domain_flags_f sd_flags;
<span class="lineNum">    1015 </span>            :         int                 flags;
<span class="lineNum">    1016 </span>            :         int                 numa_level;
<span class="lineNum">    1017 </span>            :         struct sd_data      data;
<span class="lineNum">    1018 </span>            : #ifdef CONFIG_SCHED_DEBUG
<span class="lineNum">    1019 </span>            :         char                *name;
<span class="lineNum">    1020 </span>            : #endif
<span class="lineNum">    1021 </span>            : };
<span class="lineNum">    1022 </span>            : 
<span class="lineNum">    1023 </span>            : extern struct sched_domain_topology_level *sched_domain_topology;
<span class="lineNum">    1024 </span>            : 
<span class="lineNum">    1025 </span>            : extern void set_sched_topology(struct sched_domain_topology_level *tl);
<span class="lineNum">    1026 </span>            : 
<span class="lineNum">    1027 </span>            : #ifdef CONFIG_SCHED_DEBUG
<span class="lineNum">    1028 </span>            : # define SD_INIT_NAME(type)             .name = #type
<span class="lineNum">    1029 </span>            : #else
<span class="lineNum">    1030 </span>            : # define SD_INIT_NAME(type)
<span class="lineNum">    1031 </span>            : #endif
<span class="lineNum">    1032 </span>            : 
<span class="lineNum">    1033 </span>            : #else /* CONFIG_SMP */
<span class="lineNum">    1034 </span>            : 
<span class="lineNum">    1035 </span>            : struct sched_domain_attr;
<span class="lineNum">    1036 </span>            : 
<span class="lineNum">    1037 </span>            : static inline void
<span class="lineNum">    1038 </span>            : partition_sched_domains(int ndoms_new, cpumask_var_t doms_new[],
<span class="lineNum">    1039 </span>            :                         struct sched_domain_attr *dattr_new)
<span class="lineNum">    1040 </span>            : {
<span class="lineNum">    1041 </span>            : }
<span class="lineNum">    1042 </span>            : 
<span class="lineNum">    1043 </span>            : static inline bool cpus_share_cache(int this_cpu, int that_cpu)
<span class="lineNum">    1044 </span>            : {
<span class="lineNum">    1045 </span>            :         return true;
<span class="lineNum">    1046 </span>            : }
<span class="lineNum">    1047 </span>            : 
<span class="lineNum">    1048 </span>            : #endif  /* !CONFIG_SMP */
<span class="lineNum">    1049 </span>            : 
<span class="lineNum">    1050 </span>            : 
<span class="lineNum">    1051 </span>            : struct io_context;                      /* See blkdev.h */
<span class="lineNum">    1052 </span>            : 
<span class="lineNum">    1053 </span>            : 
<span class="lineNum">    1054 </span>            : #ifdef ARCH_HAS_PREFETCH_SWITCH_STACK
<span class="lineNum">    1055 </span>            : extern void prefetch_stack(struct task_struct *t);
<span class="lineNum">    1056 </span>            : #else
<span class="lineNum">    1057 </span>            : static inline void prefetch_stack(struct task_struct *t) { }
<span class="lineNum">    1058 </span>            : #endif
<span class="lineNum">    1059 </span>            : 
<span class="lineNum">    1060 </span>            : struct audit_context;           /* See audit.c */
<span class="lineNum">    1061 </span>            : struct mempolicy;
<span class="lineNum">    1062 </span>            : struct pipe_inode_info;
<span class="lineNum">    1063 </span>            : struct uts_namespace;
<span class="lineNum">    1064 </span>            : 
<span class="lineNum">    1065 </span>            : struct load_weight {
<span class="lineNum">    1066 </span>            :         unsigned long weight;
<span class="lineNum">    1067 </span>            :         u32 inv_weight;
<span class="lineNum">    1068 </span>            : };
<span class="lineNum">    1069 </span>            : 
<span class="lineNum">    1070 </span>            : struct sched_avg {
<span class="lineNum">    1071 </span>            :         /*
<span class="lineNum">    1072 </span>            :          * These sums represent an infinite geometric series and so are bound
<span class="lineNum">    1073 </span>            :          * above by 1024/(1-y).  Thus we only need a u32 to store them for all
<span class="lineNum">    1074 </span>            :          * choices of y &lt; 1-2^(-32)*1024.
<span class="lineNum">    1075 </span>            :          */
<span class="lineNum">    1076 </span>            :         u32 runnable_avg_sum, runnable_avg_period;
<span class="lineNum">    1077 </span>            :         u64 last_runnable_update;
<span class="lineNum">    1078 </span>            :         s64 decay_count;
<span class="lineNum">    1079 </span>            :         unsigned long load_avg_contrib;
<span class="lineNum">    1080 </span>            : };
<span class="lineNum">    1081 </span>            : 
<span class="lineNum">    1082 </span>            : #ifdef CONFIG_SCHEDSTATS
<span class="lineNum">    1083 </span>            : struct sched_statistics {
<span class="lineNum">    1084 </span>            :         u64                     wait_start;
<span class="lineNum">    1085 </span>            :         u64                     wait_max;
<span class="lineNum">    1086 </span>            :         u64                     wait_count;
<span class="lineNum">    1087 </span>            :         u64                     wait_sum;
<span class="lineNum">    1088 </span>            :         u64                     iowait_count;
<span class="lineNum">    1089 </span>            :         u64                     iowait_sum;
<span class="lineNum">    1090 </span>            : 
<span class="lineNum">    1091 </span>            :         u64                     sleep_start;
<span class="lineNum">    1092 </span>            :         u64                     sleep_max;
<span class="lineNum">    1093 </span>            :         s64                     sum_sleep_runtime;
<span class="lineNum">    1094 </span>            : 
<span class="lineNum">    1095 </span>            :         u64                     block_start;
<span class="lineNum">    1096 </span>            :         u64                     block_max;
<span class="lineNum">    1097 </span>            :         u64                     exec_max;
<span class="lineNum">    1098 </span>            :         u64                     slice_max;
<span class="lineNum">    1099 </span>            : 
<span class="lineNum">    1100 </span>            :         u64                     nr_migrations_cold;
<span class="lineNum">    1101 </span>            :         u64                     nr_failed_migrations_affine;
<span class="lineNum">    1102 </span>            :         u64                     nr_failed_migrations_running;
<span class="lineNum">    1103 </span>            :         u64                     nr_failed_migrations_hot;
<span class="lineNum">    1104 </span>            :         u64                     nr_forced_migrations;
<span class="lineNum">    1105 </span>            : 
<span class="lineNum">    1106 </span>            :         u64                     nr_wakeups;
<span class="lineNum">    1107 </span>            :         u64                     nr_wakeups_sync;
<span class="lineNum">    1108 </span>            :         u64                     nr_wakeups_migrate;
<span class="lineNum">    1109 </span>            :         u64                     nr_wakeups_local;
<span class="lineNum">    1110 </span>            :         u64                     nr_wakeups_remote;
<span class="lineNum">    1111 </span>            :         u64                     nr_wakeups_affine;
<span class="lineNum">    1112 </span>            :         u64                     nr_wakeups_affine_attempts;
<span class="lineNum">    1113 </span>            :         u64                     nr_wakeups_passive;
<span class="lineNum">    1114 </span>            :         u64                     nr_wakeups_idle;
<span class="lineNum">    1115 </span>            : };
<span class="lineNum">    1116 </span>            : #endif
<span class="lineNum">    1117 </span>            : 
<span class="lineNum">    1118 </span>            : struct sched_entity {
<span class="lineNum">    1119 </span>            :         struct load_weight      load;           /* for load-balancing */
<span class="lineNum">    1120 </span>            :         struct rb_node          run_node;
<span class="lineNum">    1121 </span>            :         struct list_head        group_node;
<span class="lineNum">    1122 </span>            :         unsigned int            on_rq;
<span class="lineNum">    1123 </span>            : 
<span class="lineNum">    1124 </span>            :         u64                     exec_start;
<span class="lineNum">    1125 </span>            :         u64                     sum_exec_runtime;
<span class="lineNum">    1126 </span>            :         u64                     vruntime;
<span class="lineNum">    1127 </span>            :         u64                     prev_sum_exec_runtime;
<span class="lineNum">    1128 </span>            : 
<span class="lineNum">    1129 </span>            :         u64                     nr_migrations;
<span class="lineNum">    1130 </span>            : 
<span class="lineNum">    1131 </span>            : #ifdef CONFIG_SCHEDSTATS
<span class="lineNum">    1132 </span>            :         struct sched_statistics statistics;
<span class="lineNum">    1133 </span>            : #endif
<span class="lineNum">    1134 </span>            : 
<span class="lineNum">    1135 </span>            : #ifdef CONFIG_FAIR_GROUP_SCHED
<span class="lineNum">    1136 </span>            :         int                     depth;
<span class="lineNum">    1137 </span>            :         struct sched_entity     *parent;
<span class="lineNum">    1138 </span>            :         /* rq on which this entity is (to be) queued: */
<span class="lineNum">    1139 </span>            :         struct cfs_rq           *cfs_rq;
<span class="lineNum">    1140 </span>            :         /* rq &quot;owned&quot; by this entity/group: */
<span class="lineNum">    1141 </span>            :         struct cfs_rq           *my_q;
<span class="lineNum">    1142 </span>            : #endif
<span class="lineNum">    1143 </span>            : 
<span class="lineNum">    1144 </span>            : #ifdef CONFIG_SMP
<span class="lineNum">    1145 </span>            :         /* Per-entity load-tracking */
<span class="lineNum">    1146 </span>            :         struct sched_avg        avg;
<span class="lineNum">    1147 </span>            : #endif
<span class="lineNum">    1148 </span>            : };
<span class="lineNum">    1149 </span>            : 
<span class="lineNum">    1150 </span>            : struct sched_rt_entity {
<span class="lineNum">    1151 </span>            :         struct list_head run_list;
<span class="lineNum">    1152 </span>            :         unsigned long timeout;
<span class="lineNum">    1153 </span>            :         unsigned long watchdog_stamp;
<span class="lineNum">    1154 </span>            :         unsigned int time_slice;
<span class="lineNum">    1155 </span>            : 
<span class="lineNum">    1156 </span>            :         struct sched_rt_entity *back;
<span class="lineNum">    1157 </span>            : #ifdef CONFIG_RT_GROUP_SCHED
<span class="lineNum">    1158 </span>            :         struct sched_rt_entity  *parent;
<span class="lineNum">    1159 </span>            :         /* rq on which this entity is (to be) queued: */
<span class="lineNum">    1160 </span>            :         struct rt_rq            *rt_rq;
<span class="lineNum">    1161 </span>            :         /* rq &quot;owned&quot; by this entity/group: */
<span class="lineNum">    1162 </span>            :         struct rt_rq            *my_q;
<span class="lineNum">    1163 </span>            : #endif
<span class="lineNum">    1164 </span>            : };
<span class="lineNum">    1165 </span>            : 
<span class="lineNum">    1166 </span>            : struct sched_dl_entity {
<span class="lineNum">    1167 </span>            :         struct rb_node  rb_node;
<span class="lineNum">    1168 </span>            : 
<span class="lineNum">    1169 </span>            :         /*
<span class="lineNum">    1170 </span>            :          * Original scheduling parameters. Copied here from sched_attr
<span class="lineNum">    1171 </span>            :          * during sched_setattr(), they will remain the same until
<span class="lineNum">    1172 </span>            :          * the next sched_setattr().
<span class="lineNum">    1173 </span>            :          */
<span class="lineNum">    1174 </span>            :         u64 dl_runtime;         /* maximum runtime for each instance    */
<span class="lineNum">    1175 </span>            :         u64 dl_deadline;        /* relative deadline of each instance   */
<span class="lineNum">    1176 </span>            :         u64 dl_period;          /* separation of two instances (period) */
<span class="lineNum">    1177 </span>            :         u64 dl_bw;              /* dl_runtime / dl_deadline             */
<span class="lineNum">    1178 </span>            : 
<span class="lineNum">    1179 </span>            :         /*
<span class="lineNum">    1180 </span>            :          * Actual scheduling parameters. Initialized with the values above,
<span class="lineNum">    1181 </span>            :          * they are continously updated during task execution. Note that
<span class="lineNum">    1182 </span>            :          * the remaining runtime could be &lt; 0 in case we are in overrun.
<span class="lineNum">    1183 </span>            :          */
<span class="lineNum">    1184 </span>            :         s64 runtime;            /* remaining runtime for this instance  */
<span class="lineNum">    1185 </span>            :         u64 deadline;           /* absolute deadline for this instance  */
<span class="lineNum">    1186 </span>            :         unsigned int flags;     /* specifying the scheduler behaviour   */
<span class="lineNum">    1187 </span>            : 
<span class="lineNum">    1188 </span>            :         /*
<span class="lineNum">    1189 </span>            :          * Some bool flags:
<span class="lineNum">    1190 </span>            :          *
<span class="lineNum">    1191 </span>            :          * @dl_throttled tells if we exhausted the runtime. If so, the
<span class="lineNum">    1192 </span>            :          * task has to wait for a replenishment to be performed at the
<span class="lineNum">    1193 </span>            :          * next firing of dl_timer.
<span class="lineNum">    1194 </span>            :          *
<span class="lineNum">    1195 </span>            :          * @dl_new tells if a new instance arrived. If so we must
<span class="lineNum">    1196 </span>            :          * start executing it with full runtime and reset its absolute
<span class="lineNum">    1197 </span>            :          * deadline;
<span class="lineNum">    1198 </span>            :          *
<span class="lineNum">    1199 </span>            :          * @dl_boosted tells if we are boosted due to DI. If so we are
<span class="lineNum">    1200 </span>            :          * outside bandwidth enforcement mechanism (but only until we
<span class="lineNum">    1201 </span>            :          * exit the critical section);
<span class="lineNum">    1202 </span>            :          *
<span class="lineNum">    1203 </span>            :          * @dl_yielded tells if task gave up the cpu before consuming
<span class="lineNum">    1204 </span>            :          * all its available runtime during the last job.
<span class="lineNum">    1205 </span>            :          */
<span class="lineNum">    1206 </span>            :         int dl_throttled, dl_new, dl_boosted, dl_yielded;
<span class="lineNum">    1207 </span>            : 
<span class="lineNum">    1208 </span>            :         /*
<span class="lineNum">    1209 </span>            :          * Bandwidth enforcement timer. Each -deadline task has its
<span class="lineNum">    1210 </span>            :          * own bandwidth to be enforced, thus we need one timer per task.
<span class="lineNum">    1211 </span>            :          */
<span class="lineNum">    1212 </span>            :         struct hrtimer dl_timer;
<span class="lineNum">    1213 </span>            : };
<span class="lineNum">    1214 </span>            : 
<span class="lineNum">    1215 </span>            : struct rcu_node;
<span class="lineNum">    1216 </span>            : 
<span class="lineNum">    1217 </span>            : enum perf_event_task_context {
<span class="lineNum">    1218 </span>            :         perf_invalid_context = -1,
<span class="lineNum">    1219 </span>            :         perf_hw_context = 0,
<span class="lineNum">    1220 </span>            :         perf_sw_context,
<span class="lineNum">    1221 </span>            :         perf_nr_task_contexts,
<span class="lineNum">    1222 </span>            : };
<span class="lineNum">    1223 </span>            : 
<span class="lineNum">    1224 </span>            : struct task_struct {
<span class="lineNum">    1225 </span>            :         volatile long state;    /* -1 unrunnable, 0 runnable, &gt;0 stopped */
<span class="lineNum">    1226 </span>            :         void *stack;
<span class="lineNum">    1227 </span>            :         atomic_t usage;
<span class="lineNum">    1228 </span>            :         unsigned int flags;     /* per process flags, defined below */
<span class="lineNum">    1229 </span>            :         unsigned int ptrace;
<span class="lineNum">    1230 </span>            : 
<span class="lineNum">    1231 </span>            : #ifdef CONFIG_SMP
<span class="lineNum">    1232 </span>            :         struct llist_node wake_entry;
<span class="lineNum">    1233 </span>            :         int on_cpu;
<span class="lineNum">    1234 </span>            :         struct task_struct *last_wakee;
<span class="lineNum">    1235 </span>            :         unsigned long wakee_flips;
<span class="lineNum">    1236 </span>            :         unsigned long wakee_flip_decay_ts;
<span class="lineNum">    1237 </span>            : 
<span class="lineNum">    1238 </span>            :         int wake_cpu;
<span class="lineNum">    1239 </span>            : #endif
<span class="lineNum">    1240 </span>            :         int on_rq;
<span class="lineNum">    1241 </span>            : 
<span class="lineNum">    1242 </span>            :         int prio, static_prio, normal_prio;
<span class="lineNum">    1243 </span>            :         unsigned int rt_priority;
<span class="lineNum">    1244 </span>            :         const struct sched_class *sched_class;
<span class="lineNum">    1245 </span>            :         struct sched_entity se;
<span class="lineNum">    1246 </span>            :         struct sched_rt_entity rt;
<span class="lineNum">    1247 </span>            : #ifdef CONFIG_CGROUP_SCHED
<span class="lineNum">    1248 </span>            :         struct task_group *sched_task_group;
<span class="lineNum">    1249 </span>            : #endif
<span class="lineNum">    1250 </span>            :         struct sched_dl_entity dl;
<span class="lineNum">    1251 </span>            : 
<span class="lineNum">    1252 </span>            : #ifdef CONFIG_PREEMPT_NOTIFIERS
<span class="lineNum">    1253 </span>            :         /* list of struct preempt_notifier: */
<span class="lineNum">    1254 </span>            :         struct hlist_head preempt_notifiers;
<span class="lineNum">    1255 </span>            : #endif
<span class="lineNum">    1256 </span>            : 
<span class="lineNum">    1257 </span>            : #ifdef CONFIG_BLK_DEV_IO_TRACE
<span class="lineNum">    1258 </span>            :         unsigned int btrace_seq;
<span class="lineNum">    1259 </span>            : #endif
<span class="lineNum">    1260 </span>            : 
<span class="lineNum">    1261 </span>            :         unsigned int policy;
<span class="lineNum">    1262 </span>            :         int nr_cpus_allowed;
<span class="lineNum">    1263 </span>            :         cpumask_t cpus_allowed;
<span class="lineNum">    1264 </span>            : 
<span class="lineNum">    1265 </span>            : #ifdef CONFIG_PREEMPT_RCU
<span class="lineNum">    1266 </span>            :         int rcu_read_lock_nesting;
<span class="lineNum">    1267 </span>            :         char rcu_read_unlock_special;
<span class="lineNum">    1268 </span>            :         struct list_head rcu_node_entry;
<span class="lineNum">    1269 </span>            : #endif /* #ifdef CONFIG_PREEMPT_RCU */
<span class="lineNum">    1270 </span>            : #ifdef CONFIG_TREE_PREEMPT_RCU
<span class="lineNum">    1271 </span>            :         struct rcu_node *rcu_blocked_node;
<span class="lineNum">    1272 </span>            : #endif /* #ifdef CONFIG_TREE_PREEMPT_RCU */
<span class="lineNum">    1273 </span>            : 
<span class="lineNum">    1274 </span>            : #if defined(CONFIG_SCHEDSTATS) || defined(CONFIG_TASK_DELAY_ACCT)
<span class="lineNum">    1275 </span>            :         struct sched_info sched_info;
<span class="lineNum">    1276 </span>            : #endif
<span class="lineNum">    1277 </span>            : 
<span class="lineNum">    1278 </span>            :         struct list_head tasks;
<span class="lineNum">    1279 </span>            : #ifdef CONFIG_SMP
<span class="lineNum">    1280 </span>            :         struct plist_node pushable_tasks;
<span class="lineNum">    1281 </span>            :         struct rb_node pushable_dl_tasks;
<span class="lineNum">    1282 </span>            : #endif
<span class="lineNum">    1283 </span>            : 
<span class="lineNum">    1284 </span>            :         struct mm_struct *mm, *active_mm;
<span class="lineNum">    1285 </span>            : #ifdef CONFIG_COMPAT_BRK
<span class="lineNum">    1286 </span>            :         unsigned brk_randomized:1;
<span class="lineNum">    1287 </span>            : #endif
<span class="lineNum">    1288 </span>            :         /* per-thread vma caching */
<span class="lineNum">    1289 </span>            :         u32 vmacache_seqnum;
<span class="lineNum">    1290 </span>            :         struct vm_area_struct *vmacache[VMACACHE_SIZE];
<span class="lineNum">    1291 </span>            : #if defined(SPLIT_RSS_COUNTING)
<span class="lineNum">    1292 </span>            :         struct task_rss_stat    rss_stat;
<span class="lineNum">    1293 </span>            : #endif
<span class="lineNum">    1294 </span>            : /* task state */
<span class="lineNum">    1295 </span>            :         int exit_state;
<span class="lineNum">    1296 </span>            :         int exit_code, exit_signal;
<span class="lineNum">    1297 </span>            :         int pdeath_signal;  /*  The signal sent when the parent dies  */
<span class="lineNum">    1298 </span>            :         unsigned int jobctl;    /* JOBCTL_*, siglock protected */
<span class="lineNum">    1299 </span>            : 
<span class="lineNum">    1300 </span>            :         /* Used for emulating ABI behavior of previous Linux versions */
<span class="lineNum">    1301 </span>            :         unsigned int personality;
<span class="lineNum">    1302 </span>            : 
<span class="lineNum">    1303 </span>            :         unsigned in_execve:1;   /* Tell the LSMs that the process is doing an
<span class="lineNum">    1304 </span>            :                                  * execve */
<span class="lineNum">    1305 </span>            :         unsigned in_iowait:1;
<span class="lineNum">    1306 </span>            : 
<span class="lineNum">    1307 </span>            :         /* Revert to default priority/policy when forking */
<span class="lineNum">    1308 </span>            :         unsigned sched_reset_on_fork:1;
<span class="lineNum">    1309 </span>            :         unsigned sched_contributes_to_load:1;
<span class="lineNum">    1310 </span>            : 
<span class="lineNum">    1311 </span>            :         unsigned long atomic_flags; /* Flags needing atomic access. */
<span class="lineNum">    1312 </span>            : 
<span class="lineNum">    1313 </span>            :         pid_t pid;
<span class="lineNum">    1314 </span>            :         pid_t tgid;
<span class="lineNum">    1315 </span>            : 
<span class="lineNum">    1316 </span>            : #ifdef CONFIG_CC_STACKPROTECTOR
<span class="lineNum">    1317 </span>            :         /* Canary value for the -fstack-protector gcc feature */
<span class="lineNum">    1318 </span>            :         unsigned long stack_canary;
<span class="lineNum">    1319 </span>            : #endif
<span class="lineNum">    1320 </span>            :         /*
<span class="lineNum">    1321 </span>            :          * pointers to (original) parent process, youngest child, younger sibling,
<span class="lineNum">    1322 </span>            :          * older sibling, respectively.  (p-&gt;father can be replaced with
<span class="lineNum">    1323 </span>            :          * p-&gt;real_parent-&gt;pid)
<span class="lineNum">    1324 </span>            :          */
<span class="lineNum">    1325 </span>            :         struct task_struct __rcu *real_parent; /* real parent process */
<span class="lineNum">    1326 </span>            :         struct task_struct __rcu *parent; /* recipient of SIGCHLD, wait4() reports */
<span class="lineNum">    1327 </span>            :         /*
<span class="lineNum">    1328 </span>            :          * children/sibling forms the list of my natural children
<span class="lineNum">    1329 </span>            :          */
<span class="lineNum">    1330 </span>            :         struct list_head children;      /* list of my children */
<span class="lineNum">    1331 </span>            :         struct list_head sibling;       /* linkage in my parent's children list */
<span class="lineNum">    1332 </span>            :         struct task_struct *group_leader;       /* threadgroup leader */
<span class="lineNum">    1333 </span>            : 
<span class="lineNum">    1334 </span>            :         /*
<span class="lineNum">    1335 </span>            :          * ptraced is the list of tasks this task is using ptrace on.
<span class="lineNum">    1336 </span>            :          * This includes both natural children and PTRACE_ATTACH targets.
<span class="lineNum">    1337 </span>            :          * p-&gt;ptrace_entry is p's link on the p-&gt;parent-&gt;ptraced list.
<span class="lineNum">    1338 </span>            :          */
<span class="lineNum">    1339 </span>            :         struct list_head ptraced;
<span class="lineNum">    1340 </span>            :         struct list_head ptrace_entry;
<span class="lineNum">    1341 </span>            : 
<span class="lineNum">    1342 </span>            :         /* PID/PID hash table linkage. */
<span class="lineNum">    1343 </span>            :         struct pid_link pids[PIDTYPE_MAX];
<span class="lineNum">    1344 </span>            :         struct list_head thread_group;
<span class="lineNum">    1345 </span>            :         struct list_head thread_node;
<span class="lineNum">    1346 </span>            : 
<span class="lineNum">    1347 </span>            :         struct completion *vfork_done;          /* for vfork() */
<span class="lineNum">    1348 </span>            :         int __user *set_child_tid;              /* CLONE_CHILD_SETTID */
<span class="lineNum">    1349 </span>            :         int __user *clear_child_tid;            /* CLONE_CHILD_CLEARTID */
<span class="lineNum">    1350 </span>            : 
<span class="lineNum">    1351 </span>            :         cputime_t utime, stime, utimescaled, stimescaled;
<span class="lineNum">    1352 </span>            :         cputime_t gtime;
<span class="lineNum">    1353 </span>            : #ifndef CONFIG_VIRT_CPU_ACCOUNTING_NATIVE
<span class="lineNum">    1354 </span>            :         struct cputime prev_cputime;
<span class="lineNum">    1355 </span>            : #endif
<span class="lineNum">    1356 </span>            : #ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN
<span class="lineNum">    1357 </span>            :         seqlock_t vtime_seqlock;
<span class="lineNum">    1358 </span>            :         unsigned long long vtime_snap;
<span class="lineNum">    1359 </span>            :         enum {
<span class="lineNum">    1360 </span>            :                 VTIME_SLEEPING = 0,
<span class="lineNum">    1361 </span>            :                 VTIME_USER,
<span class="lineNum">    1362 </span>            :                 VTIME_SYS,
<span class="lineNum">    1363 </span>            :         } vtime_snap_whence;
<span class="lineNum">    1364 </span>            : #endif
<span class="lineNum">    1365 </span>            :         unsigned long nvcsw, nivcsw; /* context switch counts */
<span class="lineNum">    1366 </span>            :         u64 start_time;         /* monotonic time in nsec */
<span class="lineNum">    1367 </span>            :         u64 real_start_time;    /* boot based time in nsec */
<span class="lineNum">    1368 </span>            : /* mm fault and swap info: this can arguably be seen as either mm-specific or thread-specific */
<span class="lineNum">    1369 </span>            :         unsigned long min_flt, maj_flt;
<span class="lineNum">    1370 </span>            : 
<span class="lineNum">    1371 </span>            :         struct task_cputime cputime_expires;
<span class="lineNum">    1372 </span>            :         struct list_head cpu_timers[3];
<span class="lineNum">    1373 </span>            : 
<span class="lineNum">    1374 </span>            : /* process credentials */
<span class="lineNum">    1375 </span>            :         const struct cred __rcu *real_cred; /* objective and real subjective task
<span class="lineNum">    1376 </span>            :                                          * credentials (COW) */
<span class="lineNum">    1377 </span>            :         const struct cred __rcu *cred;  /* effective (overridable) subjective task
<span class="lineNum">    1378 </span>            :                                          * credentials (COW) */
<span class="lineNum">    1379 </span>            :         char comm[TASK_COMM_LEN]; /* executable name excluding path
<span class="lineNum">    1380 </span>            :                                      - access with [gs]et_task_comm (which lock
<span class="lineNum">    1381 </span>            :                                        it with task_lock())
<span class="lineNum">    1382 </span>            :                                      - initialized normally by setup_new_exec */
<span class="lineNum">    1383 </span>            : /* file system info */
<span class="lineNum">    1384 </span>            :         int link_count, total_link_count;
<span class="lineNum">    1385 </span>            : #ifdef CONFIG_SYSVIPC
<span class="lineNum">    1386 </span>            : /* ipc stuff */
<span class="lineNum">    1387 </span>            :         struct sysv_sem sysvsem;
<span class="lineNum">    1388 </span>            :         struct sysv_shm sysvshm;
<span class="lineNum">    1389 </span>            : #endif
<span class="lineNum">    1390 </span>            : #ifdef CONFIG_DETECT_HUNG_TASK
<span class="lineNum">    1391 </span>            : /* hung task detection */
<span class="lineNum">    1392 </span>            :         unsigned long last_switch_count;
<span class="lineNum">    1393 </span>            : #endif
<span class="lineNum">    1394 </span>            : /* CPU-specific state of this task */
<span class="lineNum">    1395 </span>            :         struct thread_struct thread;
<span class="lineNum">    1396 </span>            : /* filesystem information */
<span class="lineNum">    1397 </span>            :         struct fs_struct *fs;
<span class="lineNum">    1398 </span>            : /* open file information */
<span class="lineNum">    1399 </span>            :         struct files_struct *files;
<span class="lineNum">    1400 </span>            : /* namespaces */
<span class="lineNum">    1401 </span>            :         struct nsproxy *nsproxy;
<span class="lineNum">    1402 </span>            : /* signal handlers */
<span class="lineNum">    1403 </span>            :         struct signal_struct *signal;
<span class="lineNum">    1404 </span>            :         struct sighand_struct *sighand;
<span class="lineNum">    1405 </span>            : 
<span class="lineNum">    1406 </span>            :         sigset_t blocked, real_blocked;
<span class="lineNum">    1407 </span>            :         sigset_t saved_sigmask; /* restored if set_restore_sigmask() was used */
<span class="lineNum">    1408 </span>            :         struct sigpending pending;
<span class="lineNum">    1409 </span>            : 
<span class="lineNum">    1410 </span>            :         unsigned long sas_ss_sp;
<span class="lineNum">    1411 </span>            :         size_t sas_ss_size;
<span class="lineNum">    1412 </span>            :         int (*notifier)(void *priv);
<span class="lineNum">    1413 </span>            :         void *notifier_data;
<span class="lineNum">    1414 </span>            :         sigset_t *notifier_mask;
<span class="lineNum">    1415 </span>            :         struct callback_head *task_works;
<span class="lineNum">    1416 </span>            : 
<span class="lineNum">    1417 </span>            :         struct audit_context *audit_context;
<span class="lineNum">    1418 </span>            : #ifdef CONFIG_AUDITSYSCALL
<span class="lineNum">    1419 </span>            :         kuid_t loginuid;
<span class="lineNum">    1420 </span>            :         unsigned int sessionid;
<span class="lineNum">    1421 </span>            : #endif
<span class="lineNum">    1422 </span>            :         struct seccomp seccomp;
<span class="lineNum">    1423 </span>            : 
<span class="lineNum">    1424 </span>            : /* Thread group tracking */
<span class="lineNum">    1425 </span>            :         u32 parent_exec_id;
<span class="lineNum">    1426 </span>            :         u32 self_exec_id;
<span class="lineNum">    1427 </span>            : /* Protection of (de-)allocation: mm, files, fs, tty, keyrings, mems_allowed,
<span class="lineNum">    1428 </span>            :  * mempolicy */
<span class="lineNum">    1429 </span>            :         spinlock_t alloc_lock;
<span class="lineNum">    1430 </span>            : 
<span class="lineNum">    1431 </span>            :         /* Protection of the PI data structures: */
<span class="lineNum">    1432 </span>            :         raw_spinlock_t pi_lock;
<span class="lineNum">    1433 </span>            : 
<span class="lineNum">    1434 </span>            : #ifdef CONFIG_RT_MUTEXES
<span class="lineNum">    1435 </span>            :         /* PI waiters blocked on a rt_mutex held by this task */
<span class="lineNum">    1436 </span>            :         struct rb_root pi_waiters;
<span class="lineNum">    1437 </span>            :         struct rb_node *pi_waiters_leftmost;
<span class="lineNum">    1438 </span>            :         /* Deadlock detection and priority inheritance handling */
<span class="lineNum">    1439 </span>            :         struct rt_mutex_waiter *pi_blocked_on;
<span class="lineNum">    1440 </span>            : #endif
<span class="lineNum">    1441 </span>            : 
<span class="lineNum">    1442 </span>            : #ifdef CONFIG_DEBUG_MUTEXES
<span class="lineNum">    1443 </span>            :         /* mutex deadlock detection */
<span class="lineNum">    1444 </span>            :         struct mutex_waiter *blocked_on;
<span class="lineNum">    1445 </span>            : #endif
<span class="lineNum">    1446 </span>            : #ifdef CONFIG_TRACE_IRQFLAGS
<span class="lineNum">    1447 </span>            :         unsigned int irq_events;
<span class="lineNum">    1448 </span>            :         unsigned long hardirq_enable_ip;
<span class="lineNum">    1449 </span>            :         unsigned long hardirq_disable_ip;
<span class="lineNum">    1450 </span>            :         unsigned int hardirq_enable_event;
<span class="lineNum">    1451 </span>            :         unsigned int hardirq_disable_event;
<span class="lineNum">    1452 </span>            :         int hardirqs_enabled;
<span class="lineNum">    1453 </span>            :         int hardirq_context;
<span class="lineNum">    1454 </span>            :         unsigned long softirq_disable_ip;
<span class="lineNum">    1455 </span>            :         unsigned long softirq_enable_ip;
<span class="lineNum">    1456 </span>            :         unsigned int softirq_disable_event;
<span class="lineNum">    1457 </span>            :         unsigned int softirq_enable_event;
<span class="lineNum">    1458 </span>            :         int softirqs_enabled;
<span class="lineNum">    1459 </span>            :         int softirq_context;
<span class="lineNum">    1460 </span>            : #endif
<span class="lineNum">    1461 </span>            : #ifdef CONFIG_LOCKDEP
<span class="lineNum">    1462 </span>            : # define MAX_LOCK_DEPTH 48UL
<span class="lineNum">    1463 </span>            :         u64 curr_chain_key;
<span class="lineNum">    1464 </span>            :         int lockdep_depth;
<span class="lineNum">    1465 </span>            :         unsigned int lockdep_recursion;
<span class="lineNum">    1466 </span>            :         struct held_lock held_locks[MAX_LOCK_DEPTH];
<span class="lineNum">    1467 </span>            :         gfp_t lockdep_reclaim_gfp;
<span class="lineNum">    1468 </span>            : #endif
<span class="lineNum">    1469 </span>            : 
<span class="lineNum">    1470 </span>            : /* journalling filesystem info */
<span class="lineNum">    1471 </span>            :         void *journal_info;
<span class="lineNum">    1472 </span>            : 
<span class="lineNum">    1473 </span>            : /* stacked block device info */
<span class="lineNum">    1474 </span>            :         struct bio_list *bio_list;
<span class="lineNum">    1475 </span>            : 
<span class="lineNum">    1476 </span>            : #ifdef CONFIG_BLOCK
<span class="lineNum">    1477 </span>            : /* stack plugging */
<span class="lineNum">    1478 </span>            :         struct blk_plug *plug;
<span class="lineNum">    1479 </span>            : #endif
<span class="lineNum">    1480 </span>            : 
<span class="lineNum">    1481 </span>            : /* VM state */
<span class="lineNum">    1482 </span>            :         struct reclaim_state *reclaim_state;
<span class="lineNum">    1483 </span>            : 
<span class="lineNum">    1484 </span>            :         struct backing_dev_info *backing_dev_info;
<span class="lineNum">    1485 </span>            : 
<span class="lineNum">    1486 </span>            :         struct io_context *io_context;
<span class="lineNum">    1487 </span>            : 
<span class="lineNum">    1488 </span>            :         unsigned long ptrace_message;
<span class="lineNum">    1489 </span>            :         siginfo_t *last_siginfo; /* For ptrace use.  */
<span class="lineNum">    1490 </span>            :         struct task_io_accounting ioac;
<span class="lineNum">    1491 </span>            : #if defined(CONFIG_TASK_XACCT)
<span class="lineNum">    1492 </span>            :         u64 acct_rss_mem1;      /* accumulated rss usage */
<span class="lineNum">    1493 </span>            :         u64 acct_vm_mem1;       /* accumulated virtual memory usage */
<span class="lineNum">    1494 </span>            :         cputime_t acct_timexpd; /* stime + utime since last update */
<span class="lineNum">    1495 </span>            : #endif
<span class="lineNum">    1496 </span>            : #ifdef CONFIG_CPUSETS
<span class="lineNum">    1497 </span>            :         nodemask_t mems_allowed;        /* Protected by alloc_lock */
<span class="lineNum">    1498 </span>            :         seqcount_t mems_allowed_seq;    /* Seqence no to catch updates */
<span class="lineNum">    1499 </span>            :         int cpuset_mem_spread_rotor;
<span class="lineNum">    1500 </span>            :         int cpuset_slab_spread_rotor;
<span class="lineNum">    1501 </span>            : #endif
<span class="lineNum">    1502 </span>            : #ifdef CONFIG_CGROUPS
<span class="lineNum">    1503 </span>            :         /* Control Group info protected by css_set_lock */
<span class="lineNum">    1504 </span>            :         struct css_set __rcu *cgroups;
<span class="lineNum">    1505 </span>            :         /* cg_list protected by css_set_lock and tsk-&gt;alloc_lock */
<span class="lineNum">    1506 </span>            :         struct list_head cg_list;
<span class="lineNum">    1507 </span>            : #endif
<span class="lineNum">    1508 </span>            : #ifdef CONFIG_FUTEX
<span class="lineNum">    1509 </span>            :         struct robust_list_head __user *robust_list;
<span class="lineNum">    1510 </span>            : #ifdef CONFIG_COMPAT
<span class="lineNum">    1511 </span>            :         struct compat_robust_list_head __user *compat_robust_list;
<span class="lineNum">    1512 </span>            : #endif
<span class="lineNum">    1513 </span>            :         struct list_head pi_state_list;
<span class="lineNum">    1514 </span>            :         struct futex_pi_state *pi_state_cache;
<span class="lineNum">    1515 </span>            : #endif
<span class="lineNum">    1516 </span>            : #ifdef CONFIG_PERF_EVENTS
<span class="lineNum">    1517 </span>            :         struct perf_event_context *perf_event_ctxp[perf_nr_task_contexts];
<span class="lineNum">    1518 </span>            :         struct mutex perf_event_mutex;
<span class="lineNum">    1519 </span>            :         struct list_head perf_event_list;
<span class="lineNum">    1520 </span>            : #endif
<span class="lineNum">    1521 </span>            : #ifdef CONFIG_DEBUG_PREEMPT
<span class="lineNum">    1522 </span>            :         unsigned long preempt_disable_ip;
<span class="lineNum">    1523 </span>            : #endif
<span class="lineNum">    1524 </span>            : #ifdef CONFIG_NUMA
<span class="lineNum">    1525 </span>            :         struct mempolicy *mempolicy;    /* Protected by alloc_lock */
<span class="lineNum">    1526 </span>            :         short il_next;
<span class="lineNum">    1527 </span>            :         short pref_node_fork;
<span class="lineNum">    1528 </span>            : #endif
<span class="lineNum">    1529 </span>            : #ifdef CONFIG_NUMA_BALANCING
<span class="lineNum">    1530 </span>            :         int numa_scan_seq;
<span class="lineNum">    1531 </span>            :         unsigned int numa_scan_period;
<span class="lineNum">    1532 </span>            :         unsigned int numa_scan_period_max;
<span class="lineNum">    1533 </span>            :         int numa_preferred_nid;
<span class="lineNum">    1534 </span>            :         unsigned long numa_migrate_retry;
<span class="lineNum">    1535 </span>            :         u64 node_stamp;                 /* migration stamp  */
<span class="lineNum">    1536 </span>            :         u64 last_task_numa_placement;
<span class="lineNum">    1537 </span>            :         u64 last_sum_exec_runtime;
<span class="lineNum">    1538 </span>            :         struct callback_head numa_work;
<span class="lineNum">    1539 </span>            : 
<span class="lineNum">    1540 </span>            :         struct list_head numa_entry;
<span class="lineNum">    1541 </span>            :         struct numa_group *numa_group;
<span class="lineNum">    1542 </span>            : 
<span class="lineNum">    1543 </span>            :         /*
<span class="lineNum">    1544 </span>            :          * Exponential decaying average of faults on a per-node basis.
<span class="lineNum">    1545 </span>            :          * Scheduling placement decisions are made based on the these counts.
<span class="lineNum">    1546 </span>            :          * The values remain static for the duration of a PTE scan
<span class="lineNum">    1547 </span>            :          */
<span class="lineNum">    1548 </span>            :         unsigned long *numa_faults_memory;
<span class="lineNum">    1549 </span>            :         unsigned long total_numa_faults;
<span class="lineNum">    1550 </span>            : 
<span class="lineNum">    1551 </span>            :         /*
<span class="lineNum">    1552 </span>            :          * numa_faults_buffer records faults per node during the current
<span class="lineNum">    1553 </span>            :          * scan window. When the scan completes, the counts in
<span class="lineNum">    1554 </span>            :          * numa_faults_memory decay and these values are copied.
<span class="lineNum">    1555 </span>            :          */
<span class="lineNum">    1556 </span>            :         unsigned long *numa_faults_buffer_memory;
<span class="lineNum">    1557 </span>            : 
<span class="lineNum">    1558 </span>            :         /*
<span class="lineNum">    1559 </span>            :          * Track the nodes the process was running on when a NUMA hinting
<span class="lineNum">    1560 </span>            :          * fault was incurred.
<span class="lineNum">    1561 </span>            :          */
<span class="lineNum">    1562 </span>            :         unsigned long *numa_faults_cpu;
<span class="lineNum">    1563 </span>            :         unsigned long *numa_faults_buffer_cpu;
<span class="lineNum">    1564 </span>            : 
<span class="lineNum">    1565 </span>            :         /*
<span class="lineNum">    1566 </span>            :          * numa_faults_locality tracks if faults recorded during the last
<span class="lineNum">    1567 </span>            :          * scan window were remote/local. The task scan period is adapted
<span class="lineNum">    1568 </span>            :          * based on the locality of the faults with different weights
<span class="lineNum">    1569 </span>            :          * depending on whether they were shared or private faults
<span class="lineNum">    1570 </span>            :          */
<span class="lineNum">    1571 </span>            :         unsigned long numa_faults_locality[2];
<span class="lineNum">    1572 </span>            : 
<span class="lineNum">    1573 </span>            :         unsigned long numa_pages_migrated;
<span class="lineNum">    1574 </span>            : #endif /* CONFIG_NUMA_BALANCING */
<span class="lineNum">    1575 </span>            : 
<span class="lineNum">    1576 </span>            :         struct rcu_head rcu;
<span class="lineNum">    1577 </span>            : 
<span class="lineNum">    1578 </span>            :         /*
<span class="lineNum">    1579 </span>            :          * cache last used pipe for splice
<span class="lineNum">    1580 </span>            :          */
<span class="lineNum">    1581 </span>            :         struct pipe_inode_info *splice_pipe;
<span class="lineNum">    1582 </span>            : 
<span class="lineNum">    1583 </span>            :         struct page_frag task_frag;
<span class="lineNum">    1584 </span>            : 
<span class="lineNum">    1585 </span>            : #ifdef  CONFIG_TASK_DELAY_ACCT
<span class="lineNum">    1586 </span>            :         struct task_delay_info *delays;
<span class="lineNum">    1587 </span>            : #endif
<span class="lineNum">    1588 </span>            : #ifdef CONFIG_FAULT_INJECTION
<span class="lineNum">    1589 </span>            :         int make_it_fail;
<span class="lineNum">    1590 </span>            : #endif
<span class="lineNum">    1591 </span>            :         /*
<span class="lineNum">    1592 </span>            :          * when (nr_dirtied &gt;= nr_dirtied_pause), it's time to call
<span class="lineNum">    1593 </span>            :          * balance_dirty_pages() for some dirty throttling pause
<span class="lineNum">    1594 </span>            :          */
<span class="lineNum">    1595 </span>            :         int nr_dirtied;
<span class="lineNum">    1596 </span>            :         int nr_dirtied_pause;
<span class="lineNum">    1597 </span>            :         unsigned long dirty_paused_when; /* start of a write-and-pause period */
<span class="lineNum">    1598 </span>            : 
<span class="lineNum">    1599 </span>            : #ifdef CONFIG_LATENCYTOP
<span class="lineNum">    1600 </span>            :         int latency_record_count;
<span class="lineNum">    1601 </span>            :         struct latency_record latency_record[LT_SAVECOUNT];
<span class="lineNum">    1602 </span>            : #endif
<span class="lineNum">    1603 </span>            :         /*
<span class="lineNum">    1604 </span>            :          * time slack values; these are used to round up poll() and
<span class="lineNum">    1605 </span>            :          * select() etc timeout values. These are in nanoseconds.
<span class="lineNum">    1606 </span>            :          */
<span class="lineNum">    1607 </span>            :         unsigned long timer_slack_ns;
<span class="lineNum">    1608 </span>            :         unsigned long default_timer_slack_ns;
<span class="lineNum">    1609 </span>            : 
<span class="lineNum">    1610 </span>            : #ifdef CONFIG_FUNCTION_GRAPH_TRACER
<span class="lineNum">    1611 </span>            :         /* Index of current stored address in ret_stack */
<span class="lineNum">    1612 </span>            :         int curr_ret_stack;
<span class="lineNum">    1613 </span>            :         /* Stack of return addresses for return function tracing */
<span class="lineNum">    1614 </span>            :         struct ftrace_ret_stack *ret_stack;
<span class="lineNum">    1615 </span>            :         /* time stamp for last schedule */
<span class="lineNum">    1616 </span>            :         unsigned long long ftrace_timestamp;
<span class="lineNum">    1617 </span>            :         /*
<span class="lineNum">    1618 </span>            :          * Number of functions that haven't been traced
<span class="lineNum">    1619 </span>            :          * because of depth overrun.
<span class="lineNum">    1620 </span>            :          */
<span class="lineNum">    1621 </span>            :         atomic_t trace_overrun;
<span class="lineNum">    1622 </span>            :         /* Pause for the tracing */
<span class="lineNum">    1623 </span>            :         atomic_t tracing_graph_pause;
<span class="lineNum">    1624 </span>            : #endif
<span class="lineNum">    1625 </span>            : #ifdef CONFIG_TRACING
<span class="lineNum">    1626 </span>            :         /* state flags for use by tracers */
<span class="lineNum">    1627 </span>            :         unsigned long trace;
<span class="lineNum">    1628 </span>            :         /* bitmask and counter of trace recursion */
<span class="lineNum">    1629 </span>            :         unsigned long trace_recursion;
<span class="lineNum">    1630 </span>            : #endif /* CONFIG_TRACING */
<span class="lineNum">    1631 </span>            : #ifdef CONFIG_MEMCG /* memcg uses this to do batch job */
<span class="lineNum">    1632 </span>            :         unsigned int memcg_kmem_skip_account;
<span class="lineNum">    1633 </span>            :         struct memcg_oom_info {
<span class="lineNum">    1634 </span>            :                 struct mem_cgroup *memcg;
<span class="lineNum">    1635 </span>            :                 gfp_t gfp_mask;
<span class="lineNum">    1636 </span>            :                 int order;
<span class="lineNum">    1637 </span>            :                 unsigned int may_oom:1;
<span class="lineNum">    1638 </span>            :         } memcg_oom;
<span class="lineNum">    1639 </span>            : #endif
<span class="lineNum">    1640 </span>            : #ifdef CONFIG_UPROBES
<span class="lineNum">    1641 </span>            :         struct uprobe_task *utask;
<span class="lineNum">    1642 </span>            : #endif
<span class="lineNum">    1643 </span>            : #if defined(CONFIG_BCACHE) || defined(CONFIG_BCACHE_MODULE)
<span class="lineNum">    1644 </span>            :         unsigned int    sequential_io;
<span class="lineNum">    1645 </span>            :         unsigned int    sequential_io_avg;
<span class="lineNum">    1646 </span>            : #endif
<span class="lineNum">    1647 </span>            : };
<span class="lineNum">    1648 </span>            : 
<span class="lineNum">    1649 </span>            : /* Future-safe accessor for struct task_struct's cpus_allowed. */
<span class="lineNum">    1650 </span>            : #define tsk_cpus_allowed(tsk) (&amp;(tsk)-&gt;cpus_allowed)
<span class="lineNum">    1651 </span>            : 
<span class="lineNum">    1652 </span>            : #define TNF_MIGRATED    0x01
<span class="lineNum">    1653 </span>            : #define TNF_NO_GROUP    0x02
<span class="lineNum">    1654 </span>            : #define TNF_SHARED      0x04
<span class="lineNum">    1655 </span>            : #define TNF_FAULT_LOCAL 0x08
<span class="lineNum">    1656 </span>            : 
<span class="lineNum">    1657 </span>            : #ifdef CONFIG_NUMA_BALANCING
<span class="lineNum">    1658 </span>            : extern void task_numa_fault(int last_node, int node, int pages, int flags);
<span class="lineNum">    1659 </span>            : extern pid_t task_numa_group_id(struct task_struct *p);
<span class="lineNum">    1660 </span>            : extern void set_numabalancing_state(bool enabled);
<span class="lineNum">    1661 </span>            : extern void task_numa_free(struct task_struct *p);
<span class="lineNum">    1662 </span>            : extern bool should_numa_migrate_memory(struct task_struct *p, struct page *page,
<span class="lineNum">    1663 </span>            :                                         int src_nid, int dst_cpu);
<span class="lineNum">    1664 </span>            : #else
<span class="lineNum">    1665 </span>            : static inline void task_numa_fault(int last_node, int node, int pages,
<span class="lineNum">    1666 </span>            :                                    int flags)
<span class="lineNum">    1667 </span>            : {
<span class="lineNum">    1668 </span>            : }
<span class="lineNum">    1669 </span>            : static inline pid_t task_numa_group_id(struct task_struct *p)
<span class="lineNum">    1670 </span>            : {
<span class="lineNum">    1671 </span>            :         return 0;
<span class="lineNum">    1672 </span>            : }
<span class="lineNum">    1673 </span>            : static inline void set_numabalancing_state(bool enabled)
<span class="lineNum">    1674 </span>            : {
<span class="lineNum">    1675 </span>            : }
<span class="lineNum">    1676 </span>            : static inline void task_numa_free(struct task_struct *p)
<span class="lineNum">    1677 </span>            : {
<span class="lineNum">    1678 </span>            : }
<span class="lineNum">    1679 </span>            : static inline bool should_numa_migrate_memory(struct task_struct *p,
<span class="lineNum">    1680 </span>            :                                 struct page *page, int src_nid, int dst_cpu)
<span class="lineNum">    1681 </span>            : {
<span class="lineNum">    1682 </span>            :         return true;
<span class="lineNum">    1683 </span>            : }
<span class="lineNum">    1684 </span>            : #endif
<span class="lineNum">    1685 </span>            : 
<span class="lineNum">    1686 </span>            : static inline struct pid *task_pid(struct task_struct *task)
<span class="lineNum">    1687 </span>            : {
<span class="lineNum">    1688 </span>            :         return task-&gt;pids[PIDTYPE_PID].pid;
<span class="lineNum">    1689 </span>            : }
<span class="lineNum">    1690 </span>            : 
<span class="lineNum">    1691 </span>            : static inline struct pid *task_tgid(struct task_struct *task)
<span class="lineNum">    1692 </span>            : {
<span class="lineNum">    1693 </span>            :         return task-&gt;group_leader-&gt;pids[PIDTYPE_PID].pid;
<span class="lineNum">    1694 </span>            : }
<span class="lineNum">    1695 </span>            : 
<span class="lineNum">    1696 </span>            : /*
<span class="lineNum">    1697 </span>            :  * Without tasklist or rcu lock it is not safe to dereference
<span class="lineNum">    1698 </span>            :  * the result of task_pgrp/task_session even if task == current,
<span class="lineNum">    1699 </span>            :  * we can race with another thread doing sys_setsid/sys_setpgid.
<span class="lineNum">    1700 </span>            :  */
<span class="lineNum">    1701 </span>            : static inline struct pid *task_pgrp(struct task_struct *task)
<span class="lineNum">    1702 </span>            : {
<span class="lineNum">    1703 </span>            :         return task-&gt;group_leader-&gt;pids[PIDTYPE_PGID].pid;
<span class="lineNum">    1704 </span>            : }
<span class="lineNum">    1705 </span>            : 
<span class="lineNum">    1706 </span>            : static inline struct pid *task_session(struct task_struct *task)
<span class="lineNum">    1707 </span>            : {
<span class="lineNum">    1708 </span>            :         return task-&gt;group_leader-&gt;pids[PIDTYPE_SID].pid;
<span class="lineNum">    1709 </span>            : }
<span class="lineNum">    1710 </span>            : 
<span class="lineNum">    1711 </span>            : struct pid_namespace;
<span class="lineNum">    1712 </span>            : 
<span class="lineNum">    1713 </span>            : /*
<span class="lineNum">    1714 </span>            :  * the helpers to get the task's different pids as they are seen
<span class="lineNum">    1715 </span>            :  * from various namespaces
<span class="lineNum">    1716 </span>            :  *
<span class="lineNum">    1717 </span>            :  * task_xid_nr()     : global id, i.e. the id seen from the init namespace;
<span class="lineNum">    1718 </span>            :  * task_xid_vnr()    : virtual id, i.e. the id seen from the pid namespace of
<span class="lineNum">    1719 </span>            :  *                     current.
<span class="lineNum">    1720 </span>            :  * task_xid_nr_ns()  : id seen from the ns specified;
<span class="lineNum">    1721 </span>            :  *
<span class="lineNum">    1722 </span>            :  * set_task_vxid()   : assigns a virtual id to a task;
<span class="lineNum">    1723 </span>            :  *
<span class="lineNum">    1724 </span>            :  * see also pid_nr() etc in include/linux/pid.h
<span class="lineNum">    1725 </span>            :  */
<span class="lineNum">    1726 </span>            : pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type,
<span class="lineNum">    1727 </span>            :                         struct pid_namespace *ns);
<span class="lineNum">    1728 </span>            : 
<span class="lineNum">    1729 </span>            : static inline pid_t task_pid_nr(struct task_struct *tsk)
<span class="lineNum">    1730 </span>            : {
<span class="lineNum">    1731 </span>            :         return tsk-&gt;pid;
<span class="lineNum">    1732 </span>            : }
<span class="lineNum">    1733 </span>            : 
<span class="lineNum">    1734 </span>            : static inline pid_t task_pid_nr_ns(struct task_struct *tsk,
<span class="lineNum">    1735 </span>            :                                         struct pid_namespace *ns)
<span class="lineNum">    1736 </span>            : {
<span class="lineNum">    1737 </span>            :         return __task_pid_nr_ns(tsk, PIDTYPE_PID, ns);
<span class="lineNum">    1738 </span>            : }
<span class="lineNum">    1739 </span>            : 
<span class="lineNum">    1740 </span>            : static inline pid_t task_pid_vnr(struct task_struct *tsk)
<span class="lineNum">    1741 </span>            : {
<span class="lineNum">    1742 </span>            :         return __task_pid_nr_ns(tsk, PIDTYPE_PID, NULL);
<span class="lineNum">    1743 </span>            : }
<span class="lineNum">    1744 </span>            : 
<span class="lineNum">    1745 </span>            : 
<span class="lineNum">    1746 </span>            : static inline pid_t task_tgid_nr(struct task_struct *tsk)
<span class="lineNum">    1747 </span>            : {
<span class="lineNum">    1748 </span>            :         return tsk-&gt;tgid;
<span class="lineNum">    1749 </span>            : }
<span class="lineNum">    1750 </span>            : 
<span class="lineNum">    1751 </span>            : pid_t task_tgid_nr_ns(struct task_struct *tsk, struct pid_namespace *ns);
<span class="lineNum">    1752 </span>            : 
<span class="lineNum">    1753 </span>            : static inline pid_t task_tgid_vnr(struct task_struct *tsk)
<span class="lineNum">    1754 </span>            : {
<span class="lineNum">    1755 </span>            :         return pid_vnr(task_tgid(tsk));
<span class="lineNum">    1756 </span>            : }
<span class="lineNum">    1757 </span>            : 
<span class="lineNum">    1758 </span>            : 
<span class="lineNum">    1759 </span>            : static inline int pid_alive(const struct task_struct *p);
<span class="lineNum">    1760 </span>            : static inline pid_t task_ppid_nr_ns(const struct task_struct *tsk, struct pid_namespace *ns)
<span class="lineNum">    1761 </span>            : {
<span class="lineNum">    1762 </span>            :         pid_t pid = 0;
<span class="lineNum">    1763 </span>            : 
<span class="lineNum">    1764 </span>            :         rcu_read_lock();
<span class="lineNum">    1765 </span>            :         if (pid_alive(tsk))
<span class="lineNum">    1766 </span>            :                 pid = task_tgid_nr_ns(rcu_dereference(tsk-&gt;real_parent), ns);
<span class="lineNum">    1767 </span>            :         rcu_read_unlock();
<span class="lineNum">    1768 </span>            : 
<span class="lineNum">    1769 </span>            :         return pid;
<span class="lineNum">    1770 </span>            : }
<span class="lineNum">    1771 </span>            : 
<span class="lineNum">    1772 </span>            : static inline pid_t task_ppid_nr(const struct task_struct *tsk)
<span class="lineNum">    1773 </span>            : {
<span class="lineNum">    1774 </span>            :         return task_ppid_nr_ns(tsk, &amp;init_pid_ns);
<span class="lineNum">    1775 </span>            : }
<span class="lineNum">    1776 </span>            : 
<span class="lineNum">    1777 </span>            : static inline pid_t task_pgrp_nr_ns(struct task_struct *tsk,
<span class="lineNum">    1778 </span>            :                                         struct pid_namespace *ns)
<span class="lineNum">    1779 </span>            : {
<span class="lineNum">    1780 </span>            :         return __task_pid_nr_ns(tsk, PIDTYPE_PGID, ns);
<span class="lineNum">    1781 </span>            : }
<span class="lineNum">    1782 </span>            : 
<span class="lineNum">    1783 </span>            : static inline pid_t task_pgrp_vnr(struct task_struct *tsk)
<span class="lineNum">    1784 </span>            : {
<span class="lineNum">    1785 </span>            :         return __task_pid_nr_ns(tsk, PIDTYPE_PGID, NULL);
<span class="lineNum">    1786 </span>            : }
<span class="lineNum">    1787 </span>            : 
<span class="lineNum">    1788 </span>            : 
<span class="lineNum">    1789 </span>            : static inline pid_t task_session_nr_ns(struct task_struct *tsk,
<span class="lineNum">    1790 </span>            :                                         struct pid_namespace *ns)
<span class="lineNum">    1791 </span>            : {
<span class="lineNum">    1792 </span>            :         return __task_pid_nr_ns(tsk, PIDTYPE_SID, ns);
<span class="lineNum">    1793 </span>            : }
<span class="lineNum">    1794 </span>            : 
<span class="lineNum">    1795 </span>            : static inline pid_t task_session_vnr(struct task_struct *tsk)
<span class="lineNum">    1796 </span>            : {
<span class="lineNum">    1797 </span>            :         return __task_pid_nr_ns(tsk, PIDTYPE_SID, NULL);
<span class="lineNum">    1798 </span>            : }
<span class="lineNum">    1799 </span>            : 
<span class="lineNum">    1800 </span>            : /* obsolete, do not use */
<span class="lineNum">    1801 </span>            : static inline pid_t task_pgrp_nr(struct task_struct *tsk)
<span class="lineNum">    1802 </span>            : {
<span class="lineNum">    1803 </span>            :         return task_pgrp_nr_ns(tsk, &amp;init_pid_ns);
<span class="lineNum">    1804 </span>            : }
<span class="lineNum">    1805 </span>            : 
<span class="lineNum">    1806 </span>            : /**
<span class="lineNum">    1807 </span>            :  * pid_alive - check that a task structure is not stale
<span class="lineNum">    1808 </span>            :  * @p: Task structure to be checked.
<span class="lineNum">    1809 </span>            :  *
<span class="lineNum">    1810 </span>            :  * Test if a process is not yet dead (at most zombie state)
<span class="lineNum">    1811 </span>            :  * If pid_alive fails, then pointers within the task structure
<span class="lineNum">    1812 </span>            :  * can be stale and must not be dereferenced.
<span class="lineNum">    1813 </span>            :  *
<span class="lineNum">    1814 </span>            :  * Return: 1 if the process is alive. 0 otherwise.
<span class="lineNum">    1815 </span>            :  */
<span class="lineNum">    1816 </span>            : static inline int pid_alive(const struct task_struct *p)
<span class="lineNum">    1817 </span>            : {
<span class="lineNum">    1818 </span>            :         return p-&gt;pids[PIDTYPE_PID].pid != NULL;
<span class="lineNum">    1819 </span>            : }
<span class="lineNum">    1820 </span>            : 
<span class="lineNum">    1821 </span>            : /**
<span class="lineNum">    1822 </span>            :  * is_global_init - check if a task structure is init
<span class="lineNum">    1823 </span>            :  * @tsk: Task structure to be checked.
<span class="lineNum">    1824 </span>            :  *
<span class="lineNum">    1825 </span>            :  * Check if a task structure is the first user space task the kernel created.
<span class="lineNum">    1826 </span>            :  *
<span class="lineNum">    1827 </span>            :  * Return: 1 if the task structure is init. 0 otherwise.
<span class="lineNum">    1828 </span>            :  */
<span class="lineNum">    1829 </span>            : static inline int is_global_init(struct task_struct *tsk)
<span class="lineNum">    1830 </span>            : {
<span class="lineNum">    1831 </span>            :         return tsk-&gt;pid == 1;
<span class="lineNum">    1832 </span>            : }
<span class="lineNum">    1833 </span>            : 
<span class="lineNum">    1834 </span>            : extern struct pid *cad_pid;
<span class="lineNum">    1835 </span>            : 
<span class="lineNum">    1836 </span>            : extern void free_task(struct task_struct *tsk);
<span class="lineNum">    1837 </span>            : #define get_task_struct(tsk) do { atomic_inc(&amp;(tsk)-&gt;usage); } while(0)
<span class="lineNum">    1838 </span>            : 
<span class="lineNum">    1839 </span>            : extern void __put_task_struct(struct task_struct *t);
<span class="lineNum">    1840 </span>            : 
<span class="lineNum">    1841 </span>            : static inline void put_task_struct(struct task_struct *t)
<span class="lineNum">    1842 </span>            : {
<span class="lineNum">    1843 </span>            :         if (atomic_dec_and_test(&amp;t-&gt;usage))
<span class="lineNum">    1844 </span>            :                 __put_task_struct(t);
<span class="lineNum">    1845 </span>            : }
<span class="lineNum">    1846 </span>            : 
<span class="lineNum">    1847 </span>            : #ifdef CONFIG_VIRT_CPU_ACCOUNTING_GEN
<span class="lineNum">    1848 </span>            : extern void task_cputime(struct task_struct *t,
<span class="lineNum">    1849 </span>            :                          cputime_t *utime, cputime_t *stime);
<span class="lineNum">    1850 </span>            : extern void task_cputime_scaled(struct task_struct *t,
<span class="lineNum">    1851 </span>            :                                 cputime_t *utimescaled, cputime_t *stimescaled);
<span class="lineNum">    1852 </span>            : extern cputime_t task_gtime(struct task_struct *t);
<span class="lineNum">    1853 </span>            : #else
<span class="lineNum">    1854 </span>            : static inline void task_cputime(struct task_struct *t,
<span class="lineNum">    1855 </span>            :                                 cputime_t *utime, cputime_t *stime)
<span class="lineNum">    1856 </span>            : {
<span class="lineNum">    1857 </span>            :         if (utime)
<span class="lineNum">    1858 </span>            :                 *utime = t-&gt;utime;
<span class="lineNum">    1859 </span>            :         if (stime)
<span class="lineNum">    1860 </span>            :                 *stime = t-&gt;stime;
<span class="lineNum">    1861 </span>            : }
<span class="lineNum">    1862 </span>            : 
<span class="lineNum">    1863 </span>            : static inline void task_cputime_scaled(struct task_struct *t,
<span class="lineNum">    1864 </span>            :                                        cputime_t *utimescaled,
<span class="lineNum">    1865 </span>            :                                        cputime_t *stimescaled)
<span class="lineNum">    1866 </span>            : {
<span class="lineNum">    1867 </span>            :         if (utimescaled)
<span class="lineNum">    1868 </span>            :                 *utimescaled = t-&gt;utimescaled;
<span class="lineNum">    1869 </span>            :         if (stimescaled)
<span class="lineNum">    1870 </span>            :                 *stimescaled = t-&gt;stimescaled;
<span class="lineNum">    1871 </span>            : }
<span class="lineNum">    1872 </span>            : 
<span class="lineNum">    1873 </span>            : static inline cputime_t task_gtime(struct task_struct *t)
<span class="lineNum">    1874 </span>            : {
<span class="lineNum">    1875 </span>            :         return t-&gt;gtime;
<span class="lineNum">    1876 </span>            : }
<span class="lineNum">    1877 </span>            : #endif
<span class="lineNum">    1878 </span>            : extern void task_cputime_adjusted(struct task_struct *p, cputime_t *ut, cputime_t *st);
<span class="lineNum">    1879 </span>            : extern void thread_group_cputime_adjusted(struct task_struct *p, cputime_t *ut, cputime_t *st);
<span class="lineNum">    1880 </span>            : 
<span class="lineNum">    1881 </span>            : /*
<span class="lineNum">    1882 </span>            :  * Per process flags
<span class="lineNum">    1883 </span>            :  */
<span class="lineNum">    1884 </span>            : #define PF_EXITING      0x00000004      /* getting shut down */
<span class="lineNum">    1885 </span>            : #define PF_EXITPIDONE   0x00000008      /* pi exit done on shut down */
<span class="lineNum">    1886 </span>            : #define PF_VCPU         0x00000010      /* I'm a virtual CPU */
<span class="lineNum">    1887 </span>            : #define PF_WQ_WORKER    0x00000020      /* I'm a workqueue worker */
<span class="lineNum">    1888 </span>            : #define PF_FORKNOEXEC   0x00000040      /* forked but didn't exec */
<span class="lineNum">    1889 </span>            : #define PF_MCE_PROCESS  0x00000080      /* process policy on mce errors */
<span class="lineNum">    1890 </span>            : #define PF_SUPERPRIV    0x00000100      /* used super-user privileges */
<span class="lineNum">    1891 </span>            : #define PF_DUMPCORE     0x00000200      /* dumped core */
<span class="lineNum">    1892 </span>            : #define PF_SIGNALED     0x00000400      /* killed by a signal */
<span class="lineNum">    1893 </span>            : #define PF_MEMALLOC     0x00000800      /* Allocating memory */
<span class="lineNum">    1894 </span>            : #define PF_NPROC_EXCEEDED 0x00001000    /* set_user noticed that RLIMIT_NPROC was exceeded */
<span class="lineNum">    1895 </span>            : #define PF_USED_MATH    0x00002000      /* if unset the fpu must be initialized before use */
<span class="lineNum">    1896 </span>            : #define PF_USED_ASYNC   0x00004000      /* used async_schedule*(), used by module init */
<span class="lineNum">    1897 </span>            : #define PF_NOFREEZE     0x00008000      /* this thread should not be frozen */
<span class="lineNum">    1898 </span>            : #define PF_FROZEN       0x00010000      /* frozen for system suspend */
<span class="lineNum">    1899 </span>            : #define PF_FSTRANS      0x00020000      /* inside a filesystem transaction */
<span class="lineNum">    1900 </span>            : #define PF_KSWAPD       0x00040000      /* I am kswapd */
<span class="lineNum">    1901 </span>            : #define PF_MEMALLOC_NOIO 0x00080000     /* Allocating memory without IO involved */
<span class="lineNum">    1902 </span>            : #define PF_LESS_THROTTLE 0x00100000     /* Throttle me less: I clean memory */
<span class="lineNum">    1903 </span>            : #define PF_KTHREAD      0x00200000      /* I am a kernel thread */
<span class="lineNum">    1904 </span>            : #define PF_RANDOMIZE    0x00400000      /* randomize virtual address space */
<span class="lineNum">    1905 </span>            : #define PF_SWAPWRITE    0x00800000      /* Allowed to write to swap */
<span class="lineNum">    1906 </span>            : #define PF_NO_SETAFFINITY 0x04000000    /* Userland is not allowed to meddle with cpus_allowed */
<span class="lineNum">    1907 </span>            : #define PF_MCE_EARLY    0x08000000      /* Early kill for mce process policy */
<span class="lineNum">    1908 </span>            : #define PF_MUTEX_TESTER 0x20000000      /* Thread belongs to the rt mutex tester */
<span class="lineNum">    1909 </span>            : #define PF_FREEZER_SKIP 0x40000000      /* Freezer should not count it as freezable */
<span class="lineNum">    1910 </span>            : #define PF_SUSPEND_TASK 0x80000000      /* this thread called freeze_processes and should not be frozen */
<span class="lineNum">    1911 </span>            : 
<span class="lineNum">    1912 </span>            : /*
<span class="lineNum">    1913 </span>            :  * Only the _current_ task can read/write to tsk-&gt;flags, but other
<span class="lineNum">    1914 </span>            :  * tasks can access tsk-&gt;flags in readonly mode for example
<span class="lineNum">    1915 </span>            :  * with tsk_used_math (like during threaded core dumping).
<span class="lineNum">    1916 </span>            :  * There is however an exception to this rule during ptrace
<span class="lineNum">    1917 </span>            :  * or during fork: the ptracer task is allowed to write to the
<span class="lineNum">    1918 </span>            :  * child-&gt;flags of its traced child (same goes for fork, the parent
<span class="lineNum">    1919 </span>            :  * can write to the child-&gt;flags), because we're guaranteed the
<span class="lineNum">    1920 </span>            :  * child is not running and in turn not changing child-&gt;flags
<span class="lineNum">    1921 </span>            :  * at the same time the parent does it.
<span class="lineNum">    1922 </span>            :  */
<span class="lineNum">    1923 </span>            : #define clear_stopped_child_used_math(child) do { (child)-&gt;flags &amp;= ~PF_USED_MATH; } while (0)
<span class="lineNum">    1924 </span>            : #define set_stopped_child_used_math(child) do { (child)-&gt;flags |= PF_USED_MATH; } while (0)
<span class="lineNum">    1925 </span>            : #define clear_used_math() clear_stopped_child_used_math(current)
<span class="lineNum">    1926 </span>            : #define set_used_math() set_stopped_child_used_math(current)
<span class="lineNum">    1927 </span>            : #define conditional_stopped_child_used_math(condition, child) \
<span class="lineNum">    1928 </span>            :         do { (child)-&gt;flags &amp;= ~PF_USED_MATH, (child)-&gt;flags |= (condition) ? PF_USED_MATH : 0; } while (0)
<span class="lineNum">    1929 </span>            : #define conditional_used_math(condition) \
<span class="lineNum">    1930 </span>            :         conditional_stopped_child_used_math(condition, current)
<span class="lineNum">    1931 </span>            : #define copy_to_stopped_child_used_math(child) \
<span class="lineNum">    1932 </span>            :         do { (child)-&gt;flags &amp;= ~PF_USED_MATH, (child)-&gt;flags |= current-&gt;flags &amp; PF_USED_MATH; } while (0)
<span class="lineNum">    1933 </span>            : /* NOTE: this will return 0 or PF_USED_MATH, it will never return 1 */
<span class="lineNum">    1934 </span>            : #define tsk_used_math(p) ((p)-&gt;flags &amp; PF_USED_MATH)
<span class="lineNum">    1935 </span>            : #define used_math() tsk_used_math(current)
<span class="lineNum">    1936 </span>            : 
<span class="lineNum">    1937 </span>            : /* __GFP_IO isn't allowed if PF_MEMALLOC_NOIO is set in current-&gt;flags */
<span class="lineNum">    1938 </span>            : static inline gfp_t memalloc_noio_flags(gfp_t flags)
<span class="lineNum">    1939 </span>            : {
<span class="lineNum">    1940 </span>            :         if (unlikely(current-&gt;flags &amp; PF_MEMALLOC_NOIO))
<span class="lineNum">    1941 </span>            :                 flags &amp;= ~__GFP_IO;
<span class="lineNum">    1942 </span>            :         return flags;
<span class="lineNum">    1943 </span>            : }
<span class="lineNum">    1944 </span>            : 
<span class="lineNum">    1945 </span>            : static inline unsigned int memalloc_noio_save(void)
<span class="lineNum">    1946 </span>            : {
<span class="lineNum">    1947 </span>            :         unsigned int flags = current-&gt;flags &amp; PF_MEMALLOC_NOIO;
<span class="lineNum">    1948 </span>            :         current-&gt;flags |= PF_MEMALLOC_NOIO;
<span class="lineNum">    1949 </span>            :         return flags;
<span class="lineNum">    1950 </span>            : }
<span class="lineNum">    1951 </span>            : 
<span class="lineNum">    1952 </span>            : static inline void memalloc_noio_restore(unsigned int flags)
<span class="lineNum">    1953 </span>            : {
<span class="lineNum">    1954 </span>            :         current-&gt;flags = (current-&gt;flags &amp; ~PF_MEMALLOC_NOIO) | flags;
<span class="lineNum">    1955 </span>            : }
<span class="lineNum">    1956 </span>            : 
<span class="lineNum">    1957 </span>            : /* Per-process atomic flags. */
<span class="lineNum">    1958 </span>            : #define PFA_NO_NEW_PRIVS 0      /* May not gain new privileges. */
<span class="lineNum">    1959 </span>            : #define PFA_SPREAD_PAGE  1      /* Spread page cache over cpuset */
<span class="lineNum">    1960 </span>            : #define PFA_SPREAD_SLAB  2      /* Spread some slab caches over cpuset */
<span class="lineNum">    1961 </span>            : 
<span class="lineNum">    1962 </span>            : 
<span class="lineNum">    1963 </span>            : #define TASK_PFA_TEST(name, func)                                       \
<span class="lineNum">    1964 </span>            :         static inline bool task_##func(struct task_struct *p)           \
<span class="lineNum">    1965 </span>            :         { return test_bit(PFA_##name, &amp;p-&gt;atomic_flags); }
<span class="lineNum">    1966 </span>            : #define TASK_PFA_SET(name, func)                                        \
<span class="lineNum">    1967 </span>            :         static inline void task_set_##func(struct task_struct *p)       \
<span class="lineNum">    1968 </span>            :         { set_bit(PFA_##name, &amp;p-&gt;atomic_flags); }
<span class="lineNum">    1969 </span>            : #define TASK_PFA_CLEAR(name, func)                                      \
<span class="lineNum">    1970 </span>            :         static inline void task_clear_##func(struct task_struct *p)     \
<span class="lineNum">    1971 </span>            :         { clear_bit(PFA_##name, &amp;p-&gt;atomic_flags); }
<span class="lineNum">    1972 </span>            : 
<span class="lineNum">    1973 </span>            : TASK_PFA_TEST(NO_NEW_PRIVS, no_new_privs)
<span class="lineNum">    1974 </span>            : TASK_PFA_SET(NO_NEW_PRIVS, no_new_privs)
<span class="lineNum">    1975 </span>            : 
<span class="lineNum">    1976 </span>            : TASK_PFA_TEST(SPREAD_PAGE, spread_page)
<span class="lineNum">    1977 </span>            : TASK_PFA_SET(SPREAD_PAGE, spread_page)
<span class="lineNum">    1978 </span>            : TASK_PFA_CLEAR(SPREAD_PAGE, spread_page)
<span class="lineNum">    1979 </span>            : 
<span class="lineNum">    1980 </span>            : TASK_PFA_TEST(SPREAD_SLAB, spread_slab)
<span class="lineNum">    1981 </span>            : TASK_PFA_SET(SPREAD_SLAB, spread_slab)
<span class="lineNum">    1982 </span>            : TASK_PFA_CLEAR(SPREAD_SLAB, spread_slab)
<span class="lineNum">    1983 </span>            : 
<span class="lineNum">    1984 </span>            : /*
<span class="lineNum">    1985 </span>            :  * task-&gt;jobctl flags
<span class="lineNum">    1986 </span>            :  */
<span class="lineNum">    1987 </span>            : #define JOBCTL_STOP_SIGMASK     0xffff  /* signr of the last group stop */
<span class="lineNum">    1988 </span>            : 
<span class="lineNum">    1989 </span>            : #define JOBCTL_STOP_DEQUEUED_BIT 16     /* stop signal dequeued */
<span class="lineNum">    1990 </span>            : #define JOBCTL_STOP_PENDING_BIT 17      /* task should stop for group stop */
<span class="lineNum">    1991 </span>            : #define JOBCTL_STOP_CONSUME_BIT 18      /* consume group stop count */
<span class="lineNum">    1992 </span>            : #define JOBCTL_TRAP_STOP_BIT    19      /* trap for STOP */
<span class="lineNum">    1993 </span>            : #define JOBCTL_TRAP_NOTIFY_BIT  20      /* trap for NOTIFY */
<span class="lineNum">    1994 </span>            : #define JOBCTL_TRAPPING_BIT     21      /* switching to TRACED */
<span class="lineNum">    1995 </span>            : #define JOBCTL_LISTENING_BIT    22      /* ptracer is listening for events */
<span class="lineNum">    1996 </span>            : 
<span class="lineNum">    1997 </span>            : #define JOBCTL_STOP_DEQUEUED    (1 &lt;&lt; JOBCTL_STOP_DEQUEUED_BIT)
<span class="lineNum">    1998 </span>            : #define JOBCTL_STOP_PENDING     (1 &lt;&lt; JOBCTL_STOP_PENDING_BIT)
<span class="lineNum">    1999 </span>            : #define JOBCTL_STOP_CONSUME     (1 &lt;&lt; JOBCTL_STOP_CONSUME_BIT)
<span class="lineNum">    2000 </span>            : #define JOBCTL_TRAP_STOP        (1 &lt;&lt; JOBCTL_TRAP_STOP_BIT)
<span class="lineNum">    2001 </span>            : #define JOBCTL_TRAP_NOTIFY      (1 &lt;&lt; JOBCTL_TRAP_NOTIFY_BIT)
<span class="lineNum">    2002 </span>            : #define JOBCTL_TRAPPING         (1 &lt;&lt; JOBCTL_TRAPPING_BIT)
<span class="lineNum">    2003 </span>            : #define JOBCTL_LISTENING        (1 &lt;&lt; JOBCTL_LISTENING_BIT)
<span class="lineNum">    2004 </span>            : 
<span class="lineNum">    2005 </span>            : #define JOBCTL_TRAP_MASK        (JOBCTL_TRAP_STOP | JOBCTL_TRAP_NOTIFY)
<span class="lineNum">    2006 </span>            : #define JOBCTL_PENDING_MASK     (JOBCTL_STOP_PENDING | JOBCTL_TRAP_MASK)
<span class="lineNum">    2007 </span>            : 
<span class="lineNum">    2008 </span>            : extern bool task_set_jobctl_pending(struct task_struct *task,
<span class="lineNum">    2009 </span>            :                                     unsigned int mask);
<span class="lineNum">    2010 </span>            : extern void task_clear_jobctl_trapping(struct task_struct *task);
<span class="lineNum">    2011 </span>            : extern void task_clear_jobctl_pending(struct task_struct *task,
<span class="lineNum">    2012 </span>            :                                       unsigned int mask);
<span class="lineNum">    2013 </span>            : 
<span class="lineNum">    2014 </span>            : #ifdef CONFIG_PREEMPT_RCU
<span class="lineNum">    2015 </span>            : 
<span class="lineNum">    2016 </span>            : #define RCU_READ_UNLOCK_BLOCKED (1 &lt;&lt; 0) /* blocked while in RCU read-side. */
<span class="lineNum">    2017 </span>            : #define RCU_READ_UNLOCK_NEED_QS (1 &lt;&lt; 1) /* RCU core needs CPU response. */
<span class="lineNum">    2018 </span>            : 
<span class="lineNum">    2019 </span>            : static inline void rcu_copy_process(struct task_struct *p)
<span class="lineNum">    2020 </span>            : {
<span class="lineNum">    2021 </span>            :         p-&gt;rcu_read_lock_nesting = 0;
<span class="lineNum">    2022 </span>            :         p-&gt;rcu_read_unlock_special = 0;
<span class="lineNum">    2023 </span>            : #ifdef CONFIG_TREE_PREEMPT_RCU
<span class="lineNum">    2024 </span>            :         p-&gt;rcu_blocked_node = NULL;
<span class="lineNum">    2025 </span>            : #endif /* #ifdef CONFIG_TREE_PREEMPT_RCU */
<span class="lineNum">    2026 </span>            :         INIT_LIST_HEAD(&amp;p-&gt;rcu_node_entry);
<span class="lineNum">    2027 </span>            : }
<span class="lineNum">    2028 </span>            : 
<span class="lineNum">    2029 </span>            : #else
<span class="lineNum">    2030 </span>            : 
<span class="lineNum">    2031 </span>            : static inline void rcu_copy_process(struct task_struct *p)
<span class="lineNum">    2032 </span>            : {
<span class="lineNum">    2033 </span>            : }
<span class="lineNum">    2034 </span>            : 
<span class="lineNum">    2035 </span>            : #endif
<span class="lineNum">    2036 </span>            : 
<span class="lineNum">    2037 </span>            : static inline void tsk_restore_flags(struct task_struct *task,
<span class="lineNum">    2038 </span>            :                                 unsigned long orig_flags, unsigned long flags)
<span class="lineNum">    2039 </span>            : {
<span class="lineNum">    2040 </span>            :         task-&gt;flags &amp;= ~flags;
<span class="lineNum">    2041 </span>            :         task-&gt;flags |= orig_flags &amp; flags;
<span class="lineNum">    2042 </span>            : }
<span class="lineNum">    2043 </span>            : 
<span class="lineNum">    2044 </span>            : #ifdef CONFIG_SMP
<span class="lineNum">    2045 </span>            : extern void do_set_cpus_allowed(struct task_struct *p,
<span class="lineNum">    2046 </span>            :                                const struct cpumask *new_mask);
<span class="lineNum">    2047 </span>            : 
<span class="lineNum">    2048 </span>            : extern int set_cpus_allowed_ptr(struct task_struct *p,
<span class="lineNum">    2049 </span>            :                                 const struct cpumask *new_mask);
<span class="lineNum">    2050 </span>            : #else
<span class="lineNum">    2051 </span>            : static inline void do_set_cpus_allowed(struct task_struct *p,
<span class="lineNum">    2052 </span>            :                                       const struct cpumask *new_mask)
<span class="lineNum">    2053 </span>            : {
<span class="lineNum">    2054 </span>            : }
<span class="lineNum">    2055 </span>            : static inline int set_cpus_allowed_ptr(struct task_struct *p,
<span class="lineNum">    2056 </span>            :                                        const struct cpumask *new_mask)
<span class="lineNum">    2057 </span>            : {
<span class="lineNum">    2058 </span>            :         if (!cpumask_test_cpu(0, new_mask))
<span class="lineNum">    2059 </span>            :                 return -EINVAL;
<span class="lineNum">    2060 </span>            :         return 0;
<span class="lineNum">    2061 </span>            : }
<span class="lineNum">    2062 </span>            : #endif
<span class="lineNum">    2063 </span>            : 
<span class="lineNum">    2064 </span>            : #ifdef CONFIG_NO_HZ_COMMON
<span class="lineNum">    2065 </span>            : void calc_load_enter_idle(void);
<span class="lineNum">    2066 </span>            : void calc_load_exit_idle(void);
<span class="lineNum">    2067 </span>            : #else
<span class="lineNum">    2068 </span>            : static inline void calc_load_enter_idle(void) { }
<span class="lineNum">    2069 </span>            : static inline void calc_load_exit_idle(void) { }
<span class="lineNum">    2070 </span>            : #endif /* CONFIG_NO_HZ_COMMON */
<span class="lineNum">    2071 </span>            : 
<span class="lineNum">    2072 </span>            : #ifndef CONFIG_CPUMASK_OFFSTACK
<span class="lineNum">    2073 </span>            : static inline int set_cpus_allowed(struct task_struct *p, cpumask_t new_mask)
<span class="lineNum">    2074 </span>            : {
<span class="lineNum">    2075 </span>            :         return set_cpus_allowed_ptr(p, &amp;new_mask);
<span class="lineNum">    2076 </span>            : }
<span class="lineNum">    2077 </span>            : #endif
<span class="lineNum">    2078 </span>            : 
<span class="lineNum">    2079 </span>            : /*
<span class="lineNum">    2080 </span>            :  * Do not use outside of architecture code which knows its limitations.
<span class="lineNum">    2081 </span>            :  *
<span class="lineNum">    2082 </span>            :  * sched_clock() has no promise of monotonicity or bounded drift between
<span class="lineNum">    2083 </span>            :  * CPUs, use (which you should not) requires disabling IRQs.
<span class="lineNum">    2084 </span>            :  *
<span class="lineNum">    2085 </span>            :  * Please use one of the three interfaces below.
<span class="lineNum">    2086 </span>            :  */
<span class="lineNum">    2087 </span>            : extern unsigned long long notrace sched_clock(void);
<span class="lineNum">    2088 </span>            : /*
<span class="lineNum">    2089 </span>            :  * See the comment in kernel/sched/clock.c
<span class="lineNum">    2090 </span>            :  */
<span class="lineNum">    2091 </span>            : extern u64 cpu_clock(int cpu);
<span class="lineNum">    2092 </span>            : extern u64 local_clock(void);
<span class="lineNum">    2093 </span>            : extern u64 sched_clock_cpu(int cpu);
<span class="lineNum">    2094 </span>            : 
<span class="lineNum">    2095 </span>            : 
<span class="lineNum">    2096 </span>            : extern void sched_clock_init(void);
<span class="lineNum">    2097 </span>            : 
<span class="lineNum">    2098 </span>            : #ifndef CONFIG_HAVE_UNSTABLE_SCHED_CLOCK
<span class="lineNum">    2099 </span>            : static inline void sched_clock_tick(void)
<span class="lineNum">    2100 </span>            : {
<span class="lineNum">    2101 </span>            : }
<span class="lineNum">    2102 </span>            : 
<span class="lineNum">    2103 </span>            : static inline void sched_clock_idle_sleep_event(void)
<span class="lineNum">    2104 </span>            : {
<span class="lineNum">    2105 </span>            : }
<span class="lineNum">    2106 </span>            : 
<span class="lineNum">    2107 </span>            : static inline void sched_clock_idle_wakeup_event(u64 delta_ns)
<span class="lineNum">    2108 </span>            : {
<span class="lineNum">    2109 </span>            : }
<span class="lineNum">    2110 </span>            : #else
<span class="lineNum">    2111 </span>            : /*
<span class="lineNum">    2112 </span>            :  * Architectures can set this to 1 if they have specified
<span class="lineNum">    2113 </span>            :  * CONFIG_HAVE_UNSTABLE_SCHED_CLOCK in their arch Kconfig,
<span class="lineNum">    2114 </span>            :  * but then during bootup it turns out that sched_clock()
<span class="lineNum">    2115 </span>            :  * is reliable after all:
<span class="lineNum">    2116 </span>            :  */
<span class="lineNum">    2117 </span>            : extern int sched_clock_stable(void);
<span class="lineNum">    2118 </span>            : extern void set_sched_clock_stable(void);
<span class="lineNum">    2119 </span>            : extern void clear_sched_clock_stable(void);
<span class="lineNum">    2120 </span>            : 
<span class="lineNum">    2121 </span>            : extern void sched_clock_tick(void);
<span class="lineNum">    2122 </span>            : extern void sched_clock_idle_sleep_event(void);
<span class="lineNum">    2123 </span>            : extern void sched_clock_idle_wakeup_event(u64 delta_ns);
<span class="lineNum">    2124 </span>            : #endif
<span class="lineNum">    2125 </span>            : 
<span class="lineNum">    2126 </span>            : #ifdef CONFIG_IRQ_TIME_ACCOUNTING
<span class="lineNum">    2127 </span>            : /*
<span class="lineNum">    2128 </span>            :  * An i/f to runtime opt-in for irq time accounting based off of sched_clock.
<span class="lineNum">    2129 </span>            :  * The reason for this explicit opt-in is not to have perf penalty with
<span class="lineNum">    2130 </span>            :  * slow sched_clocks.
<span class="lineNum">    2131 </span>            :  */
<span class="lineNum">    2132 </span>            : extern void enable_sched_clock_irqtime(void);
<span class="lineNum">    2133 </span>            : extern void disable_sched_clock_irqtime(void);
<span class="lineNum">    2134 </span>            : #else
<span class="lineNum">    2135 </span>            : static inline void enable_sched_clock_irqtime(void) {}
<span class="lineNum">    2136 </span>            : static inline void disable_sched_clock_irqtime(void) {}
<span class="lineNum">    2137 </span>            : #endif
<span class="lineNum">    2138 </span>            : 
<span class="lineNum">    2139 </span>            : extern unsigned long long
<span class="lineNum">    2140 </span>            : task_sched_runtime(struct task_struct *task);
<span class="lineNum">    2141 </span>            : 
<span class="lineNum">    2142 </span>            : /* sched_exec is called by processes performing an exec */
<span class="lineNum">    2143 </span>            : #ifdef CONFIG_SMP
<span class="lineNum">    2144 </span>            : extern void sched_exec(void);
<span class="lineNum">    2145 </span>            : #else
<span class="lineNum">    2146 </span>            : #define sched_exec()   {}
<span class="lineNum">    2147 </span>            : #endif
<span class="lineNum">    2148 </span>            : 
<span class="lineNum">    2149 </span>            : extern void sched_clock_idle_sleep_event(void);
<span class="lineNum">    2150 </span>            : extern void sched_clock_idle_wakeup_event(u64 delta_ns);
<span class="lineNum">    2151 </span>            : 
<span class="lineNum">    2152 </span>            : #ifdef CONFIG_HOTPLUG_CPU
<span class="lineNum">    2153 </span>            : extern void idle_task_exit(void);
<span class="lineNum">    2154 </span>            : #else
<span class="lineNum">    2155 </span>            : static inline void idle_task_exit(void) {}
<span class="lineNum">    2156 </span>            : #endif
<span class="lineNum">    2157 </span>            : 
<span class="lineNum">    2158 </span>            : #if defined(CONFIG_NO_HZ_COMMON) &amp;&amp; defined(CONFIG_SMP)
<span class="lineNum">    2159 </span>            : extern void wake_up_nohz_cpu(int cpu);
<span class="lineNum">    2160 </span>            : #else
<span class="lineNum">    2161 </span>            : static inline void wake_up_nohz_cpu(int cpu) { }
<span class="lineNum">    2162 </span>            : #endif
<span class="lineNum">    2163 </span>            : 
<span class="lineNum">    2164 </span>            : #ifdef CONFIG_NO_HZ_FULL
<span class="lineNum">    2165 </span>            : extern bool sched_can_stop_tick(void);
<span class="lineNum">    2166 </span>            : extern u64 scheduler_tick_max_deferment(void);
<span class="lineNum">    2167 </span>            : #else
<span class="lineNum">    2168 </span>            : static inline bool sched_can_stop_tick(void) { return false; }
<span class="lineNum">    2169 </span>            : #endif
<span class="lineNum">    2170 </span>            : 
<span class="lineNum">    2171 </span>            : #ifdef CONFIG_SCHED_AUTOGROUP
<span class="lineNum">    2172 </span>            : extern void sched_autogroup_create_attach(struct task_struct *p);
<span class="lineNum">    2173 </span>            : extern void sched_autogroup_detach(struct task_struct *p);
<span class="lineNum">    2174 </span>            : extern void sched_autogroup_fork(struct signal_struct *sig);
<span class="lineNum">    2175 </span>            : extern void sched_autogroup_exit(struct signal_struct *sig);
<span class="lineNum">    2176 </span>            : #ifdef CONFIG_PROC_FS
<span class="lineNum">    2177 </span>            : extern void proc_sched_autogroup_show_task(struct task_struct *p, struct seq_file *m);
<span class="lineNum">    2178 </span>            : extern int proc_sched_autogroup_set_nice(struct task_struct *p, int nice);
<span class="lineNum">    2179 </span>            : #endif
<span class="lineNum">    2180 </span>            : #else
<span class="lineNum">    2181 </span>            : static inline void sched_autogroup_create_attach(struct task_struct *p) { }
<span class="lineNum">    2182 </span>            : static inline void sched_autogroup_detach(struct task_struct *p) { }
<span class="lineNum">    2183 </span>            : static inline void sched_autogroup_fork(struct signal_struct *sig) { }
<span class="lineNum">    2184 </span>            : static inline void sched_autogroup_exit(struct signal_struct *sig) { }
<span class="lineNum">    2185 </span>            : #endif
<span class="lineNum">    2186 </span>            : 
<span class="lineNum">    2187 </span>            : extern int yield_to(struct task_struct *p, bool preempt);
<span class="lineNum">    2188 </span>            : extern void set_user_nice(struct task_struct *p, long nice);
<span class="lineNum">    2189 </span>            : extern int task_prio(const struct task_struct *p);
<span class="lineNum">    2190 </span>            : /**
<span class="lineNum">    2191 </span>            :  * task_nice - return the nice value of a given task.
<span class="lineNum">    2192 </span>            :  * @p: the task in question.
<span class="lineNum">    2193 </span>            :  *
<span class="lineNum">    2194 </span>            :  * Return: The nice value [ -20 ... 0 ... 19 ].
<span class="lineNum">    2195 </span>            :  */
<span class="lineNum">    2196 </span>            : static inline int task_nice(const struct task_struct *p)
<span class="lineNum">    2197 </span>            : {
<span class="lineNum">    2198 </span><span class="lineCov">        372 :         return PRIO_TO_NICE((p)-&gt;static_prio);</span>
<span class="lineNum">    2199 </span>            : }
<span class="lineNum">    2200 </span>            : extern int can_nice(const struct task_struct *p, const int nice);
<span class="lineNum">    2201 </span>            : extern int task_curr(const struct task_struct *p);
<span class="lineNum">    2202 </span>            : extern int idle_cpu(int cpu);
<span class="lineNum">    2203 </span>            : extern int sched_setscheduler(struct task_struct *, int,
<span class="lineNum">    2204 </span>            :                               const struct sched_param *);
<span class="lineNum">    2205 </span>            : extern int sched_setscheduler_nocheck(struct task_struct *, int,
<span class="lineNum">    2206 </span>            :                                       const struct sched_param *);
<span class="lineNum">    2207 </span>            : extern int sched_setattr(struct task_struct *,
<span class="lineNum">    2208 </span>            :                          const struct sched_attr *);
<span class="lineNum">    2209 </span>            : extern struct task_struct *idle_task(int cpu);
<span class="lineNum">    2210 </span>            : /**
<span class="lineNum">    2211 </span>            :  * is_idle_task - is the specified task an idle task?
<span class="lineNum">    2212 </span>            :  * @p: the task in question.
<span class="lineNum">    2213 </span>            :  *
<span class="lineNum">    2214 </span>            :  * Return: 1 if @p is an idle task. 0 otherwise.
<span class="lineNum">    2215 </span>            :  */
<span class="lineNum">    2216 </span>            : static inline bool is_idle_task(const struct task_struct *p)
<span class="lineNum">    2217 </span>            : {
<span class="lineNum">    2218 </span>            :         return p-&gt;pid == 0;
<span class="lineNum">    2219 </span>            : }
<span class="lineNum">    2220 </span>            : extern struct task_struct *curr_task(int cpu);
<span class="lineNum">    2221 </span>            : extern void set_curr_task(int cpu, struct task_struct *p);
<span class="lineNum">    2222 </span>            : 
<span class="lineNum">    2223 </span>            : void yield(void);
<span class="lineNum">    2224 </span>            : 
<span class="lineNum">    2225 </span>            : /*
<span class="lineNum">    2226 </span>            :  * The default (Linux) execution domain.
<span class="lineNum">    2227 </span>            :  */
<span class="lineNum">    2228 </span>            : extern struct exec_domain       default_exec_domain;
<span class="lineNum">    2229 </span>            : 
<span class="lineNum">    2230 </span>            : union thread_union {
<span class="lineNum">    2231 </span>            :         struct thread_info thread_info;
<span class="lineNum">    2232 </span>            :         unsigned long stack[THREAD_SIZE/sizeof(long)];
<span class="lineNum">    2233 </span>            : };
<span class="lineNum">    2234 </span>            : 
<span class="lineNum">    2235 </span>            : #ifndef __HAVE_ARCH_KSTACK_END
<span class="lineNum">    2236 </span>            : static inline int kstack_end(void *addr)
<span class="lineNum">    2237 </span>            : {
<span class="lineNum">    2238 </span>            :         /* Reliable end of stack detection:
<span class="lineNum">    2239 </span>            :          * Some APM bios versions misalign the stack
<span class="lineNum">    2240 </span>            :          */
<span class="lineNum">    2241 </span>            :         return !(((unsigned long)addr+sizeof(void*)-1) &amp; (THREAD_SIZE-sizeof(void*)));
<span class="lineNum">    2242 </span>            : }
<span class="lineNum">    2243 </span>            : #endif
<span class="lineNum">    2244 </span>            : 
<span class="lineNum">    2245 </span>            : extern union thread_union init_thread_union;
<span class="lineNum">    2246 </span>            : extern struct task_struct init_task;
<span class="lineNum">    2247 </span>            : 
<span class="lineNum">    2248 </span>            : extern struct   mm_struct init_mm;
<span class="lineNum">    2249 </span>            : 
<span class="lineNum">    2250 </span>            : extern struct pid_namespace init_pid_ns;
<span class="lineNum">    2251 </span>            : 
<span class="lineNum">    2252 </span>            : /*
<span class="lineNum">    2253 </span>            :  * find a task by one of its numerical ids
<span class="lineNum">    2254 </span>            :  *
<span class="lineNum">    2255 </span>            :  * find_task_by_pid_ns():
<span class="lineNum">    2256 </span>            :  *      finds a task by its pid in the specified namespace
<span class="lineNum">    2257 </span>            :  * find_task_by_vpid():
<span class="lineNum">    2258 </span>            :  *      finds a task by its virtual pid
<span class="lineNum">    2259 </span>            :  *
<span class="lineNum">    2260 </span>            :  * see also find_vpid() etc in include/linux/pid.h
<span class="lineNum">    2261 </span>            :  */
<span class="lineNum">    2262 </span>            : 
<span class="lineNum">    2263 </span>            : extern struct task_struct *find_task_by_vpid(pid_t nr);
<span class="lineNum">    2264 </span>            : extern struct task_struct *find_task_by_pid_ns(pid_t nr,
<span class="lineNum">    2265 </span>            :                 struct pid_namespace *ns);
<span class="lineNum">    2266 </span>            : 
<span class="lineNum">    2267 </span>            : /* per-UID process charging. */
<span class="lineNum">    2268 </span>            : extern struct user_struct * alloc_uid(kuid_t);
<span class="lineNum">    2269 </span>            : static inline struct user_struct *get_uid(struct user_struct *u)
<span class="lineNum">    2270 </span>            : {
<span class="lineNum">    2271 </span>            :         atomic_inc(&amp;u-&gt;__count);
<span class="lineNum">    2272 </span>            :         return u;
<span class="lineNum">    2273 </span>            : }
<span class="lineNum">    2274 </span>            : extern void free_uid(struct user_struct *);
<span class="lineNum">    2275 </span>            : 
<span class="lineNum">    2276 </span>            : #include &lt;asm/current.h&gt;
<span class="lineNum">    2277 </span>            : 
<span class="lineNum">    2278 </span>            : extern void xtime_update(unsigned long ticks);
<span class="lineNum">    2279 </span>            : 
<span class="lineNum">    2280 </span>            : extern int wake_up_state(struct task_struct *tsk, unsigned int state);
<span class="lineNum">    2281 </span>            : extern int wake_up_process(struct task_struct *tsk);
<span class="lineNum">    2282 </span>            : extern void wake_up_new_task(struct task_struct *tsk);
<span class="lineNum">    2283 </span>            : #ifdef CONFIG_SMP
<span class="lineNum">    2284 </span>            :  extern void kick_process(struct task_struct *tsk);
<span class="lineNum">    2285 </span>            : #else
<span class="lineNum">    2286 </span>            :  static inline void kick_process(struct task_struct *tsk) { }
<span class="lineNum">    2287 </span>            : #endif
<span class="lineNum">    2288 </span>            : extern int sched_fork(unsigned long clone_flags, struct task_struct *p);
<span class="lineNum">    2289 </span>            : extern void sched_dead(struct task_struct *p);
<span class="lineNum">    2290 </span>            : 
<span class="lineNum">    2291 </span>            : extern void proc_caches_init(void);
<span class="lineNum">    2292 </span>            : extern void flush_signals(struct task_struct *);
<span class="lineNum">    2293 </span>            : extern void __flush_signals(struct task_struct *);
<span class="lineNum">    2294 </span>            : extern void ignore_signals(struct task_struct *);
<span class="lineNum">    2295 </span>            : extern void flush_signal_handlers(struct task_struct *, int force_default);
<span class="lineNum">    2296 </span>            : extern int dequeue_signal(struct task_struct *tsk, sigset_t *mask, siginfo_t *info);
<span class="lineNum">    2297 </span>            : 
<span class="lineNum">    2298 </span>            : static inline int dequeue_signal_lock(struct task_struct *tsk, sigset_t *mask, siginfo_t *info)
<span class="lineNum">    2299 </span>            : {
<span class="lineNum">    2300 </span>            :         unsigned long flags;
<span class="lineNum">    2301 </span>            :         int ret;
<span class="lineNum">    2302 </span>            : 
<span class="lineNum">    2303 </span>            :         spin_lock_irqsave(&amp;tsk-&gt;sighand-&gt;siglock, flags);
<span class="lineNum">    2304 </span>            :         ret = dequeue_signal(tsk, mask, info);
<span class="lineNum">    2305 </span>            :         spin_unlock_irqrestore(&amp;tsk-&gt;sighand-&gt;siglock, flags);
<span class="lineNum">    2306 </span>            : 
<span class="lineNum">    2307 </span>            :         return ret;
<span class="lineNum">    2308 </span>            : }
<span class="lineNum">    2309 </span>            : 
<span class="lineNum">    2310 </span>            : extern void block_all_signals(int (*notifier)(void *priv), void *priv,
<span class="lineNum">    2311 </span>            :                               sigset_t *mask);
<span class="lineNum">    2312 </span>            : extern void unblock_all_signals(void);
<span class="lineNum">    2313 </span>            : extern void release_task(struct task_struct * p);
<span class="lineNum">    2314 </span>            : extern int send_sig_info(int, struct siginfo *, struct task_struct *);
<span class="lineNum">    2315 </span>            : extern int force_sigsegv(int, struct task_struct *);
<span class="lineNum">    2316 </span>            : extern int force_sig_info(int, struct siginfo *, struct task_struct *);
<span class="lineNum">    2317 </span>            : extern int __kill_pgrp_info(int sig, struct siginfo *info, struct pid *pgrp);
<span class="lineNum">    2318 </span>            : extern int kill_pid_info(int sig, struct siginfo *info, struct pid *pid);
<span class="lineNum">    2319 </span>            : extern int kill_pid_info_as_cred(int, struct siginfo *, struct pid *,
<span class="lineNum">    2320 </span>            :                                 const struct cred *, u32);
<span class="lineNum">    2321 </span>            : extern int kill_pgrp(struct pid *pid, int sig, int priv);
<span class="lineNum">    2322 </span>            : extern int kill_pid(struct pid *pid, int sig, int priv);
<span class="lineNum">    2323 </span>            : extern int kill_proc_info(int, struct siginfo *, pid_t);
<span class="lineNum">    2324 </span>            : extern __must_check bool do_notify_parent(struct task_struct *, int);
<span class="lineNum">    2325 </span>            : extern void __wake_up_parent(struct task_struct *p, struct task_struct *parent);
<span class="lineNum">    2326 </span>            : extern void force_sig(int, struct task_struct *);
<span class="lineNum">    2327 </span>            : extern int send_sig(int, struct task_struct *, int);
<span class="lineNum">    2328 </span>            : extern int zap_other_threads(struct task_struct *p);
<span class="lineNum">    2329 </span>            : extern struct sigqueue *sigqueue_alloc(void);
<span class="lineNum">    2330 </span>            : extern void sigqueue_free(struct sigqueue *);
<span class="lineNum">    2331 </span>            : extern int send_sigqueue(struct sigqueue *,  struct task_struct *, int group);
<span class="lineNum">    2332 </span>            : extern int do_sigaction(int, struct k_sigaction *, struct k_sigaction *);
<span class="lineNum">    2333 </span>            : 
<span class="lineNum">    2334 </span>            : static inline void restore_saved_sigmask(void)
<span class="lineNum">    2335 </span>            : {
<span class="lineNum">    2336 </span>            :         if (test_and_clear_restore_sigmask())
<span class="lineNum">    2337 </span>            :                 __set_current_blocked(&amp;current-&gt;saved_sigmask);
<span class="lineNum">    2338 </span>            : }
<span class="lineNum">    2339 </span>            : 
<span class="lineNum">    2340 </span>            : static inline sigset_t *sigmask_to_save(void)
<span class="lineNum">    2341 </span>            : {
<span class="lineNum">    2342 </span>            :         sigset_t *res = &amp;current-&gt;blocked;
<span class="lineNum">    2343 </span>            :         if (unlikely(test_restore_sigmask()))
<span class="lineNum">    2344 </span>            :                 res = &amp;current-&gt;saved_sigmask;
<span class="lineNum">    2345 </span>            :         return res;
<span class="lineNum">    2346 </span>            : }
<span class="lineNum">    2347 </span>            : 
<span class="lineNum">    2348 </span>            : static inline int kill_cad_pid(int sig, int priv)
<span class="lineNum">    2349 </span>            : {
<span class="lineNum">    2350 </span>            :         return kill_pid(cad_pid, sig, priv);
<span class="lineNum">    2351 </span>            : }
<span class="lineNum">    2352 </span>            : 
<span class="lineNum">    2353 </span>            : /* These can be the second arg to send_sig_info/send_group_sig_info.  */
<span class="lineNum">    2354 </span>            : #define SEND_SIG_NOINFO ((struct siginfo *) 0)
<span class="lineNum">    2355 </span>            : #define SEND_SIG_PRIV   ((struct siginfo *) 1)
<span class="lineNum">    2356 </span>            : #define SEND_SIG_FORCED ((struct siginfo *) 2)
<span class="lineNum">    2357 </span>            : 
<span class="lineNum">    2358 </span>            : /*
<span class="lineNum">    2359 </span>            :  * True if we are on the alternate signal stack.
<span class="lineNum">    2360 </span>            :  */
<span class="lineNum">    2361 </span>            : static inline int on_sig_stack(unsigned long sp)
<span class="lineNum">    2362 </span>            : {
<span class="lineNum">    2363 </span>            : #ifdef CONFIG_STACK_GROWSUP
<span class="lineNum">    2364 </span>            :         return sp &gt;= current-&gt;sas_ss_sp &amp;&amp;
<span class="lineNum">    2365 </span>            :                 sp - current-&gt;sas_ss_sp &lt; current-&gt;sas_ss_size;
<span class="lineNum">    2366 </span>            : #else
<span class="lineNum">    2367 </span>            :         return sp &gt; current-&gt;sas_ss_sp &amp;&amp;
<span class="lineNum">    2368 </span>            :                 sp - current-&gt;sas_ss_sp &lt;= current-&gt;sas_ss_size;
<span class="lineNum">    2369 </span>            : #endif
<span class="lineNum">    2370 </span>            : }
<span class="lineNum">    2371 </span>            : 
<span class="lineNum">    2372 </span>            : static inline int sas_ss_flags(unsigned long sp)
<span class="lineNum">    2373 </span>            : {
<span class="lineNum">    2374 </span>            :         if (!current-&gt;sas_ss_size)
<span class="lineNum">    2375 </span>            :                 return SS_DISABLE;
<span class="lineNum">    2376 </span>            : 
<span class="lineNum">    2377 </span>            :         return on_sig_stack(sp) ? SS_ONSTACK : 0;
<span class="lineNum">    2378 </span>            : }
<span class="lineNum">    2379 </span>            : 
<span class="lineNum">    2380 </span>            : static inline unsigned long sigsp(unsigned long sp, struct ksignal *ksig)
<span class="lineNum">    2381 </span>            : {
<span class="lineNum">    2382 </span>            :         if (unlikely((ksig-&gt;ka.sa.sa_flags &amp; SA_ONSTACK)) &amp;&amp; ! sas_ss_flags(sp))
<span class="lineNum">    2383 </span>            : #ifdef CONFIG_STACK_GROWSUP
<span class="lineNum">    2384 </span>            :                 return current-&gt;sas_ss_sp;
<span class="lineNum">    2385 </span>            : #else
<span class="lineNum">    2386 </span>            :                 return current-&gt;sas_ss_sp + current-&gt;sas_ss_size;
<span class="lineNum">    2387 </span>            : #endif
<span class="lineNum">    2388 </span>            :         return sp;
<span class="lineNum">    2389 </span>            : }
<span class="lineNum">    2390 </span>            : 
<span class="lineNum">    2391 </span>            : /*
<span class="lineNum">    2392 </span>            :  * Routines for handling mm_structs
<span class="lineNum">    2393 </span>            :  */
<span class="lineNum">    2394 </span>            : extern struct mm_struct * mm_alloc(void);
<span class="lineNum">    2395 </span>            : 
<span class="lineNum">    2396 </span>            : /* mmdrop drops the mm and the page tables */
<span class="lineNum">    2397 </span>            : extern void __mmdrop(struct mm_struct *);
<span class="lineNum">    2398 </span>            : static inline void mmdrop(struct mm_struct * mm)
<span class="lineNum">    2399 </span>            : {
<span class="lineNum">    2400 </span>            :         if (unlikely(atomic_dec_and_test(&amp;mm-&gt;mm_count)))
<span class="lineNum">    2401 </span>            :                 __mmdrop(mm);
<span class="lineNum">    2402 </span>            : }
<span class="lineNum">    2403 </span>            : 
<span class="lineNum">    2404 </span>            : /* mmput gets rid of the mappings and all user-space */
<span class="lineNum">    2405 </span>            : extern void mmput(struct mm_struct *);
<span class="lineNum">    2406 </span>            : /* Grab a reference to a task's mm, if it is not already going away */
<span class="lineNum">    2407 </span>            : extern struct mm_struct *get_task_mm(struct task_struct *task);
<span class="lineNum">    2408 </span>            : /*
<span class="lineNum">    2409 </span>            :  * Grab a reference to a task's mm, if it is not already going away
<span class="lineNum">    2410 </span>            :  * and ptrace_may_access with the mode parameter passed to it
<span class="lineNum">    2411 </span>            :  * succeeds.
<span class="lineNum">    2412 </span>            :  */
<span class="lineNum">    2413 </span>            : extern struct mm_struct *mm_access(struct task_struct *task, unsigned int mode);
<span class="lineNum">    2414 </span>            : /* Remove the current tasks stale references to the old mm_struct */
<span class="lineNum">    2415 </span>            : extern void mm_release(struct task_struct *, struct mm_struct *);
<span class="lineNum">    2416 </span>            : 
<span class="lineNum">    2417 </span>            : extern int copy_thread(unsigned long, unsigned long, unsigned long,
<span class="lineNum">    2418 </span>            :                         struct task_struct *);
<span class="lineNum">    2419 </span>            : extern void flush_thread(void);
<span class="lineNum">    2420 </span>            : extern void exit_thread(void);
<span class="lineNum">    2421 </span>            : 
<span class="lineNum">    2422 </span>            : extern void exit_files(struct task_struct *);
<span class="lineNum">    2423 </span>            : extern void __cleanup_sighand(struct sighand_struct *);
<span class="lineNum">    2424 </span>            : 
<span class="lineNum">    2425 </span>            : extern void exit_itimers(struct signal_struct *);
<span class="lineNum">    2426 </span>            : extern void flush_itimer_signals(void);
<span class="lineNum">    2427 </span>            : 
<span class="lineNum">    2428 </span>            : extern void do_group_exit(int);
<span class="lineNum">    2429 </span>            : 
<span class="lineNum">    2430 </span>            : extern int do_execve(struct filename *,
<span class="lineNum">    2431 </span>            :                      const char __user * const __user *,
<span class="lineNum">    2432 </span>            :                      const char __user * const __user *);
<span class="lineNum">    2433 </span>            : extern long do_fork(unsigned long, unsigned long, unsigned long, int __user *, int __user *);
<span class="lineNum">    2434 </span>            : struct task_struct *fork_idle(int);
<span class="lineNum">    2435 </span>            : extern pid_t kernel_thread(int (*fn)(void *), void *arg, unsigned long flags);
<span class="lineNum">    2436 </span>            : 
<span class="lineNum">    2437 </span>            : extern void __set_task_comm(struct task_struct *tsk, const char *from, bool exec);
<span class="lineNum">    2438 </span>            : static inline void set_task_comm(struct task_struct *tsk, const char *from)
<span class="lineNum">    2439 </span>            : {
<span class="lineNum">    2440 </span>            :         __set_task_comm(tsk, from, false);
<span class="lineNum">    2441 </span>            : }
<span class="lineNum">    2442 </span>            : extern char *get_task_comm(char *to, struct task_struct *tsk);
<span class="lineNum">    2443 </span>            : 
<span class="lineNum">    2444 </span>            : #ifdef CONFIG_SMP
<span class="lineNum">    2445 </span>            : void scheduler_ipi(void);
<span class="lineNum">    2446 </span>            : extern unsigned long wait_task_inactive(struct task_struct *, long match_state);
<span class="lineNum">    2447 </span>            : #else
<span class="lineNum">    2448 </span>            : static inline void scheduler_ipi(void) { }
<span class="lineNum">    2449 </span>            : static inline unsigned long wait_task_inactive(struct task_struct *p,
<span class="lineNum">    2450 </span>            :                                                long match_state)
<span class="lineNum">    2451 </span>            : {
<span class="lineNum">    2452 </span>            :         return 1;
<span class="lineNum">    2453 </span>            : }
<span class="lineNum">    2454 </span>            : #endif
<span class="lineNum">    2455 </span>            : 
<span class="lineNum">    2456 </span>            : #define next_task(p) \
<span class="lineNum">    2457 </span>            :         list_entry_rcu((p)-&gt;tasks.next, struct task_struct, tasks)
<span class="lineNum">    2458 </span>            : 
<span class="lineNum">    2459 </span>            : #define for_each_process(p) \
<span class="lineNum">    2460 </span>            :         for (p = &amp;init_task ; (p = next_task(p)) != &amp;init_task ; )
<span class="lineNum">    2461 </span>            : 
<span class="lineNum">    2462 </span>            : extern bool current_is_single_threaded(void);
<span class="lineNum">    2463 </span>            : 
<span class="lineNum">    2464 </span>            : /*
<span class="lineNum">    2465 </span>            :  * Careful: do_each_thread/while_each_thread is a double loop so
<span class="lineNum">    2466 </span>            :  *          'break' will not work as expected - use goto instead.
<span class="lineNum">    2467 </span>            :  */
<span class="lineNum">    2468 </span>            : #define do_each_thread(g, t) \
<span class="lineNum">    2469 </span>            :         for (g = t = &amp;init_task ; (g = t = next_task(g)) != &amp;init_task ; ) do
<span class="lineNum">    2470 </span>            : 
<span class="lineNum">    2471 </span>            : #define while_each_thread(g, t) \
<span class="lineNum">    2472 </span>            :         while ((t = next_thread(t)) != g)
<span class="lineNum">    2473 </span>            : 
<span class="lineNum">    2474 </span>            : #define __for_each_thread(signal, t)    \
<span class="lineNum">    2475 </span>            :         list_for_each_entry_rcu(t, &amp;(signal)-&gt;thread_head, thread_node)
<span class="lineNum">    2476 </span>            : 
<span class="lineNum">    2477 </span>            : #define for_each_thread(p, t)           \
<span class="lineNum">    2478 </span>            :         __for_each_thread((p)-&gt;signal, t)
<span class="lineNum">    2479 </span>            : 
<span class="lineNum">    2480 </span>            : /* Careful: this is a double loop, 'break' won't work as expected. */
<span class="lineNum">    2481 </span>            : #define for_each_process_thread(p, t)   \
<span class="lineNum">    2482 </span>            :         for_each_process(p) for_each_thread(p, t)
<span class="lineNum">    2483 </span>            : 
<span class="lineNum">    2484 </span>            : static inline int get_nr_threads(struct task_struct *tsk)
<span class="lineNum">    2485 </span>            : {
<span class="lineNum">    2486 </span>            :         return tsk-&gt;signal-&gt;nr_threads;
<span class="lineNum">    2487 </span>            : }
<span class="lineNum">    2488 </span>            : 
<span class="lineNum">    2489 </span>            : static inline bool thread_group_leader(struct task_struct *p)
<span class="lineNum">    2490 </span>            : {
<span class="lineNum">    2491 </span>            :         return p-&gt;exit_signal &gt;= 0;
<span class="lineNum">    2492 </span>            : }
<span class="lineNum">    2493 </span>            : 
<span class="lineNum">    2494 </span>            : /* Do to the insanities of de_thread it is possible for a process
<span class="lineNum">    2495 </span>            :  * to have the pid of the thread group leader without actually being
<span class="lineNum">    2496 </span>            :  * the thread group leader.  For iteration through the pids in proc
<span class="lineNum">    2497 </span>            :  * all we care about is that we have a task with the appropriate
<span class="lineNum">    2498 </span>            :  * pid, we don't actually care if we have the right task.
<span class="lineNum">    2499 </span>            :  */
<span class="lineNum">    2500 </span>            : static inline bool has_group_leader_pid(struct task_struct *p)
<span class="lineNum">    2501 </span>            : {
<span class="lineNum">    2502 </span>            :         return task_pid(p) == p-&gt;signal-&gt;leader_pid;
<span class="lineNum">    2503 </span>            : }
<span class="lineNum">    2504 </span>            : 
<span class="lineNum">    2505 </span>            : static inline
<span class="lineNum">    2506 </span>            : bool same_thread_group(struct task_struct *p1, struct task_struct *p2)
<span class="lineNum">    2507 </span>            : {
<span class="lineNum">    2508 </span>            :         return p1-&gt;signal == p2-&gt;signal;
<span class="lineNum">    2509 </span>            : }
<span class="lineNum">    2510 </span>            : 
<span class="lineNum">    2511 </span>            : static inline struct task_struct *next_thread(const struct task_struct *p)
<span class="lineNum">    2512 </span>            : {
<span class="lineNum">    2513 </span>            :         return list_entry_rcu(p-&gt;thread_group.next,
<span class="lineNum">    2514 </span>            :                               struct task_struct, thread_group);
<span class="lineNum">    2515 </span>            : }
<span class="lineNum">    2516 </span>            : 
<span class="lineNum">    2517 </span>            : static inline int thread_group_empty(struct task_struct *p)
<span class="lineNum">    2518 </span>            : {
<span class="lineNum">    2519 </span>            :         return list_empty(&amp;p-&gt;thread_group);
<span class="lineNum">    2520 </span>            : }
<span class="lineNum">    2521 </span>            : 
<span class="lineNum">    2522 </span>            : #define delay_group_leader(p) \
<span class="lineNum">    2523 </span>            :                 (thread_group_leader(p) &amp;&amp; !thread_group_empty(p))
<span class="lineNum">    2524 </span>            : 
<span class="lineNum">    2525 </span>            : /*
<span class="lineNum">    2526 </span>            :  * Protects -&gt;fs, -&gt;files, -&gt;mm, -&gt;group_info, -&gt;comm, keyring
<span class="lineNum">    2527 </span>            :  * subscriptions and synchronises with wait4().  Also used in procfs.  Also
<span class="lineNum">    2528 </span>            :  * pins the final release of task.io_context.  Also protects -&gt;cpuset and
<span class="lineNum">    2529 </span>            :  * -&gt;cgroup.subsys[]. And -&gt;vfork_done.
<span class="lineNum">    2530 </span>            :  *
<span class="lineNum">    2531 </span>            :  * Nests both inside and outside of read_lock(&amp;tasklist_lock).
<span class="lineNum">    2532 </span>            :  * It must not be nested with write_lock_irq(&amp;tasklist_lock),
<span class="lineNum">    2533 </span>            :  * neither inside nor outside.
<span class="lineNum">    2534 </span>            :  */
<span class="lineNum">    2535 </span>            : static inline void task_lock(struct task_struct *p)
<span class="lineNum">    2536 </span>            : {
<span class="lineNum">    2537 </span>            :         spin_lock(&amp;p-&gt;alloc_lock);
<span class="lineNum">    2538 </span>            : }
<span class="lineNum">    2539 </span>            : 
<span class="lineNum">    2540 </span>            : static inline void task_unlock(struct task_struct *p)
<span class="lineNum">    2541 </span>            : {
<span class="lineNum">    2542 </span>            :         spin_unlock(&amp;p-&gt;alloc_lock);
<span class="lineNum">    2543 </span>            : }
<span class="lineNum">    2544 </span>            : 
<span class="lineNum">    2545 </span>            : extern struct sighand_struct *__lock_task_sighand(struct task_struct *tsk,
<span class="lineNum">    2546 </span>            :                                                         unsigned long *flags);
<span class="lineNum">    2547 </span>            : 
<span class="lineNum">    2548 </span>            : static inline struct sighand_struct *lock_task_sighand(struct task_struct *tsk,
<span class="lineNum">    2549 </span>            :                                                        unsigned long *flags)
<span class="lineNum">    2550 </span>            : {
<span class="lineNum">    2551 </span>            :         struct sighand_struct *ret;
<span class="lineNum">    2552 </span>            : 
<span class="lineNum">    2553 </span>            :         ret = __lock_task_sighand(tsk, flags);
<span class="lineNum">    2554 </span>            :         (void)__cond_lock(&amp;tsk-&gt;sighand-&gt;siglock, ret);
<span class="lineNum">    2555 </span>            :         return ret;
<span class="lineNum">    2556 </span>            : }
<span class="lineNum">    2557 </span>            : 
<span class="lineNum">    2558 </span>            : static inline void unlock_task_sighand(struct task_struct *tsk,
<span class="lineNum">    2559 </span>            :                                                 unsigned long *flags)
<span class="lineNum">    2560 </span>            : {
<span class="lineNum">    2561 </span>            :         spin_unlock_irqrestore(&amp;tsk-&gt;sighand-&gt;siglock, *flags);
<span class="lineNum">    2562 </span>            : }
<span class="lineNum">    2563 </span>            : 
<span class="lineNum">    2564 </span>            : #ifdef CONFIG_CGROUPS
<span class="lineNum">    2565 </span>            : static inline void threadgroup_change_begin(struct task_struct *tsk)
<span class="lineNum">    2566 </span>            : {
<span class="lineNum">    2567 </span>            :         down_read(&amp;tsk-&gt;signal-&gt;group_rwsem);
<span class="lineNum">    2568 </span>            : }
<span class="lineNum">    2569 </span>            : static inline void threadgroup_change_end(struct task_struct *tsk)
<span class="lineNum">    2570 </span>            : {
<span class="lineNum">    2571 </span>            :         up_read(&amp;tsk-&gt;signal-&gt;group_rwsem);
<span class="lineNum">    2572 </span>            : }
<span class="lineNum">    2573 </span>            : 
<span class="lineNum">    2574 </span>            : /**
<span class="lineNum">    2575 </span>            :  * threadgroup_lock - lock threadgroup
<span class="lineNum">    2576 </span>            :  * @tsk: member task of the threadgroup to lock
<span class="lineNum">    2577 </span>            :  *
<span class="lineNum">    2578 </span>            :  * Lock the threadgroup @tsk belongs to.  No new task is allowed to enter
<span class="lineNum">    2579 </span>            :  * and member tasks aren't allowed to exit (as indicated by PF_EXITING) or
<span class="lineNum">    2580 </span>            :  * change -&gt;group_leader/pid.  This is useful for cases where the threadgroup
<span class="lineNum">    2581 </span>            :  * needs to stay stable across blockable operations.
<span class="lineNum">    2582 </span>            :  *
<span class="lineNum">    2583 </span>            :  * fork and exit paths explicitly call threadgroup_change_{begin|end}() for
<span class="lineNum">    2584 </span>            :  * synchronization.  While held, no new task will be added to threadgroup
<span class="lineNum">    2585 </span>            :  * and no existing live task will have its PF_EXITING set.
<span class="lineNum">    2586 </span>            :  *
<span class="lineNum">    2587 </span>            :  * de_thread() does threadgroup_change_{begin|end}() when a non-leader
<span class="lineNum">    2588 </span>            :  * sub-thread becomes a new leader.
<span class="lineNum">    2589 </span>            :  */
<span class="lineNum">    2590 </span>            : static inline void threadgroup_lock(struct task_struct *tsk)
<span class="lineNum">    2591 </span>            : {
<span class="lineNum">    2592 </span>            :         down_write(&amp;tsk-&gt;signal-&gt;group_rwsem);
<span class="lineNum">    2593 </span>            : }
<span class="lineNum">    2594 </span>            : 
<span class="lineNum">    2595 </span>            : /**
<span class="lineNum">    2596 </span>            :  * threadgroup_unlock - unlock threadgroup
<span class="lineNum">    2597 </span>            :  * @tsk: member task of the threadgroup to unlock
<span class="lineNum">    2598 </span>            :  *
<span class="lineNum">    2599 </span>            :  * Reverse threadgroup_lock().
<span class="lineNum">    2600 </span>            :  */
<span class="lineNum">    2601 </span>            : static inline void threadgroup_unlock(struct task_struct *tsk)
<span class="lineNum">    2602 </span>            : {
<span class="lineNum">    2603 </span>            :         up_write(&amp;tsk-&gt;signal-&gt;group_rwsem);
<span class="lineNum">    2604 </span>            : }
<span class="lineNum">    2605 </span>            : #else
<span class="lineNum">    2606 </span>            : static inline void threadgroup_change_begin(struct task_struct *tsk) {}
<span class="lineNum">    2607 </span>            : static inline void threadgroup_change_end(struct task_struct *tsk) {}
<span class="lineNum">    2608 </span>            : static inline void threadgroup_lock(struct task_struct *tsk) {}
<span class="lineNum">    2609 </span>            : static inline void threadgroup_unlock(struct task_struct *tsk) {}
<span class="lineNum">    2610 </span>            : #endif
<span class="lineNum">    2611 </span>            : 
<span class="lineNum">    2612 </span>            : #ifndef __HAVE_THREAD_FUNCTIONS
<span class="lineNum">    2613 </span>            : 
<span class="lineNum">    2614 </span>            : #define task_thread_info(task)  ((struct thread_info *)(task)-&gt;stack)
<span class="lineNum">    2615 </span>            : #define task_stack_page(task)   ((task)-&gt;stack)
<span class="lineNum">    2616 </span>            : 
<span class="lineNum">    2617 </span>            : static inline void setup_thread_stack(struct task_struct *p, struct task_struct *org)
<span class="lineNum">    2618 </span>            : {
<span class="lineNum">    2619 </span>            :         *task_thread_info(p) = *task_thread_info(org);
<span class="lineNum">    2620 </span>            :         task_thread_info(p)-&gt;task = p;
<span class="lineNum">    2621 </span>            : }
<span class="lineNum">    2622 </span>            : 
<span class="lineNum">    2623 </span>            : /*
<span class="lineNum">    2624 </span>            :  * Return the address of the last usable long on the stack.
<span class="lineNum">    2625 </span>            :  *
<span class="lineNum">    2626 </span>            :  * When the stack grows down, this is just above the thread
<span class="lineNum">    2627 </span>            :  * info struct. Going any lower will corrupt the threadinfo.
<span class="lineNum">    2628 </span>            :  *
<span class="lineNum">    2629 </span>            :  * When the stack grows up, this is the highest address.
<span class="lineNum">    2630 </span>            :  * Beyond that position, we corrupt data on the next page.
<span class="lineNum">    2631 </span>            :  */
<span class="lineNum">    2632 </span>            : static inline unsigned long *end_of_stack(struct task_struct *p)
<span class="lineNum">    2633 </span>            : {
<span class="lineNum">    2634 </span>            : #ifdef CONFIG_STACK_GROWSUP
<span class="lineNum">    2635 </span>            :         return (unsigned long *)((unsigned long)task_thread_info(p) + THREAD_SIZE) - 1;
<span class="lineNum">    2636 </span>            : #else
<span class="lineNum">    2637 </span>            :         return (unsigned long *)(task_thread_info(p) + 1);
<span class="lineNum">    2638 </span>            : #endif
<span class="lineNum">    2639 </span>            : }
<span class="lineNum">    2640 </span>            : 
<span class="lineNum">    2641 </span>            : #endif
<span class="lineNum">    2642 </span>            : 
<span class="lineNum">    2643 </span>            : static inline int object_is_on_stack(void *obj)
<span class="lineNum">    2644 </span>            : {
<span class="lineNum">    2645 </span>            :         void *stack = task_stack_page(current);
<span class="lineNum">    2646 </span>            : 
<span class="lineNum">    2647 </span>            :         return (obj &gt;= stack) &amp;&amp; (obj &lt; (stack + THREAD_SIZE));
<span class="lineNum">    2648 </span>            : }
<span class="lineNum">    2649 </span>            : 
<span class="lineNum">    2650 </span>            : extern void thread_info_cache_init(void);
<span class="lineNum">    2651 </span>            : 
<span class="lineNum">    2652 </span>            : #ifdef CONFIG_DEBUG_STACK_USAGE
<span class="lineNum">    2653 </span>            : static inline unsigned long stack_not_used(struct task_struct *p)
<span class="lineNum">    2654 </span>            : {
<span class="lineNum">    2655 </span>            :         unsigned long *n = end_of_stack(p);
<span class="lineNum">    2656 </span>            : 
<span class="lineNum">    2657 </span>            :         do {    /* Skip over canary */
<span class="lineNum">    2658 </span>            :                 n++;
<span class="lineNum">    2659 </span>            :         } while (!*n);
<span class="lineNum">    2660 </span>            : 
<span class="lineNum">    2661 </span>            :         return (unsigned long)n - (unsigned long)end_of_stack(p);
<span class="lineNum">    2662 </span>            : }
<span class="lineNum">    2663 </span>            : #endif
<span class="lineNum">    2664 </span>            : 
<span class="lineNum">    2665 </span>            : /* set thread flags in other task's structures
<span class="lineNum">    2666 </span>            :  * - see asm/thread_info.h for TIF_xxxx flags available
<span class="lineNum">    2667 </span>            :  */
<span class="lineNum">    2668 </span>            : static inline void set_tsk_thread_flag(struct task_struct *tsk, int flag)
<span class="lineNum">    2669 </span>            : {
<span class="lineNum">    2670 </span>            :         set_ti_thread_flag(task_thread_info(tsk), flag);
<span class="lineNum">    2671 </span>            : }
<span class="lineNum">    2672 </span>            : 
<span class="lineNum">    2673 </span>            : static inline void clear_tsk_thread_flag(struct task_struct *tsk, int flag)
<span class="lineNum">    2674 </span>            : {
<span class="lineNum">    2675 </span>            :         clear_ti_thread_flag(task_thread_info(tsk), flag);
<span class="lineNum">    2676 </span>            : }
<span class="lineNum">    2677 </span>            : 
<span class="lineNum">    2678 </span>            : static inline int test_and_set_tsk_thread_flag(struct task_struct *tsk, int flag)
<span class="lineNum">    2679 </span>            : {
<span class="lineNum">    2680 </span>            :         return test_and_set_ti_thread_flag(task_thread_info(tsk), flag);
<span class="lineNum">    2681 </span>            : }
<span class="lineNum">    2682 </span>            : 
<span class="lineNum">    2683 </span>            : static inline int test_and_clear_tsk_thread_flag(struct task_struct *tsk, int flag)
<span class="lineNum">    2684 </span>            : {
<span class="lineNum">    2685 </span>            :         return test_and_clear_ti_thread_flag(task_thread_info(tsk), flag);
<span class="lineNum">    2686 </span>            : }
<span class="lineNum">    2687 </span>            : 
<span class="lineNum">    2688 </span>            : static inline int test_tsk_thread_flag(struct task_struct *tsk, int flag)
<span class="lineNum">    2689 </span>            : {
<span class="lineNum">    2690 </span><span class="lineCov">       1390 :         return test_ti_thread_flag(task_thread_info(tsk), flag);</span>
<span class="lineNum">    2691 </span>            : }
<span class="lineNum">    2692 </span>            : 
<span class="lineNum">    2693 </span>            : static inline void set_tsk_need_resched(struct task_struct *tsk)
<span class="lineNum">    2694 </span>            : {
<span class="lineNum">    2695 </span>            :         set_tsk_thread_flag(tsk,TIF_NEED_RESCHED);
<span class="lineNum">    2696 </span>            : }
<span class="lineNum">    2697 </span>            : 
<span class="lineNum">    2698 </span>            : static inline void clear_tsk_need_resched(struct task_struct *tsk)
<span class="lineNum">    2699 </span>            : {
<span class="lineNum">    2700 </span>            :         clear_tsk_thread_flag(tsk,TIF_NEED_RESCHED);
<span class="lineNum">    2701 </span>            : }
<span class="lineNum">    2702 </span>            : 
<span class="lineNum">    2703 </span>            : static inline int test_tsk_need_resched(struct task_struct *tsk)
<span class="lineNum">    2704 </span>            : {
<span class="lineNum">    2705 </span>            :         return unlikely(test_tsk_thread_flag(tsk,TIF_NEED_RESCHED));
<span class="lineNum">    2706 </span>            : }
<span class="lineNum">    2707 </span>            : 
<span class="lineNum">    2708 </span>            : static inline int restart_syscall(void)
<span class="lineNum">    2709 </span>            : {
<span class="lineNum">    2710 </span>            :         set_tsk_thread_flag(current, TIF_SIGPENDING);
<span class="lineNum">    2711 </span>            :         return -ERESTARTNOINTR;
<span class="lineNum">    2712 </span>            : }
<span class="lineNum">    2713 </span>            : 
<span class="lineNum">    2714 </span>            : static inline int signal_pending(struct task_struct *p)
<span class="lineNum">    2715 </span>            : {
<span class="lineNum">    2716 </span><span class="lineCov">       1390 :         return unlikely(test_tsk_thread_flag(p,TIF_SIGPENDING));</span>
<span class="lineNum">    2717 </span>            : }
<span class="lineNum">    2718 </span>            : 
<span class="lineNum">    2719 </span>            : static inline int __fatal_signal_pending(struct task_struct *p)
<span class="lineNum">    2720 </span>            : {
<span class="lineNum">    2721 </span><span class="lineNoCov">          0 :         return unlikely(sigismember(&amp;p-&gt;pending.signal, SIGKILL));</span>
<span class="lineNum">    2722 </span>            : }
<span class="lineNum">    2723 </span>            : 
<span class="lineNum">    2724 </span>            : static inline int fatal_signal_pending(struct task_struct *p)
<span class="lineNum">    2725 </span>            : {
<span class="lineNum">    2726 </span><span class="lineNoCov">          0 :         return signal_pending(p) &amp;&amp; __fatal_signal_pending(p);</span>
<span class="lineNum">    2727 </span>            : }
<span class="lineNum">    2728 </span>            : 
<span class="lineNum">    2729 </span>            : static inline int signal_pending_state(long state, struct task_struct *p)
<span class="lineNum">    2730 </span>            : {
<span class="lineNum">    2731 </span>            :         if (!(state &amp; (TASK_INTERRUPTIBLE | TASK_WAKEKILL)))
<span class="lineNum">    2732 </span>            :                 return 0;
<span class="lineNum">    2733 </span>            :         if (!signal_pending(p))
<span class="lineNum">    2734 </span>            :                 return 0;
<span class="lineNum">    2735 </span>            : 
<span class="lineNum">    2736 </span>            :         return (state &amp; TASK_INTERRUPTIBLE) || __fatal_signal_pending(p);
<span class="lineNum">    2737 </span>            : }
<span class="lineNum">    2738 </span>            : 
<span class="lineNum">    2739 </span>            : /*
<span class="lineNum">    2740 </span>            :  * cond_resched() and cond_resched_lock(): latency reduction via
<span class="lineNum">    2741 </span>            :  * explicit rescheduling in places that are safe. The return
<span class="lineNum">    2742 </span>            :  * value indicates whether a reschedule was done in fact.
<span class="lineNum">    2743 </span>            :  * cond_resched_lock() will drop the spinlock before scheduling,
<span class="lineNum">    2744 </span>            :  * cond_resched_softirq() will enable bhs before scheduling.
<span class="lineNum">    2745 </span>            :  */
<span class="lineNum">    2746 </span>            : extern int _cond_resched(void);
<span class="lineNum">    2747 </span>            : 
<span class="lineNum">    2748 </span>            : #define cond_resched() ({                       \
<span class="lineNum">    2749 </span>            :         __might_sleep(__FILE__, __LINE__, 0);   \
<span class="lineNum">    2750 </span>            :         _cond_resched();                        \
<span class="lineNum">    2751 </span>            : })
<span class="lineNum">    2752 </span>            : 
<span class="lineNum">    2753 </span>            : extern int __cond_resched_lock(spinlock_t *lock);
<span class="lineNum">    2754 </span>            : 
<span class="lineNum">    2755 </span>            : #ifdef CONFIG_PREEMPT_COUNT
<span class="lineNum">    2756 </span>            : #define PREEMPT_LOCK_OFFSET     PREEMPT_OFFSET
<span class="lineNum">    2757 </span>            : #else
<span class="lineNum">    2758 </span>            : #define PREEMPT_LOCK_OFFSET     0
<span class="lineNum">    2759 </span>            : #endif
<span class="lineNum">    2760 </span>            : 
<span class="lineNum">    2761 </span>            : #define cond_resched_lock(lock) ({                              \
<span class="lineNum">    2762 </span>            :         __might_sleep(__FILE__, __LINE__, PREEMPT_LOCK_OFFSET); \
<span class="lineNum">    2763 </span>            :         __cond_resched_lock(lock);                              \
<span class="lineNum">    2764 </span>            : })
<span class="lineNum">    2765 </span>            : 
<span class="lineNum">    2766 </span>            : extern int __cond_resched_softirq(void);
<span class="lineNum">    2767 </span>            : 
<span class="lineNum">    2768 </span>            : #define cond_resched_softirq() ({                                       \
<span class="lineNum">    2769 </span>            :         __might_sleep(__FILE__, __LINE__, SOFTIRQ_DISABLE_OFFSET);      \
<span class="lineNum">    2770 </span>            :         __cond_resched_softirq();                                       \
<span class="lineNum">    2771 </span>            : })
<span class="lineNum">    2772 </span>            : 
<span class="lineNum">    2773 </span>            : static inline void cond_resched_rcu(void)
<span class="lineNum">    2774 </span>            : {
<span class="lineNum">    2775 </span>            : #if defined(CONFIG_DEBUG_ATOMIC_SLEEP) || !defined(CONFIG_PREEMPT_RCU)
<span class="lineNum">    2776 </span>            :         rcu_read_unlock();
<span class="lineNum">    2777 </span>            :         cond_resched();
<span class="lineNum">    2778 </span>            :         rcu_read_lock();
<span class="lineNum">    2779 </span>            : #endif
<span class="lineNum">    2780 </span>            : }
<span class="lineNum">    2781 </span>            : 
<span class="lineNum">    2782 </span>            : /*
<span class="lineNum">    2783 </span>            :  * Does a critical section need to be broken due to another
<span class="lineNum">    2784 </span>            :  * task waiting?: (technically does not depend on CONFIG_PREEMPT,
<span class="lineNum">    2785 </span>            :  * but a general need for low latency)
<span class="lineNum">    2786 </span>            :  */
<span class="lineNum">    2787 </span>            : static inline int spin_needbreak(spinlock_t *lock)
<span class="lineNum">    2788 </span>            : {
<span class="lineNum">    2789 </span>            : #ifdef CONFIG_PREEMPT
<span class="lineNum">    2790 </span>            :         return spin_is_contended(lock);
<span class="lineNum">    2791 </span>            : #else
<span class="lineNum">    2792 </span>            :         return 0;
<span class="lineNum">    2793 </span>            : #endif
<span class="lineNum">    2794 </span>            : }
<span class="lineNum">    2795 </span>            : 
<span class="lineNum">    2796 </span>            : /*
<span class="lineNum">    2797 </span>            :  * Idle thread specific functions to determine the need_resched
<span class="lineNum">    2798 </span>            :  * polling state.
<span class="lineNum">    2799 </span>            :  */
<span class="lineNum">    2800 </span>            : #ifdef TIF_POLLING_NRFLAG
<span class="lineNum">    2801 </span>            : static inline int tsk_is_polling(struct task_struct *p)
<span class="lineNum">    2802 </span>            : {
<span class="lineNum">    2803 </span>            :         return test_tsk_thread_flag(p, TIF_POLLING_NRFLAG);
<span class="lineNum">    2804 </span>            : }
<span class="lineNum">    2805 </span>            : 
<span class="lineNum">    2806 </span>            : static inline void __current_set_polling(void)
<span class="lineNum">    2807 </span>            : {
<span class="lineNum">    2808 </span>            :         set_thread_flag(TIF_POLLING_NRFLAG);
<span class="lineNum">    2809 </span>            : }
<span class="lineNum">    2810 </span>            : 
<span class="lineNum">    2811 </span>            : static inline bool __must_check current_set_polling_and_test(void)
<span class="lineNum">    2812 </span>            : {
<span class="lineNum">    2813 </span>            :         __current_set_polling();
<span class="lineNum">    2814 </span>            : 
<span class="lineNum">    2815 </span>            :         /*
<span class="lineNum">    2816 </span>            :          * Polling state must be visible before we test NEED_RESCHED,
<span class="lineNum">    2817 </span>            :          * paired by resched_curr()
<span class="lineNum">    2818 </span>            :          */
<span class="lineNum">    2819 </span>            :         smp_mb__after_atomic();
<span class="lineNum">    2820 </span>            : 
<span class="lineNum">    2821 </span>            :         return unlikely(tif_need_resched());
<span class="lineNum">    2822 </span>            : }
<span class="lineNum">    2823 </span>            : 
<span class="lineNum">    2824 </span>            : static inline void __current_clr_polling(void)
<span class="lineNum">    2825 </span>            : {
<span class="lineNum">    2826 </span>            :         clear_thread_flag(TIF_POLLING_NRFLAG);
<span class="lineNum">    2827 </span>            : }
<span class="lineNum">    2828 </span>            : 
<span class="lineNum">    2829 </span>            : static inline bool __must_check current_clr_polling_and_test(void)
<span class="lineNum">    2830 </span>            : {
<span class="lineNum">    2831 </span>            :         __current_clr_polling();
<span class="lineNum">    2832 </span>            : 
<span class="lineNum">    2833 </span>            :         /*
<span class="lineNum">    2834 </span>            :          * Polling state must be visible before we test NEED_RESCHED,
<span class="lineNum">    2835 </span>            :          * paired by resched_curr()
<span class="lineNum">    2836 </span>            :          */
<span class="lineNum">    2837 </span>            :         smp_mb__after_atomic();
<span class="lineNum">    2838 </span>            : 
<span class="lineNum">    2839 </span>            :         return unlikely(tif_need_resched());
<span class="lineNum">    2840 </span>            : }
<span class="lineNum">    2841 </span>            : 
<span class="lineNum">    2842 </span>            : #else
<span class="lineNum">    2843 </span>            : static inline int tsk_is_polling(struct task_struct *p) { return 0; }
<span class="lineNum">    2844 </span>            : static inline void __current_set_polling(void) { }
<span class="lineNum">    2845 </span>            : static inline void __current_clr_polling(void) { }
<span class="lineNum">    2846 </span>            : 
<span class="lineNum">    2847 </span>            : static inline bool __must_check current_set_polling_and_test(void)
<span class="lineNum">    2848 </span>            : {
<span class="lineNum">    2849 </span>            :         return unlikely(tif_need_resched());
<span class="lineNum">    2850 </span>            : }
<span class="lineNum">    2851 </span>            : static inline bool __must_check current_clr_polling_and_test(void)
<span class="lineNum">    2852 </span>            : {
<span class="lineNum">    2853 </span>            :         return unlikely(tif_need_resched());
<span class="lineNum">    2854 </span>            : }
<span class="lineNum">    2855 </span>            : #endif
<span class="lineNum">    2856 </span>            : 
<span class="lineNum">    2857 </span>            : static inline void current_clr_polling(void)
<span class="lineNum">    2858 </span>            : {
<span class="lineNum">    2859 </span>            :         __current_clr_polling();
<span class="lineNum">    2860 </span>            : 
<span class="lineNum">    2861 </span>            :         /*
<span class="lineNum">    2862 </span>            :          * Ensure we check TIF_NEED_RESCHED after we clear the polling bit.
<span class="lineNum">    2863 </span>            :          * Once the bit is cleared, we'll get IPIs with every new
<span class="lineNum">    2864 </span>            :          * TIF_NEED_RESCHED and the IPI handler, scheduler_ipi(), will also
<span class="lineNum">    2865 </span>            :          * fold.
<span class="lineNum">    2866 </span>            :          */
<span class="lineNum">    2867 </span>            :         smp_mb(); /* paired with resched_curr() */
<span class="lineNum">    2868 </span>            : 
<span class="lineNum">    2869 </span>            :         preempt_fold_need_resched();
<span class="lineNum">    2870 </span>            : }
<span class="lineNum">    2871 </span>            : 
<span class="lineNum">    2872 </span>            : static __always_inline bool need_resched(void)
<span class="lineNum">    2873 </span>            : {
<span class="lineNum">    2874 </span><span class="lineCov">     248943 :         return unlikely(tif_need_resched());</span>
<span class="lineNum">    2875 </span>            : }
<span class="lineNum">    2876 </span>            : 
<span class="lineNum">    2877 </span>            : /*
<span class="lineNum">    2878 </span>            :  * Thread group CPU time accounting.
<span class="lineNum">    2879 </span>            :  */
<span class="lineNum">    2880 </span>            : void thread_group_cputime(struct task_struct *tsk, struct task_cputime *times);
<span class="lineNum">    2881 </span>            : void thread_group_cputimer(struct task_struct *tsk, struct task_cputime *times);
<span class="lineNum">    2882 </span>            : 
<span class="lineNum">    2883 </span>            : static inline void thread_group_cputime_init(struct signal_struct *sig)
<span class="lineNum">    2884 </span>            : {
<span class="lineNum">    2885 </span>            :         raw_spin_lock_init(&amp;sig-&gt;cputimer.lock);
<span class="lineNum">    2886 </span>            : }
<span class="lineNum">    2887 </span>            : 
<span class="lineNum">    2888 </span>            : /*
<span class="lineNum">    2889 </span>            :  * Reevaluate whether the task has signals pending delivery.
<span class="lineNum">    2890 </span>            :  * Wake the task if so.
<span class="lineNum">    2891 </span>            :  * This is required every time the blocked sigset_t changes.
<span class="lineNum">    2892 </span>            :  * callers must hold sighand-&gt;siglock.
<span class="lineNum">    2893 </span>            :  */
<span class="lineNum">    2894 </span>            : extern void recalc_sigpending_and_wake(struct task_struct *t);
<span class="lineNum">    2895 </span>            : extern void recalc_sigpending(void);
<span class="lineNum">    2896 </span>            : 
<span class="lineNum">    2897 </span>            : extern void signal_wake_up_state(struct task_struct *t, unsigned int state);
<span class="lineNum">    2898 </span>            : 
<span class="lineNum">    2899 </span>            : static inline void signal_wake_up(struct task_struct *t, bool resume)
<span class="lineNum">    2900 </span>            : {
<span class="lineNum">    2901 </span>            :         signal_wake_up_state(t, resume ? TASK_WAKEKILL : 0);
<span class="lineNum">    2902 </span>            : }
<span class="lineNum">    2903 </span>            : static inline void ptrace_signal_wake_up(struct task_struct *t, bool resume)
<span class="lineNum">    2904 </span>            : {
<span class="lineNum">    2905 </span>            :         signal_wake_up_state(t, resume ? __TASK_TRACED : 0);
<span class="lineNum">    2906 </span>            : }
<span class="lineNum">    2907 </span>            : 
<span class="lineNum">    2908 </span>            : /*
<span class="lineNum">    2909 </span>            :  * Wrappers for p-&gt;thread_info-&gt;cpu access. No-op on UP.
<span class="lineNum">    2910 </span>            :  */
<span class="lineNum">    2911 </span>            : #ifdef CONFIG_SMP
<span class="lineNum">    2912 </span>            : 
<span class="lineNum">    2913 </span>            : static inline unsigned int task_cpu(const struct task_struct *p)
<span class="lineNum">    2914 </span>            : {
<span class="lineNum">    2915 </span>            :         return task_thread_info(p)-&gt;cpu;
<span class="lineNum">    2916 </span>            : }
<span class="lineNum">    2917 </span>            : 
<span class="lineNum">    2918 </span>            : static inline int task_node(const struct task_struct *p)
<span class="lineNum">    2919 </span>            : {
<span class="lineNum">    2920 </span>            :         return cpu_to_node(task_cpu(p));
<span class="lineNum">    2921 </span>            : }
<span class="lineNum">    2922 </span>            : 
<span class="lineNum">    2923 </span>            : extern void set_task_cpu(struct task_struct *p, unsigned int cpu);
<span class="lineNum">    2924 </span>            : 
<span class="lineNum">    2925 </span>            : #else
<span class="lineNum">    2926 </span>            : 
<span class="lineNum">    2927 </span>            : static inline unsigned int task_cpu(const struct task_struct *p)
<span class="lineNum">    2928 </span>            : {
<span class="lineNum">    2929 </span>            :         return 0;
<span class="lineNum">    2930 </span>            : }
<span class="lineNum">    2931 </span>            : 
<span class="lineNum">    2932 </span>            : static inline void set_task_cpu(struct task_struct *p, unsigned int cpu)
<span class="lineNum">    2933 </span>            : {
<span class="lineNum">    2934 </span>            : }
<span class="lineNum">    2935 </span>            : 
<span class="lineNum">    2936 </span>            : #endif /* CONFIG_SMP */
<span class="lineNum">    2937 </span>            : 
<span class="lineNum">    2938 </span>            : extern long sched_setaffinity(pid_t pid, const struct cpumask *new_mask);
<span class="lineNum">    2939 </span>            : extern long sched_getaffinity(pid_t pid, struct cpumask *mask);
<span class="lineNum">    2940 </span>            : 
<span class="lineNum">    2941 </span>            : #ifdef CONFIG_CGROUP_SCHED
<span class="lineNum">    2942 </span>            : extern struct task_group root_task_group;
<span class="lineNum">    2943 </span>            : #endif /* CONFIG_CGROUP_SCHED */
<span class="lineNum">    2944 </span>            : 
<span class="lineNum">    2945 </span>            : extern int task_can_switch_user(struct user_struct *up,
<span class="lineNum">    2946 </span>            :                                         struct task_struct *tsk);
<span class="lineNum">    2947 </span>            : 
<span class="lineNum">    2948 </span>            : #ifdef CONFIG_TASK_XACCT
<span class="lineNum">    2949 </span>            : static inline void add_rchar(struct task_struct *tsk, ssize_t amt)
<span class="lineNum">    2950 </span>            : {
<span class="lineNum">    2951 </span>            :         tsk-&gt;ioac.rchar += amt;
<span class="lineNum">    2952 </span>            : }
<span class="lineNum">    2953 </span>            : 
<span class="lineNum">    2954 </span>            : static inline void add_wchar(struct task_struct *tsk, ssize_t amt)
<span class="lineNum">    2955 </span>            : {
<span class="lineNum">    2956 </span>            :         tsk-&gt;ioac.wchar += amt;
<span class="lineNum">    2957 </span>            : }
<span class="lineNum">    2958 </span>            : 
<span class="lineNum">    2959 </span>            : static inline void inc_syscr(struct task_struct *tsk)
<span class="lineNum">    2960 </span>            : {
<span class="lineNum">    2961 </span>            :         tsk-&gt;ioac.syscr++;
<span class="lineNum">    2962 </span>            : }
<span class="lineNum">    2963 </span>            : 
<span class="lineNum">    2964 </span>            : static inline void inc_syscw(struct task_struct *tsk)
<span class="lineNum">    2965 </span>            : {
<span class="lineNum">    2966 </span>            :         tsk-&gt;ioac.syscw++;
<span class="lineNum">    2967 </span>            : }
<span class="lineNum">    2968 </span>            : #else
<span class="lineNum">    2969 </span>            : static inline void add_rchar(struct task_struct *tsk, ssize_t amt)
<span class="lineNum">    2970 </span>            : {
<span class="lineNum">    2971 </span>            : }
<span class="lineNum">    2972 </span>            : 
<span class="lineNum">    2973 </span>            : static inline void add_wchar(struct task_struct *tsk, ssize_t amt)
<span class="lineNum">    2974 </span>            : {
<span class="lineNum">    2975 </span>            : }
<span class="lineNum">    2976 </span>            : 
<span class="lineNum">    2977 </span>            : static inline void inc_syscr(struct task_struct *tsk)
<span class="lineNum">    2978 </span>            : {
<span class="lineNum">    2979 </span>            : }
<span class="lineNum">    2980 </span>            : 
<span class="lineNum">    2981 </span>            : static inline void inc_syscw(struct task_struct *tsk)
<span class="lineNum">    2982 </span>            : {
<span class="lineNum">    2983 </span>            : }
<span class="lineNum">    2984 </span>            : #endif
<span class="lineNum">    2985 </span>            : 
<span class="lineNum">    2986 </span>            : #ifndef TASK_SIZE_OF
<span class="lineNum">    2987 </span>            : #define TASK_SIZE_OF(tsk)       TASK_SIZE
<span class="lineNum">    2988 </span>            : #endif
<span class="lineNum">    2989 </span>            : 
<span class="lineNum">    2990 </span>            : #ifdef CONFIG_MEMCG
<span class="lineNum">    2991 </span>            : extern void mm_update_next_owner(struct mm_struct *mm);
<span class="lineNum">    2992 </span>            : #else
<span class="lineNum">    2993 </span>            : static inline void mm_update_next_owner(struct mm_struct *mm)
<span class="lineNum">    2994 </span>            : {
<span class="lineNum">    2995 </span>            : }
<span class="lineNum">    2996 </span>            : #endif /* CONFIG_MEMCG */
<span class="lineNum">    2997 </span>            : 
<span class="lineNum">    2998 </span>            : static inline unsigned long task_rlimit(const struct task_struct *tsk,
<span class="lineNum">    2999 </span>            :                 unsigned int limit)
<span class="lineNum">    3000 </span>            : {
<span class="lineNum">    3001 </span>            :         return ACCESS_ONCE(tsk-&gt;signal-&gt;rlim[limit].rlim_cur);
<span class="lineNum">    3002 </span>            : }
<span class="lineNum">    3003 </span>            : 
<span class="lineNum">    3004 </span>            : static inline unsigned long task_rlimit_max(const struct task_struct *tsk,
<span class="lineNum">    3005 </span>            :                 unsigned int limit)
<span class="lineNum">    3006 </span>            : {
<span class="lineNum">    3007 </span>            :         return ACCESS_ONCE(tsk-&gt;signal-&gt;rlim[limit].rlim_max);
<span class="lineNum">    3008 </span>            : }
<span class="lineNum">    3009 </span>            : 
<span class="lineNum">    3010 </span>            : static inline unsigned long rlimit(unsigned int limit)
<span class="lineNum">    3011 </span>            : {
<span class="lineNum">    3012 </span>            :         return task_rlimit(current, limit);
<span class="lineNum">    3013 </span>            : }
<span class="lineNum">    3014 </span>            : 
<span class="lineNum">    3015 </span>            : static inline unsigned long rlimit_max(unsigned int limit)
<span class="lineNum">    3016 </span>            : {
<span class="lineNum">    3017 </span>            :         return task_rlimit_max(current, limit);
<span class="lineNum">    3018 </span>            : }
<span class="lineNum">    3019 </span>            : 
<span class="lineNum">    3020 </span>            : #endif
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="http://ltp.sourceforge.net/coverage/lcov.php" target="_parent">LCOV version 1.10</a></td></tr>
  </table>
  <br>

</body>
</html>
